2018-04-17 21:10:50,575 - brc - INFO - Running with args : Namespace(algo='BIDAF', batch_size=32, brc_dir='model/', char_embed='../../data/embedding/wiki_brc/wiki_brc.char.vec', char_hidden_size=100, dev_files=['../../data/preprocessed_ltp/devset/search.dev.filter.json', '../../data/preprocessed_ltp/devset/zhidao.dev.filter.json'], dropout_keep_prob=1, epochs=10, evaluate=False, gpu='0', hidden_size=150, learning_rate=0.001, log_path='model/log', max_a_len=500, max_p_len=500, max_p_num=5, max_q_len=60, max_w_len=4, model_dir='model/', optim='adam', pos_embed_dim=10, pr_rate=0.2, predict=False, prepare=False, restore=False, result_dir='model/', summary_dir='model/', test_files=['../../data/test1set/preprocessed/search.test1.json', '../../data/test1set/preprocessed/zhidao.test1.json'], train=True, train_files=['../../data/preprocessed_ltp/trainset/search.train.filter.json', '../../data/preprocessed_ltp/trainset/zhidao.train.filter.json'], vocab_dir='model/', weight_decay=0, word_embed='../../data/embedding/wiki_brc/wiki_brc.word.vec')
2018-04-17 21:10:50,575 - brc - INFO - Load data_set and vocab...
2018-04-17 21:15:57,926 - brc - INFO - Train set size: 257469 questions.
2018-04-17 21:16:49,416 - brc - INFO - Dev set size: 10000 questions.
2018-04-17 21:16:49,416 - brc - INFO - Converting text into ids...
2018-04-17 21:26:35,957 - brc - INFO - Initialize the model...
2018-04-17 21:26:41,496 - brc - INFO - Time to build graph: 4.63964104652 s
2018-04-17 21:26:58,168 - brc - INFO - There are 3865506 parameters in the model
2018-04-17 21:27:00,372 - brc - INFO - Training the model...
2018-04-17 21:27:00,372 - brc - INFO - Training the model for epoch 1
2018-04-17 21:29:26,942 - brc - INFO - Average loss from batch 1 to 50 is 8.32034473419
2018-04-17 21:31:27,567 - brc - INFO - Average loss from batch 51 to 100 is 6.78043298721
2018-04-17 21:33:27,539 - brc - INFO - Average loss from batch 101 to 150 is 6.52112897873
2018-04-17 21:35:21,337 - brc - INFO - Average loss from batch 151 to 200 is 6.47333483696
2018-04-17 21:37:18,720 - brc - INFO - Average loss from batch 201 to 250 is 6.26414298058
2018-04-17 21:39:16,942 - brc - INFO - Average loss from batch 251 to 300 is 6.13277905464
2018-04-17 21:41:16,061 - brc - INFO - Average loss from batch 301 to 350 is 6.15191849709
2018-04-17 21:43:14,340 - brc - INFO - Average loss from batch 351 to 400 is 6.09864494324
2018-04-17 21:45:13,514 - brc - INFO - Average loss from batch 401 to 450 is 6.11721182823
2018-04-17 21:47:13,173 - brc - INFO - Average loss from batch 451 to 500 is 6.07800627708
2018-04-17 21:49:09,317 - brc - INFO - Average loss from batch 501 to 550 is 5.93170716286
2018-04-17 21:51:05,657 - brc - INFO - Average loss from batch 551 to 600 is 6.04983345032
2018-04-17 21:53:02,172 - brc - INFO - Average loss from batch 601 to 650 is 6.09341701508
2018-04-17 21:55:28,269 - brc - INFO - Average loss from batch 651 to 700 is 5.90012483597
2018-04-17 21:57:24,930 - brc - INFO - Average loss from batch 701 to 750 is 5.88921401978
2018-04-17 21:59:21,329 - brc - INFO - Average loss from batch 751 to 800 is 5.98275157928
2018-04-17 22:01:18,100 - brc - INFO - Average loss from batch 801 to 850 is 5.97210185051
2018-04-17 22:03:14,077 - brc - INFO - Average loss from batch 851 to 900 is 5.80384282112
2018-04-17 22:05:09,920 - brc - INFO - Average loss from batch 901 to 950 is 6.04839696884
2018-04-17 22:07:06,711 - brc - INFO - Average loss from batch 951 to 1000 is 5.93719968796
2018-04-17 22:09:02,403 - brc - INFO - Average loss from batch 1001 to 1050 is 5.94748041153
2018-04-17 22:10:58,420 - brc - INFO - Average loss from batch 1051 to 1100 is 5.91993243217
2018-04-17 22:12:53,403 - brc - INFO - Average loss from batch 1101 to 1150 is 5.89908519745
2018-04-17 22:14:49,228 - brc - INFO - Average loss from batch 1151 to 1200 is 5.86386656761
2018-04-17 22:16:46,237 - brc - INFO - Average loss from batch 1201 to 1250 is 5.94588514328
2018-04-17 22:18:41,804 - brc - INFO - Average loss from batch 1251 to 1300 is 5.897850914
2018-04-17 22:21:09,067 - brc - INFO - Average loss from batch 1301 to 1350 is 5.76923833847
2018-04-17 22:23:06,605 - brc - INFO - Average loss from batch 1351 to 1400 is 5.78484553337
2018-04-17 22:25:02,638 - brc - INFO - Average loss from batch 1401 to 1450 is 5.69063648224
2018-04-17 22:26:58,820 - brc - INFO - Average loss from batch 1451 to 1500 is 5.73315769196
2018-04-17 22:28:54,403 - brc - INFO - Average loss from batch 1501 to 1550 is 5.85342255116
2018-04-17 22:30:51,325 - brc - INFO - Average loss from batch 1551 to 1600 is 5.77886814117
2018-04-17 22:32:47,217 - brc - INFO - Average loss from batch 1601 to 1650 is 5.82419774055
2018-04-17 22:34:42,889 - brc - INFO - Average loss from batch 1651 to 1700 is 5.79944355965
2018-04-17 22:36:39,050 - brc - INFO - Average loss from batch 1701 to 1750 is 5.78308917999
2018-04-17 22:38:33,227 - brc - INFO - Average loss from batch 1751 to 1800 is 5.64859993935
2018-04-17 22:40:27,057 - brc - INFO - Average loss from batch 1801 to 1850 is 5.70593464851
2018-04-17 22:42:20,758 - brc - INFO - Average loss from batch 1851 to 1900 is 5.75746148109
2018-04-17 22:44:15,701 - brc - INFO - Average loss from batch 1901 to 1950 is 5.69906319618
2018-04-17 22:46:43,903 - brc - INFO - Average loss from batch 1951 to 2000 is 5.74472056389
2018-04-17 22:47:10,085 - brc - INFO - Evaluating the model ...
2018-04-17 23:04:37,380 - brc - INFO - Dev eval loss 8.2613579071
2018-04-17 23:04:37,383 - brc - INFO - Dev eval result: {'BLEU-4': 37.43, 'ROUGE-L': 45.15}
2018-04-17 23:04:39,197 - brc - INFO - Model saved in model/, with prefix BIDAF.
2018-04-17 23:06:10,353 - brc - INFO - Average loss from batch 2001 to 2050 is 5.76614418983
2018-04-17 23:08:06,511 - brc - INFO - Average loss from batch 2051 to 2100 is 5.63970542908
2018-04-17 23:10:04,925 - brc - INFO - Average loss from batch 2101 to 2150 is 5.70999527931
2018-04-17 23:12:01,368 - brc - INFO - Average loss from batch 2151 to 2200 is 5.72820848465
2018-04-17 23:13:55,921 - brc - INFO - Average loss from batch 2201 to 2250 is 5.65291761398
2018-04-17 23:16:27,047 - brc - INFO - Average loss from batch 2251 to 2300 is 5.54533735275
2018-04-17 23:18:23,963 - brc - INFO - Average loss from batch 2301 to 2350 is 5.71939282417
2018-04-17 23:20:20,804 - brc - INFO - Average loss from batch 2351 to 2400 is 5.67099719048
2018-04-17 23:22:18,044 - brc - INFO - Average loss from batch 2401 to 2450 is 5.72478092194
2018-04-17 23:24:14,035 - brc - INFO - Average loss from batch 2451 to 2500 is 5.71122713089
2018-04-17 23:26:09,842 - brc - INFO - Average loss from batch 2501 to 2550 is 5.67135561943
2018-04-17 23:28:05,020 - brc - INFO - Average loss from batch 2551 to 2600 is 5.63552603722
2018-04-17 23:30:00,535 - brc - INFO - Average loss from batch 2601 to 2650 is 5.6333162117
2018-04-17 23:31:55,205 - brc - INFO - Average loss from batch 2651 to 2700 is 5.67271540642
2018-04-17 23:33:50,765 - brc - INFO - Average loss from batch 2701 to 2750 is 5.66704114914
2018-04-17 23:35:47,864 - brc - INFO - Average loss from batch 2751 to 2800 is 5.53338287354
2018-04-17 23:37:44,358 - brc - INFO - Average loss from batch 2801 to 2850 is 5.67031627655
2018-04-17 23:39:39,970 - brc - INFO - Average loss from batch 2851 to 2900 is 5.45515431404
2018-04-17 23:42:12,441 - brc - INFO - Average loss from batch 2901 to 2950 is 5.62104729652
2018-04-17 23:44:08,177 - brc - INFO - Average loss from batch 2951 to 3000 is 5.66196424484
2018-04-17 23:46:04,688 - brc - INFO - Average loss from batch 3001 to 3050 is 5.52961209297
2018-04-17 23:48:00,725 - brc - INFO - Average loss from batch 3051 to 3100 is 5.66932088852
2018-04-17 23:49:57,577 - brc - INFO - Average loss from batch 3101 to 3150 is 5.57785805702
2018-04-17 23:51:52,708 - brc - INFO - Average loss from batch 3151 to 3200 is 5.68764843941
2018-04-17 23:53:48,877 - brc - INFO - Average loss from batch 3201 to 3250 is 5.69339287758
2018-04-17 23:55:44,000 - brc - INFO - Average loss from batch 3251 to 3300 is 5.54291060448
2018-04-17 23:57:38,804 - brc - INFO - Average loss from batch 3301 to 3350 is 5.58190303802
2018-04-17 23:59:34,560 - brc - INFO - Average loss from batch 3351 to 3400 is 5.57058579445
2018-04-18 00:01:30,656 - brc - INFO - Average loss from batch 3401 to 3450 is 5.59486861229
2018-04-18 00:03:25,687 - brc - INFO - Average loss from batch 3451 to 3500 is 5.59554358482
2018-04-18 00:05:21,373 - brc - INFO - Average loss from batch 3501 to 3550 is 5.60722373962
2018-04-18 00:07:53,888 - brc - INFO - Average loss from batch 3551 to 3600 is 5.75211836815
2018-04-18 00:09:50,195 - brc - INFO - Average loss from batch 3601 to 3650 is 5.66514184952
2018-04-18 00:11:45,832 - brc - INFO - Average loss from batch 3651 to 3700 is 5.5714888382
2018-04-18 00:13:42,505 - brc - INFO - Average loss from batch 3701 to 3750 is 5.50434594154
2018-04-18 00:15:38,978 - brc - INFO - Average loss from batch 3751 to 3800 is 5.6576143074
2018-04-18 00:17:35,529 - brc - INFO - Average loss from batch 3801 to 3850 is 5.51033782005
2018-04-18 00:19:31,263 - brc - INFO - Average loss from batch 3851 to 3900 is 5.66566305161
2018-04-18 00:21:26,754 - brc - INFO - Average loss from batch 3901 to 3950 is 5.5585131073
2018-04-18 00:23:23,403 - brc - INFO - Average loss from batch 3951 to 4000 is 5.53881810188
2018-04-18 00:24:14,045 - brc - INFO - Evaluating the model ...
2018-04-18 00:43:44,415 - brc - INFO - Dev eval loss 8.02767901459
2018-04-18 00:43:44,418 - brc - INFO - Dev eval result: {'BLEU-4': 37.03, 'ROUGE-L': 46.29}
2018-04-18 00:43:50,836 - brc - INFO - Model saved in model/, with prefix BIDAF.
2018-04-18 00:44:55,008 - brc - INFO - Average loss from batch 4001 to 4050 is 5.5283839798
2018-04-18 00:46:53,052 - brc - INFO - Average loss from batch 4051 to 4100 is 5.480111866
2018-04-18 00:48:50,168 - brc - INFO - Average loss from batch 4101 to 4150 is 5.54850694656
2018-04-18 00:50:46,456 - brc - INFO - Average loss from batch 4151 to 4200 is 5.63361084938
2018-04-18 00:52:43,165 - brc - INFO - Average loss from batch 4201 to 4250 is 5.62221714973
2018-04-18 00:54:38,687 - brc - INFO - Average loss from batch 4251 to 4300 is 5.46164980888
2018-04-18 00:56:34,709 - brc - INFO - Average loss from batch 4301 to 4350 is 5.60804392815
2018-04-18 00:58:28,830 - brc - INFO - Average loss from batch 4351 to 4400 is 5.51363253593
2018-04-18 01:00:23,620 - brc - INFO - Average loss from batch 4401 to 4450 is 5.59845684052
2018-04-18 01:02:18,845 - brc - INFO - Average loss from batch 4451 to 4500 is 5.54375218391
2018-04-18 01:04:14,299 - brc - INFO - Average loss from batch 4501 to 4550 is 5.50381285667
2018-04-18 01:06:47,850 - brc - INFO - Average loss from batch 4551 to 4600 is 5.56962613106
2018-04-18 01:08:45,024 - brc - INFO - Average loss from batch 4601 to 4650 is 5.59476943016
2018-04-18 01:10:42,146 - brc - INFO - Average loss from batch 4651 to 4700 is 5.52905201912
2018-04-18 01:12:37,447 - brc - INFO - Average loss from batch 4701 to 4750 is 5.55080172539
2018-04-18 01:14:33,964 - brc - INFO - Average loss from batch 4751 to 4800 is 5.4721378994
2018-04-18 01:16:30,319 - brc - INFO - Average loss from batch 4801 to 4850 is 5.62975716591
2018-04-18 01:18:26,778 - brc - INFO - Average loss from batch 4851 to 4900 is 5.5540639019
2018-04-18 01:20:22,380 - brc - INFO - Average loss from batch 4901 to 4950 is 5.67109994888
2018-04-18 01:22:19,081 - brc - INFO - Average loss from batch 4951 to 5000 is 5.59268082619
2018-04-18 01:24:15,400 - brc - INFO - Average loss from batch 5001 to 5050 is 5.63830287933
2018-04-18 01:26:11,789 - brc - INFO - Average loss from batch 5051 to 5100 is 5.57811696053
2018-04-18 01:28:08,561 - brc - INFO - Average loss from batch 5101 to 5150 is 5.42051528931
2018-04-18 01:30:05,261 - brc - INFO - Average loss from batch 5151 to 5200 is 5.48154734612
2018-04-18 01:32:39,249 - brc - INFO - Average loss from batch 5201 to 5250 is 5.56748116493
2018-04-18 01:34:35,959 - brc - INFO - Average loss from batch 5251 to 5300 is 5.5291236496
2018-04-18 01:36:32,146 - brc - INFO - Average loss from batch 5301 to 5350 is 5.52813337326
2018-04-18 01:38:28,262 - brc - INFO - Average loss from batch 5351 to 5400 is 5.51489584923
2018-04-18 01:40:24,828 - brc - INFO - Average loss from batch 5401 to 5450 is 5.56365999222
2018-04-18 01:42:19,980 - brc - INFO - Average loss from batch 5451 to 5500 is 5.67607041359
2018-04-18 01:44:16,344 - brc - INFO - Average loss from batch 5501 to 5550 is 5.47961792946
2018-04-18 01:46:10,305 - brc - INFO - Average loss from batch 5551 to 5600 is 5.46838560104
2018-04-18 01:48:12,975 - brc - INFO - Average loss from batch 5601 to 5650 is 5.574540205
2018-04-18 01:50:11,484 - brc - INFO - Average loss from batch 5651 to 5700 is 5.47107321739
2018-04-18 01:52:08,530 - brc - INFO - Average loss from batch 5701 to 5750 is 5.65766206741
2018-04-18 01:54:06,495 - brc - INFO - Average loss from batch 5751 to 5800 is 5.5162280941
2018-04-18 01:56:02,491 - brc - INFO - Average loss from batch 5801 to 5850 is 5.56617577553
2018-04-18 01:57:58,155 - brc - INFO - Average loss from batch 5851 to 5900 is 5.38735376358
2018-04-18 02:00:35,010 - brc - INFO - Average loss from batch 5901 to 5950 is 5.60281141281
2018-04-18 02:02:31,151 - brc - INFO - Average loss from batch 5951 to 6000 is 5.59863908768
2018-04-18 02:03:47,614 - brc - INFO - Evaluating the model ...
2018-04-18 02:21:46,778 - brc - INFO - Dev eval loss 8.09354494476
2018-04-18 02:21:46,780 - brc - INFO - Dev eval result: {'BLEU-4': 38.46, 'ROUGE-L': 46.48}
2018-04-18 02:21:54,218 - brc - INFO - Model saved in model/, with prefix BIDAF.
2018-04-18 02:22:33,497 - brc - INFO - Average loss from batch 6001 to 6050 is 5.56858594894
2018-04-18 02:24:30,917 - brc - INFO - Average loss from batch 6051 to 6100 is 5.50263141632
2018-04-18 02:26:28,333 - brc - INFO - Average loss from batch 6101 to 6150 is 5.58977131844
2018-04-18 02:28:27,075 - brc - INFO - Average loss from batch 6151 to 6200 is 5.48082940102
2018-04-18 02:30:24,086 - brc - INFO - Average loss from batch 6201 to 6250 is 5.47244681358
2018-04-18 02:33:01,167 - brc - INFO - Average loss from batch 6251 to 6300 is 5.4639751339
2018-04-18 02:34:58,398 - brc - INFO - Average loss from batch 6301 to 6350 is 5.606560812
2018-04-18 02:36:55,600 - brc - INFO - Average loss from batch 6351 to 6400 is 5.49367972374
2018-04-18 02:38:51,080 - brc - INFO - Average loss from batch 6401 to 6450 is 5.55220301628
2018-04-18 02:40:47,717 - brc - INFO - Average loss from batch 6451 to 6500 is 5.5031883812
2018-04-18 02:42:42,901 - brc - INFO - Average loss from batch 6501 to 6550 is 5.44232170105
2018-04-18 02:44:38,883 - brc - INFO - Average loss from batch 6551 to 6600 is 5.60141275406
2018-04-18 02:46:35,056 - brc - INFO - Average loss from batch 6601 to 6650 is 5.49902714729
2018-04-18 02:48:30,326 - brc - INFO - Average loss from batch 6651 to 6700 is 5.3869844389
2018-04-18 02:50:25,708 - brc - INFO - Average loss from batch 6701 to 6750 is 5.38880214691
2018-04-18 02:52:21,182 - brc - INFO - Average loss from batch 6751 to 6800 is 5.34107563019
2018-04-18 02:54:18,415 - brc - INFO - Average loss from batch 6801 to 6850 is 5.43778945923
2018-04-18 02:56:14,471 - brc - INFO - Average loss from batch 6851 to 6900 is 5.48308149338
2018-04-18 02:58:51,607 - brc - INFO - Average loss from batch 6901 to 6950 is 5.30685067177
2018-04-18 03:00:48,291 - brc - INFO - Average loss from batch 6951 to 7000 is 5.54324784279
2018-04-18 03:02:44,319 - brc - INFO - Average loss from batch 7001 to 7050 is 5.43853905678
2018-04-18 03:04:41,219 - brc - INFO - Average loss from batch 7051 to 7100 is 5.52436673164
2018-04-18 03:06:37,709 - brc - INFO - Average loss from batch 7101 to 7150 is 5.49015626907
2018-04-18 03:08:34,297 - brc - INFO - Average loss from batch 7151 to 7200 is 5.36572201729
2018-04-18 03:10:29,208 - brc - INFO - Average loss from batch 7201 to 7250 is 5.46361318588
2018-04-18 03:12:25,355 - brc - INFO - Average loss from batch 7251 to 7300 is 5.42906573296
2018-04-18 03:14:20,929 - brc - INFO - Average loss from batch 7301 to 7350 is 5.62481772423
2018-04-18 03:16:17,098 - brc - INFO - Average loss from batch 7351 to 7400 is 5.37756371498
2018-04-18 03:18:12,793 - brc - INFO - Average loss from batch 7401 to 7450 is 5.44627414703
2018-04-18 03:20:07,436 - brc - INFO - Average loss from batch 7451 to 7500 is 5.48203946114
2018-04-18 03:22:02,091 - brc - INFO - Average loss from batch 7501 to 7550 is 5.38235013962
2018-04-18 03:24:38,504 - brc - INFO - Average loss from batch 7551 to 7600 is 5.40934364319
2018-04-18 03:26:35,273 - brc - INFO - Average loss from batch 7601 to 7650 is 5.45958607674
2018-04-18 03:28:31,536 - brc - INFO - Average loss from batch 7651 to 7700 is 5.39087613106
2018-04-18 03:30:27,165 - brc - INFO - Average loss from batch 7701 to 7750 is 5.36579025269
2018-04-18 03:32:22,924 - brc - INFO - Average loss from batch 7751 to 7800 is 5.49924895287
2018-04-18 03:34:17,834 - brc - INFO - Average loss from batch 7801 to 7850 is 5.37172370911
2018-04-18 03:36:14,070 - brc - INFO - Average loss from batch 7851 to 7900 is 5.61459305763
2018-04-18 03:38:10,260 - brc - INFO - Average loss from batch 7901 to 7950 is 5.39173886299
2018-04-18 03:40:05,255 - brc - INFO - Average loss from batch 7951 to 8000 is 5.37529616356
2018-04-18 03:41:47,334 - brc - INFO - Evaluating the model ...
2018-04-18 04:00:33,761 - brc - INFO - Dev eval loss 7.88214730072
2018-04-18 04:00:33,763 - brc - INFO - Dev eval result: {'BLEU-4': 38.62, 'ROUGE-L': 47.18}
2018-04-18 04:00:40,036 - brc - INFO - Model saved in model/, with prefix BIDAF.
2018-04-18 04:00:44,574 - brc - INFO - Average train loss for epoch 1 is 5.66407125716
2018-04-18 04:00:45,726 - brc - INFO - Evaluating the model after epoch 1
2018-04-18 04:18:34,436 - brc - INFO - Dev eval loss 7.88199060516
2018-04-18 04:18:34,439 - brc - INFO - Dev eval result: {'BLEU-4': 38.62, 'ROUGE-L': 47.09}
2018-04-18 04:18:34,440 - brc - INFO - Training the model for epoch 2
2018-04-18 04:20:31,444 - brc - INFO - Average loss from batch 1 to 50 is 5.33492940903
2018-04-18 04:22:30,487 - brc - INFO - Average loss from batch 51 to 100 is 5.31860260963
2018-04-18 04:24:29,962 - brc - INFO - Average loss from batch 101 to 150 is 5.34042222023
2018-04-18 04:26:28,665 - brc - INFO - Average loss from batch 151 to 200 is 5.25706399441
2018-04-18 04:28:28,422 - brc - INFO - Average loss from batch 201 to 250 is 5.37544687271
2018-04-18 04:31:10,928 - brc - INFO - Average loss from batch 251 to 300 is 5.26987288475
2018-04-18 04:33:11,091 - brc - INFO - Average loss from batch 301 to 350 is 5.27837553978
2018-04-18 04:35:10,792 - brc - INFO - Average loss from batch 351 to 400 is 5.30140566826
2018-04-18 04:37:11,276 - brc - INFO - Average loss from batch 401 to 450 is 5.4064743042
2018-04-18 04:39:10,064 - brc - INFO - Average loss from batch 451 to 500 is 5.51006982803
2018-04-18 04:41:10,998 - brc - INFO - Average loss from batch 501 to 550 is 5.48469417572
2018-04-18 04:43:09,890 - brc - INFO - Average loss from batch 551 to 600 is 5.44537769318
2018-04-18 04:45:10,639 - brc - INFO - Average loss from batch 601 to 650 is 5.37529613495
2018-04-18 04:47:11,075 - brc - INFO - Average loss from batch 651 to 700 is 5.40552612305
2018-04-18 04:49:11,683 - brc - INFO - Average loss from batch 701 to 750 is 5.3172191143
2018-04-18 04:51:11,547 - brc - INFO - Average loss from batch 751 to 800 is 5.37113728523
2018-04-18 04:53:10,486 - brc - INFO - Average loss from batch 801 to 850 is 5.40756708145
2018-04-18 04:55:09,905 - brc - INFO - Average loss from batch 851 to 900 is 5.2734895277
2018-04-18 04:57:53,352 - brc - INFO - Average loss from batch 901 to 950 is 5.36125644684
2018-04-18 04:59:53,273 - brc - INFO - Average loss from batch 951 to 1000 is 5.39383146286
2018-04-18 05:01:54,568 - brc - INFO - Average loss from batch 1001 to 1050 is 5.33647651672
2018-04-18 05:03:56,197 - brc - INFO - Average loss from batch 1051 to 1100 is 5.34070500374
2018-04-18 05:05:55,796 - brc - INFO - Average loss from batch 1101 to 1150 is 5.18326853752
2018-04-18 05:07:56,948 - brc - INFO - Average loss from batch 1151 to 1200 is 5.24163507462
2018-04-18 05:09:56,557 - brc - INFO - Average loss from batch 1201 to 1250 is 5.40012125015
2018-04-18 05:11:56,458 - brc - INFO - Average loss from batch 1251 to 1300 is 5.44706170082
2018-04-18 05:13:56,730 - brc - INFO - Average loss from batch 1301 to 1350 is 5.31960896492
2018-04-18 05:15:57,451 - brc - INFO - Average loss from batch 1351 to 1400 is 5.35315635681
2018-04-18 05:17:57,320 - brc - INFO - Average loss from batch 1401 to 1450 is 5.37819691658
2018-04-18 05:19:59,397 - brc - INFO - Average loss from batch 1451 to 1500 is 5.34737169266
2018-04-18 05:22:00,172 - brc - INFO - Average loss from batch 1501 to 1550 is 5.44172430992
2018-04-18 05:24:01,364 - brc - INFO - Average loss from batch 1551 to 1600 is 5.43161726952
2018-04-18 05:26:47,436 - brc - INFO - Average loss from batch 1601 to 1650 is 5.37069832802
2018-04-18 05:28:48,674 - brc - INFO - Average loss from batch 1651 to 1700 is 5.36838802338
2018-04-18 05:30:49,845 - brc - INFO - Average loss from batch 1701 to 1750 is 5.43438240051
2018-04-18 05:32:49,084 - brc - INFO - Average loss from batch 1751 to 1800 is 5.292504673
2018-04-18 05:34:47,624 - brc - INFO - Average loss from batch 1801 to 1850 is 5.30744057655
2018-04-18 05:36:46,670 - brc - INFO - Average loss from batch 1851 to 1900 is 5.44425035477
2018-04-18 05:38:45,945 - brc - INFO - Average loss from batch 1901 to 1950 is 5.28457201004
2018-04-18 05:40:45,087 - brc - INFO - Average loss from batch 1951 to 2000 is 5.53300619125
2018-04-18 05:41:11,316 - brc - INFO - Evaluating the model ...
2018-04-18 06:00:24,872 - brc - INFO - Dev eval loss 8.17436183929
2018-04-18 06:00:24,873 - brc - INFO - Dev eval result: {'BLEU-4': 38.32, 'ROUGE-L': 46.98}
2018-04-18 06:01:57,843 - brc - INFO - Average loss from batch 2001 to 2050 is 5.41336192131
2018-04-18 06:03:58,780 - brc - INFO - Average loss from batch 2051 to 2100 is 5.32412085533
2018-04-18 06:05:59,151 - brc - INFO - Average loss from batch 2101 to 2150 is 5.34437909126
2018-04-18 06:07:59,616 - brc - INFO - Average loss from batch 2151 to 2200 is 5.41297506809
2018-04-18 06:09:59,510 - brc - INFO - Average loss from batch 2201 to 2250 is 5.27198669434
2018-04-18 06:11:59,298 - brc - INFO - Average loss from batch 2251 to 2300 is 5.25650137901
2018-04-18 06:14:00,127 - brc - INFO - Average loss from batch 2301 to 2350 is 5.30654459953
2018-04-18 06:15:59,756 - brc - INFO - Average loss from batch 2351 to 2400 is 5.23795048714
2018-04-18 06:17:59,357 - brc - INFO - Average loss from batch 2401 to 2450 is 5.38442008972
2018-04-18 06:19:59,403 - brc - INFO - Average loss from batch 2451 to 2500 is 5.40195556641
2018-04-18 06:21:59,350 - brc - INFO - Average loss from batch 2501 to 2550 is 5.35593610764
2018-04-18 06:23:59,776 - brc - INFO - Average loss from batch 2551 to 2600 is 5.34465492249
2018-04-18 06:26:00,314 - brc - INFO - Average loss from batch 2601 to 2650 is 5.34883215904
2018-04-18 06:28:47,240 - brc - INFO - Average loss from batch 2651 to 2700 is 5.32572991371
2018-04-18 06:30:49,406 - brc - INFO - Average loss from batch 2701 to 2750 is 5.44183960915
2018-04-18 06:32:50,727 - brc - INFO - Average loss from batch 2751 to 2800 is 5.34913880348
2018-04-18 06:34:51,365 - brc - INFO - Average loss from batch 2801 to 2850 is 5.41212341309
2018-04-18 06:36:51,211 - brc - INFO - Average loss from batch 2851 to 2900 is 5.35226120949
2018-04-18 06:38:51,841 - brc - INFO - Average loss from batch 2901 to 2950 is 5.4927208519
2018-04-18 06:40:52,156 - brc - INFO - Average loss from batch 2951 to 3000 is 5.29492686272
2018-04-18 06:42:52,806 - brc - INFO - Average loss from batch 3001 to 3050 is 5.33740276337
2018-04-18 06:44:52,633 - brc - INFO - Average loss from batch 3051 to 3100 is 5.39150870323
2018-04-18 06:46:54,002 - brc - INFO - Average loss from batch 3101 to 3150 is 5.37338015556
2018-04-18 06:48:54,497 - brc - INFO - Average loss from batch 3151 to 3200 is 5.35406513214
2018-04-18 06:50:55,393 - brc - INFO - Average loss from batch 3201 to 3250 is 5.24642918587
2018-04-18 06:52:55,935 - brc - INFO - Average loss from batch 3251 to 3300 is 5.27606116295
2018-04-18 06:55:41,651 - brc - INFO - Average loss from batch 3301 to 3350 is 5.46697218418
2018-04-18 06:57:41,632 - brc - INFO - Average loss from batch 3351 to 3400 is 5.30286131859
2018-04-18 06:59:42,250 - brc - INFO - Average loss from batch 3401 to 3450 is 5.33476875305
2018-04-18 07:01:42,623 - brc - INFO - Average loss from batch 3451 to 3500 is 5.32730782509
2018-04-18 07:03:42,985 - brc - INFO - Average loss from batch 3501 to 3550 is 5.28696954727
2018-04-18 07:05:43,312 - brc - INFO - Average loss from batch 3551 to 3600 is 5.22191779137
2018-04-18 07:07:43,739 - brc - INFO - Average loss from batch 3601 to 3650 is 5.54320632935
2018-04-18 07:09:43,522 - brc - INFO - Average loss from batch 3651 to 3700 is 5.352042799
2018-04-18 07:11:43,311 - brc - INFO - Average loss from batch 3701 to 3750 is 5.2767062664
2018-04-18 07:13:43,786 - brc - INFO - Average loss from batch 3751 to 3800 is 5.27880516052
2018-04-18 07:15:42,935 - brc - INFO - Average loss from batch 3801 to 3850 is 5.33876779556
2018-04-18 07:17:42,919 - brc - INFO - Average loss from batch 3851 to 3900 is 5.41298604965
2018-04-18 07:19:42,767 - brc - INFO - Average loss from batch 3901 to 3950 is 5.26980670929
2018-04-18 07:21:41,912 - brc - INFO - Average loss from batch 3951 to 4000 is 5.30247810364
2018-04-18 07:22:34,586 - brc - INFO - Evaluating the model ...
2018-04-18 07:42:13,000 - brc - INFO - Dev eval loss 8.19867200241
2018-04-18 07:42:13,002 - brc - INFO - Dev eval result: {'BLEU-4': 38.11, 'ROUGE-L': 47.12}
2018-04-18 07:43:18,334 - brc - INFO - Average loss from batch 4001 to 4050 is 5.31681611061
2018-04-18 07:45:19,390 - brc - INFO - Average loss from batch 4051 to 4100 is 5.31826034546
2018-04-18 07:47:17,946 - brc - INFO - Average loss from batch 4101 to 4150 is 5.19470906258
2018-04-18 07:49:16,428 - brc - INFO - Average loss from batch 4151 to 4200 is 5.25368208885
2018-04-18 07:51:14,497 - brc - INFO - Average loss from batch 4201 to 4250 is 5.26331785679
2018-04-18 07:53:14,121 - brc - INFO - Average loss from batch 4251 to 4300 is 5.43155146599
2018-04-18 07:55:14,472 - brc - INFO - Average loss from batch 4301 to 4350 is 5.46716592789
2018-04-18 07:58:01,037 - brc - INFO - Average loss from batch 4351 to 4400 is 5.24544977188
2018-04-18 08:00:02,863 - brc - INFO - Average loss from batch 4401 to 4450 is 5.15409664154
2018-04-18 08:02:03,213 - brc - INFO - Average loss from batch 4451 to 4500 is 5.30001456261
2018-04-18 08:04:04,269 - brc - INFO - Average loss from batch 4501 to 4550 is 5.28361301422
2018-04-18 08:06:04,120 - brc - INFO - Average loss from batch 4551 to 4600 is 5.28894735336
2018-04-18 08:08:04,413 - brc - INFO - Average loss from batch 4601 to 4650 is 5.19271925926
2018-04-18 08:10:03,505 - brc - INFO - Average loss from batch 4651 to 4700 is 5.32048862457
2018-04-18 08:12:03,699 - brc - INFO - Average loss from batch 4701 to 4750 is 5.36381534576
2018-04-18 08:14:03,713 - brc - INFO - Average loss from batch 4751 to 4800 is 5.24678659916
2018-04-18 08:16:03,607 - brc - INFO - Average loss from batch 4801 to 4850 is 5.41957447052
2018-04-18 08:18:03,404 - brc - INFO - Average loss from batch 4851 to 4900 is 5.52339981079
2018-04-18 08:20:03,716 - brc - INFO - Average loss from batch 4901 to 4950 is 5.44596123695
2018-04-18 08:22:04,050 - brc - INFO - Average loss from batch 4951 to 5000 is 5.48434907913
2018-04-18 08:24:03,186 - brc - INFO - Average loss from batch 5001 to 5050 is 5.35926083565
2018-04-18 08:26:50,120 - brc - INFO - Average loss from batch 5051 to 5100 is 5.36237399101
2018-04-18 08:28:51,959 - brc - INFO - Average loss from batch 5101 to 5150 is 5.29555089951
2018-04-18 08:30:54,049 - brc - INFO - Average loss from batch 5151 to 5200 is 5.36096868515
2018-04-18 08:32:54,763 - brc - INFO - Average loss from batch 5201 to 5250 is 5.24707438469
2018-04-18 08:34:55,806 - brc - INFO - Average loss from batch 5251 to 5300 is 5.29693324089
2018-04-18 08:36:55,994 - brc - INFO - Average loss from batch 5301 to 5350 is 5.39006204605
2018-04-18 08:38:56,103 - brc - INFO - Average loss from batch 5351 to 5400 is 5.35437609673
2018-04-18 08:40:56,687 - brc - INFO - Average loss from batch 5401 to 5450 is 5.36277526855
2018-04-18 08:42:58,204 - brc - INFO - Average loss from batch 5451 to 5500 is 5.25099527359
2018-04-18 08:44:59,611 - brc - INFO - Average loss from batch 5501 to 5550 is 5.36518286705
2018-04-18 08:47:00,173 - brc - INFO - Average loss from batch 5551 to 5600 is 5.28002892494
2018-04-18 08:49:01,122 - brc - INFO - Average loss from batch 5601 to 5650 is 5.3188458252
2018-04-18 08:51:02,143 - brc - INFO - Average loss from batch 5651 to 5700 is 5.40229891777
2018-04-18 08:53:51,628 - brc - INFO - Average loss from batch 5701 to 5750 is 5.260248909
2018-04-18 08:55:53,220 - brc - INFO - Average loss from batch 5751 to 5800 is 5.47184654236
2018-04-18 08:57:54,873 - brc - INFO - Average loss from batch 5801 to 5850 is 5.34539745331
2018-04-18 08:59:56,480 - brc - INFO - Average loss from batch 5851 to 5900 is 5.42574255943
2018-04-18 09:01:57,695 - brc - INFO - Average loss from batch 5901 to 5950 is 5.42967425346
2018-04-18 09:03:58,938 - brc - INFO - Average loss from batch 5951 to 6000 is 5.48546550751
2018-04-18 09:05:18,106 - brc - INFO - Evaluating the model ...
2018-04-18 09:24:04,021 - brc - INFO - Dev eval loss 8.01905863342
2018-04-18 09:24:04,024 - brc - INFO - Dev eval result: {'BLEU-4': 39.29, 'ROUGE-L': 47.87}
2018-04-18 09:24:10,125 - brc - INFO - Model saved in model/, with prefix BIDAF.
2018-04-18 09:24:49,778 - brc - INFO - Average loss from batch 6001 to 6050 is 5.34320296288
2018-04-18 09:27:41,076 - brc - INFO - Average loss from batch 6051 to 6100 is 5.40867473125
2018-04-18 09:29:41,706 - brc - INFO - Average loss from batch 6101 to 6150 is 5.41209336281
2018-04-18 09:31:43,366 - brc - INFO - Average loss from batch 6151 to 6200 is 5.25125982285
2018-04-18 09:33:44,731 - brc - INFO - Average loss from batch 6201 to 6250 is 5.30539908409
2018-04-18 09:35:45,708 - brc - INFO - Average loss from batch 6251 to 6300 is 5.32892992973
2018-04-18 09:37:46,376 - brc - INFO - Average loss from batch 6301 to 6350 is 5.30844152927
2018-04-18 09:39:47,890 - brc - INFO - Average loss from batch 6351 to 6400 is 5.38500228882
2018-04-18 09:41:47,291 - brc - INFO - Average loss from batch 6401 to 6450 is 5.35645092964
2018-04-18 09:43:47,247 - brc - INFO - Average loss from batch 6451 to 6500 is 5.35030948639
2018-04-18 09:45:47,801 - brc - INFO - Average loss from batch 6501 to 6550 is 5.28615893364
2018-04-18 09:47:49,404 - brc - INFO - Average loss from batch 6551 to 6600 is 5.26168805122
2018-04-18 09:49:50,681 - brc - INFO - Average loss from batch 6601 to 6650 is 5.26530503273
2018-04-18 09:51:52,367 - brc - INFO - Average loss from batch 6651 to 6700 is 5.34764688492
2018-04-18 09:53:53,485 - brc - INFO - Average loss from batch 6701 to 6750 is 5.28236381531
2018-04-18 09:56:40,499 - brc - INFO - Average loss from batch 6751 to 6800 is 5.21369242668
2018-04-18 09:58:42,319 - brc - INFO - Average loss from batch 6801 to 6850 is 5.36640129089
2018-04-18 10:00:44,132 - brc - INFO - Average loss from batch 6851 to 6900 is 5.32622455597
2018-04-18 10:02:45,555 - brc - INFO - Average loss from batch 6901 to 6950 is 5.18704761505
2018-04-18 10:04:44,977 - brc - INFO - Average loss from batch 6951 to 7000 is 5.27452256203
2018-04-18 10:06:44,914 - brc - INFO - Average loss from batch 7001 to 7050 is 5.26193306923
2018-04-18 10:08:43,743 - brc - INFO - Average loss from batch 7051 to 7100 is 5.38398398399
2018-04-18 10:10:43,600 - brc - INFO - Average loss from batch 7101 to 7150 is 5.30142745972
2018-04-18 10:12:44,557 - brc - INFO - Average loss from batch 7151 to 7200 is 5.34215498924
2018-04-18 10:14:44,838 - brc - INFO - Average loss from batch 7201 to 7250 is 5.32302804947
2018-04-18 10:16:45,748 - brc - INFO - Average loss from batch 7251 to 7300 is 5.34096467018
2018-04-18 10:18:46,482 - brc - INFO - Average loss from batch 7301 to 7350 is 5.38120897293
2018-04-18 10:20:46,172 - brc - INFO - Average loss from batch 7351 to 7400 is 5.2483779335
2018-04-18 10:22:46,906 - brc - INFO - Average loss from batch 7401 to 7450 is 5.24182267189
2018-04-18 10:25:36,875 - brc - INFO - Average loss from batch 7451 to 7500 is 5.27058377266
2018-04-18 10:27:38,609 - brc - INFO - Average loss from batch 7501 to 7550 is 5.29450305939
2018-04-18 10:29:39,634 - brc - INFO - Average loss from batch 7551 to 7600 is 5.36732257843
2018-04-18 10:31:40,430 - brc - INFO - Average loss from batch 7601 to 7650 is 5.31161413193
2018-04-18 10:33:40,732 - brc - INFO - Average loss from batch 7651 to 7700 is 5.4974108696
2018-04-18 10:35:40,859 - brc - INFO - Average loss from batch 7701 to 7750 is 5.21860890388
2018-04-18 10:37:40,513 - brc - INFO - Average loss from batch 7751 to 7800 is 5.38122498512
2018-04-18 10:39:41,555 - brc - INFO - Average loss from batch 7801 to 7850 is 5.2968861866
2018-04-18 10:41:42,376 - brc - INFO - Average loss from batch 7851 to 7900 is 5.32711039543
2018-04-18 10:43:43,437 - brc - INFO - Average loss from batch 7901 to 7950 is 5.25984786987
2018-04-18 10:45:43,543 - brc - INFO - Average loss from batch 7951 to 8000 is 5.34095529079
2018-04-18 10:47:30,112 - brc - INFO - Evaluating the model ...
2018-04-18 11:06:54,782 - brc - INFO - Dev eval loss 8.11130688629
2018-04-18 11:06:54,784 - brc - INFO - Dev eval result: {'BLEU-4': 39.31, 'ROUGE-L': 47.84}
2018-04-18 11:06:59,281 - brc - INFO - Average train loss for epoch 2 is 5.34030819652
2018-04-18 11:06:59,291 - brc - INFO - Evaluating the model after epoch 2
2018-04-18 11:25:10,963 - brc - INFO - Dev eval loss 8.0963453125
2018-04-18 11:25:10,963 - brc - INFO - Dev eval result: {'BLEU-4': 39.54, 'ROUGE-L': 47.81}
2018-04-18 11:25:10,965 - brc - INFO - Training the model for epoch 3
2018-04-18 11:27:10,774 - brc - INFO - Average loss from batch 1 to 50 is 5.11732779503
2018-04-18 11:29:12,433 - brc - INFO - Average loss from batch 51 to 100 is 5.17198082924
2018-04-18 11:32:01,525 - brc - INFO - Average loss from batch 101 to 150 is 5.12950331688
2018-04-18 11:34:03,774 - brc - INFO - Average loss from batch 151 to 200 is 5.20782488823
2018-04-18 11:36:05,127 - brc - INFO - Average loss from batch 201 to 250 is 5.19292754173
2018-04-18 11:38:06,229 - brc - INFO - Average loss from batch 251 to 300 is 5.00854054451
2018-04-18 11:40:07,710 - brc - INFO - Average loss from batch 301 to 350 is 5.12682831287
2018-04-18 11:42:08,842 - brc - INFO - Average loss from batch 351 to 400 is 5.22221827507
2018-04-18 11:44:11,220 - brc - INFO - Average loss from batch 401 to 450 is 4.98905274391
2018-04-18 11:46:12,436 - brc - INFO - Average loss from batch 451 to 500 is 5.13700530052
2018-04-18 11:48:13,902 - brc - INFO - Average loss from batch 501 to 550 is 5.10333323479
2018-04-18 11:50:14,760 - brc - INFO - Average loss from batch 551 to 600 is 5.21767848015
2018-04-18 11:52:16,686 - brc - INFO - Average loss from batch 601 to 650 is 5.10867702484
2018-04-18 11:54:17,170 - brc - INFO - Average loss from batch 651 to 700 is 5.17991029739
2018-04-18 11:56:18,391 - brc - INFO - Average loss from batch 701 to 750 is 5.16746889591
2018-04-18 11:58:19,615 - brc - INFO - Average loss from batch 751 to 800 is 5.21431553841
2018-04-18 12:01:07,804 - brc - INFO - Average loss from batch 801 to 850 is 5.21273456573
2018-04-18 12:03:10,500 - brc - INFO - Average loss from batch 851 to 900 is 5.23193359375
2018-04-18 12:05:12,434 - brc - INFO - Average loss from batch 901 to 950 is 5.02559623718
2018-04-18 12:07:13,096 - brc - INFO - Average loss from batch 951 to 1000 is 5.17847856522
2018-04-18 12:09:14,295 - brc - INFO - Average loss from batch 1001 to 1050 is 5.2343371439
2018-04-18 12:11:15,558 - brc - INFO - Average loss from batch 1051 to 1100 is 5.1400261116
2018-04-18 12:13:15,894 - brc - INFO - Average loss from batch 1101 to 1150 is 5.19911474228
2018-04-18 12:15:17,197 - brc - INFO - Average loss from batch 1151 to 1200 is 5.20050647259
2018-04-18 12:17:18,701 - brc - INFO - Average loss from batch 1201 to 1250 is 5.19511413574
2018-04-18 12:19:20,530 - brc - INFO - Average loss from batch 1251 to 1300 is 5.16796175003
2018-04-18 12:21:22,091 - brc - INFO - Average loss from batch 1301 to 1350 is 5.25673354149
2018-04-18 12:23:23,433 - brc - INFO - Average loss from batch 1351 to 1400 is 5.16021386147
2018-04-18 12:25:23,462 - brc - INFO - Average loss from batch 1401 to 1450 is 5.09948310375
2018-04-18 12:28:10,283 - brc - INFO - Average loss from batch 1451 to 1500 is 5.17078972816
2018-04-18 12:30:11,696 - brc - INFO - Average loss from batch 1501 to 1550 is 5.22648375511
2018-04-18 12:32:12,935 - brc - INFO - Average loss from batch 1551 to 1600 is 5.13013765335
2018-04-18 12:34:12,942 - brc - INFO - Average loss from batch 1601 to 1650 is 5.07818871975
2018-04-18 12:36:13,321 - brc - INFO - Average loss from batch 1651 to 1700 is 5.12221434593
2018-04-18 12:38:13,183 - brc - INFO - Average loss from batch 1701 to 1750 is 5.17636680603
2018-04-18 12:40:12,308 - brc - INFO - Average loss from batch 1751 to 1800 is 5.23271068573
2018-04-18 12:42:11,960 - brc - INFO - Average loss from batch 1801 to 1850 is 5.17664548874
2018-04-18 12:44:10,908 - brc - INFO - Average loss from batch 1851 to 1900 is 5.199161129
2018-04-18 12:46:11,090 - brc - INFO - Average loss from batch 1901 to 1950 is 5.17438650131
2018-04-18 12:48:10,063 - brc - INFO - Average loss from batch 1951 to 2000 is 5.15716306686
2018-04-18 12:48:36,586 - brc - INFO - Evaluating the model ...
2018-04-18 13:07:52,978 - brc - INFO - Dev eval loss 8.07338010483
2018-04-18 13:07:52,980 - brc - INFO - Dev eval result: {'BLEU-4': 39.65, 'ROUGE-L': 47.94}
2018-04-18 13:07:58,934 - brc - INFO - Model saved in model/, with prefix BIDAF.
2018-04-18 13:09:32,197 - brc - INFO - Average loss from batch 2001 to 2050 is 5.33847100258
2018-04-18 13:11:32,915 - brc - INFO - Average loss from batch 2051 to 2100 is 5.19943047523
2018-04-18 13:13:33,226 - brc - INFO - Average loss from batch 2101 to 2150 is 5.12552034378
2018-04-18 13:15:33,513 - brc - INFO - Average loss from batch 2151 to 2200 is 5.13402916908
2018-04-18 13:17:33,089 - brc - INFO - Average loss from batch 2201 to 2250 is 5.06758534431
2018-04-18 13:19:33,175 - brc - INFO - Average loss from batch 2251 to 2300 is 5.12672118187
2018-04-18 13:21:33,340 - brc - INFO - Average loss from batch 2301 to 2350 is 5.28094566345
2018-04-18 13:23:33,113 - brc - INFO - Average loss from batch 2351 to 2400 is 5.36012822151
2018-04-18 13:25:33,131 - brc - INFO - Average loss from batch 2401 to 2450 is 5.15907056808
2018-04-18 13:27:33,871 - brc - INFO - Average loss from batch 2451 to 2500 is 5.20583141327
2018-04-18 13:30:21,028 - brc - INFO - Average loss from batch 2501 to 2550 is 5.11485496521
2018-04-18 13:32:21,596 - brc - INFO - Average loss from batch 2551 to 2600 is 5.23786743164
2018-04-18 13:34:21,747 - brc - INFO - Average loss from batch 2601 to 2650 is 5.26586871147
2018-04-18 13:36:22,213 - brc - INFO - Average loss from batch 2651 to 2700 is 5.11743228912
2018-04-18 13:38:21,988 - brc - INFO - Average loss from batch 2701 to 2750 is 5.24970803261
2018-04-18 13:40:22,536 - brc - INFO - Average loss from batch 2751 to 2800 is 5.14059389114
2018-04-18 13:42:22,547 - brc - INFO - Average loss from batch 2801 to 2850 is 5.37520551682
2018-04-18 13:44:22,636 - brc - INFO - Average loss from batch 2851 to 2900 is 5.10215572357
2018-04-18 13:46:21,357 - brc - INFO - Average loss from batch 2901 to 2950 is 5.18457538128
2018-04-18 13:48:21,774 - brc - INFO - Average loss from batch 2951 to 3000 is 5.2959469986
2018-04-18 13:50:21,411 - brc - INFO - Average loss from batch 3001 to 3050 is 5.19773140907
2018-04-18 13:52:21,917 - brc - INFO - Average loss from batch 3051 to 3100 is 5.19921704292
2018-04-18 13:54:23,369 - brc - INFO - Average loss from batch 3101 to 3150 is 5.24816105843
2018-04-18 13:56:25,850 - brc - INFO - Average loss from batch 3151 to 3200 is 5.16218251228
2018-04-18 13:59:27,773 - brc - INFO - Average loss from batch 3201 to 3250 is 5.17911616325
2018-04-18 14:01:29,802 - brc - INFO - Average loss from batch 3251 to 3300 is 5.32302142143
2018-04-18 14:03:33,053 - brc - INFO - Average loss from batch 3301 to 3350 is 5.15696187973
2018-04-18 14:05:37,110 - brc - INFO - Average loss from batch 3351 to 3400 is 5.1922149086
2018-04-18 14:07:41,006 - brc - INFO - Average loss from batch 3401 to 3450 is 5.2319983387
2018-04-18 14:09:43,360 - brc - INFO - Average loss from batch 3451 to 3500 is 5.17252578735
2018-04-18 14:14:08,145 - brc - INFO - Running with args : Namespace(algo='BIDAF', batch_size=32, brc_dir='model/', char_embed='../../data/embedding/wiki_brc/wiki_brc.char.vec', char_hidden_size=100, dev_files=['../../data/preprocessed_ltp/devset/search.dev.filter.json', '../../data/preprocessed_ltp/devset/zhidao.dev.filter.json'], dropout_keep_prob=1, epochs=10, evaluate=False, gpu='0', hidden_size=150, learning_rate=0.0001, log_path='model/log', max_a_len=500, max_p_len=500, max_p_num=5, max_q_len=60, max_w_len=4, model_dir='model/', optim='adam', pos_embed_dim=10, pr_rate=0.2, predict=False, prepare=False, restore=True, result_dir='model/', summary_dir='model/', test_files=['../../data/test1set/preprocessed/search.test1.json', '../../data/test1set/preprocessed/zhidao.test1.json'], train=True, train_files=['../../data/preprocessed_ltp/trainset/search.train.filter.json', '../../data/preprocessed_ltp/trainset/zhidao.train.filter.json'], vocab_dir='model/', weight_decay=0, word_embed='../../data/embedding/wiki_brc/wiki_brc.word.vec')
2018-04-18 14:14:08,183 - brc - INFO - Load data_set and vocab...
2018-04-18 14:20:17,016 - brc - INFO - Train set size: 257469 questions.
2018-04-18 14:21:16,152 - brc - INFO - Dev set size: 10000 questions.
2018-04-18 14:21:16,152 - brc - INFO - Converting text into ids...
2018-04-18 14:31:09,053 - brc - INFO - Initialize the model...
2018-04-18 14:31:16,379 - brc - INFO - Time to build graph: 5.94795298576 s
2018-04-18 14:31:33,762 - brc - INFO - There are 3865506 parameters in the model
2018-04-18 14:31:36,790 - brc - INFO - Restoring the model...
2018-04-18 14:31:37,906 - brc - INFO - Model restored from model/, with prefix BIDAF
2018-04-18 14:31:37,906 - brc - INFO - Evaluating the model on dev set...
2018-04-18 14:58:19,615 - brc - INFO - Training the model...
2018-04-18 14:58:19,615 - brc - INFO - Training the model for epoch 1
2018-04-18 15:00:15,527 - brc - INFO - Average loss from batch 1 to 50 is 5.06189766407
2018-04-18 15:02:13,742 - brc - INFO - Average loss from batch 51 to 100 is 5.0306778717
2018-04-18 15:22:27,484 - brc - INFO - Average loss from batch 101 to 150 is 5.08040290833
2018-04-18 15:24:22,648 - brc - INFO - Average loss from batch 151 to 200 is 5.05213293076
2018-04-18 15:26:17,542 - brc - INFO - Average loss from batch 201 to 250 is 5.08065040588
2018-04-18 15:28:13,603 - brc - INFO - Average loss from batch 251 to 300 is 4.99599399567
2018-04-18 15:30:37,103 - brc - INFO - Average loss from batch 301 to 350 is 5.08804150581
2018-04-18 15:32:31,901 - brc - INFO - Average loss from batch 351 to 400 is 4.97020472527
2018-04-18 15:34:27,323 - brc - INFO - Average loss from batch 401 to 450 is 4.99883482456
2018-04-18 15:36:22,511 - brc - INFO - Average loss from batch 451 to 500 is 5.03782150269
2018-04-18 15:38:17,594 - brc - INFO - Average loss from batch 501 to 550 is 5.05632164955
2018-04-18 15:40:12,490 - brc - INFO - Average loss from batch 551 to 600 is 5.03065453529
2018-04-18 15:42:07,572 - brc - INFO - Average loss from batch 601 to 650 is 5.08341668129
2018-04-18 15:44:03,677 - brc - INFO - Average loss from batch 651 to 700 is 5.07490222931
2018-04-18 15:45:58,206 - brc - INFO - Average loss from batch 701 to 750 is 5.02991480827
2018-04-18 15:47:53,251 - brc - INFO - Average loss from batch 751 to 800 is 5.09353292465
2018-04-18 15:49:48,464 - brc - INFO - Average loss from batch 801 to 850 is 5.03204583168
2018-04-18 15:51:43,622 - brc - INFO - Average loss from batch 851 to 900 is 5.01948957443
2018-04-18 15:53:39,855 - brc - INFO - Average loss from batch 901 to 950 is 4.89675581455
2018-04-18 15:56:06,485 - brc - INFO - Average loss from batch 951 to 1000 is 5.04451126575
2018-04-18 15:58:04,621 - brc - INFO - Average loss from batch 1001 to 1050 is 5.01591230869
2018-04-18 16:00:01,497 - brc - INFO - Average loss from batch 1051 to 1100 is 5.07163417339
2018-04-18 16:01:58,222 - brc - INFO - Average loss from batch 1101 to 1150 is 5.00340799809
2018-04-18 16:03:53,828 - brc - INFO - Average loss from batch 1151 to 1200 is 4.98185029984
2018-04-18 16:05:49,735 - brc - INFO - Average loss from batch 1201 to 1250 is 5.10103239059
2018-04-18 16:07:46,581 - brc - INFO - Average loss from batch 1251 to 1300 is 5.08225803375
2018-04-18 16:09:42,900 - brc - INFO - Average loss from batch 1301 to 1350 is 4.95245550632
2018-04-18 16:11:39,712 - brc - INFO - Average loss from batch 1351 to 1400 is 4.94046233177
2018-04-18 16:13:35,211 - brc - INFO - Average loss from batch 1401 to 1450 is 5.01835609436
2018-04-18 16:15:31,133 - brc - INFO - Average loss from batch 1451 to 1500 is 4.94891393661
2018-04-18 16:17:26,998 - brc - INFO - Average loss from batch 1501 to 1550 is 5.01728615761
2018-04-18 16:19:22,585 - brc - INFO - Average loss from batch 1551 to 1600 is 4.96869732857
2018-04-18 16:21:48,688 - brc - INFO - Average loss from batch 1601 to 1650 is 4.8605236721
2018-04-18 16:23:43,935 - brc - INFO - Average loss from batch 1651 to 1700 is 5.04658610344
2018-04-18 16:25:38,982 - brc - INFO - Average loss from batch 1701 to 1750 is 5.12072887421
2018-04-18 16:27:34,222 - brc - INFO - Average loss from batch 1751 to 1800 is 4.91771533966
2018-04-18 16:29:30,631 - brc - INFO - Average loss from batch 1801 to 1850 is 4.98175818443
2018-04-18 16:31:26,746 - brc - INFO - Average loss from batch 1851 to 1900 is 4.97228969097
2018-04-18 16:33:23,502 - brc - INFO - Average loss from batch 1901 to 1950 is 4.95314106941
2018-04-18 16:35:20,457 - brc - INFO - Average loss from batch 1951 to 2000 is 4.91723396778
2018-04-18 16:35:46,129 - brc - INFO - Evaluating the model ...
2018-04-18 16:54:12,320 - brc - INFO - Dev eval loss 8.21901166611
2018-04-18 16:54:12,343 - brc - INFO - Dev eval result: {'BLEU-4': 40.51, 'ROUGE-L': 48.29}
2018-04-18 16:54:21,449 - brc - INFO - Model saved in model/, with prefix BIDAF.
2018-04-18 17:11:37,627 - brc - INFO - Average loss from batch 2001 to 2050 is 5.08958028316
2018-04-18 17:13:34,590 - brc - INFO - Average loss from batch 2051 to 2100 is 5.01594907761
2018-04-18 17:15:30,489 - brc - INFO - Average loss from batch 2101 to 2150 is 4.99490162849
2018-04-18 17:17:25,238 - brc - INFO - Average loss from batch 2151 to 2200 is 5.0084671402
2018-04-18 17:19:23,786 - brc - INFO - Average loss from batch 2201 to 2250 is 4.8538232708
2018-04-18 17:21:26,281 - brc - INFO - Average loss from batch 2251 to 2300 is 5.02858047485
2018-04-18 17:23:30,811 - brc - INFO - Average loss from batch 2301 to 2350 is 5.06756505013
2018-04-18 17:25:41,914 - brc - INFO - Average loss from batch 2351 to 2400 is 4.94064526081
2018-04-18 17:27:43,426 - brc - INFO - Average loss from batch 2401 to 2450 is 4.87489116192
2018-04-18 17:29:45,274 - brc - INFO - Average loss from batch 2451 to 2500 is 5.04236575603
2018-04-18 17:31:44,582 - brc - INFO - Average loss from batch 2501 to 2550 is 5.01275802612
2018-04-18 17:33:40,590 - brc - INFO - Average loss from batch 2551 to 2600 is 5.0091105938
2018-04-18 17:36:11,206 - brc - INFO - Average loss from batch 2601 to 2650 is 5.05011310577
2018-04-18 17:38:06,511 - brc - INFO - Average loss from batch 2651 to 2700 is 5.02276488304
2018-04-18 17:40:02,050 - brc - INFO - Average loss from batch 2701 to 2750 is 5.01565671921
2018-04-18 17:41:58,311 - brc - INFO - Average loss from batch 2751 to 2800 is 4.99156424046
2018-04-18 17:43:57,179 - brc - INFO - Average loss from batch 2801 to 2850 is 5.00894217491
2018-04-18 17:45:53,606 - brc - INFO - Average loss from batch 2851 to 2900 is 4.91346206665
2018-04-18 17:47:50,467 - brc - INFO - Average loss from batch 2901 to 2950 is 4.96308855057
2018-04-18 17:49:46,594 - brc - INFO - Average loss from batch 2951 to 3000 is 5.14247118473
2018-04-18 17:51:43,900 - brc - INFO - Average loss from batch 3001 to 3050 is 5.05351565838
2018-04-18 17:53:40,785 - brc - INFO - Average loss from batch 3051 to 3100 is 4.95055572987
2018-04-18 17:55:35,872 - brc - INFO - Average loss from batch 3101 to 3150 is 4.98456398487
2018-04-18 17:57:29,884 - brc - INFO - Average loss from batch 3151 to 3200 is 5.04398853302
2018-04-18 17:59:24,673 - brc - INFO - Average loss from batch 3201 to 3250 is 4.91502930641
2018-04-18 18:01:56,568 - brc - INFO - Average loss from batch 3251 to 3300 is 4.90345166206
2018-04-18 18:03:53,756 - brc - INFO - Average loss from batch 3301 to 3350 is 4.92587175369
2018-04-18 18:05:47,982 - brc - INFO - Average loss from batch 3351 to 3400 is 4.91516373634
2018-04-18 18:07:44,075 - brc - INFO - Average loss from batch 3401 to 3450 is 4.9759348774
2018-04-18 18:09:41,305 - brc - INFO - Average loss from batch 3451 to 3500 is 4.90986171246
2018-04-18 18:11:36,806 - brc - INFO - Average loss from batch 3501 to 3550 is 4.96326719761
2018-04-18 18:13:33,176 - brc - INFO - Average loss from batch 3551 to 3600 is 4.90237847805
2018-04-18 18:15:27,446 - brc - INFO - Average loss from batch 3601 to 3650 is 4.88070588112
2018-04-18 18:17:23,099 - brc - INFO - Average loss from batch 3651 to 3700 is 4.95674812317
2018-04-18 18:19:18,921 - brc - INFO - Average loss from batch 3701 to 3750 is 5.00021515846
2018-04-18 18:21:15,105 - brc - INFO - Average loss from batch 3751 to 3800 is 4.91604254723
2018-04-18 18:23:12,337 - brc - INFO - Average loss from batch 3801 to 3850 is 4.95114256859
2018-04-18 18:25:09,250 - brc - INFO - Average loss from batch 3851 to 3900 is 4.91159827232
2018-04-18 18:27:40,558 - brc - INFO - Average loss from batch 3901 to 3950 is 4.95386623383
2018-04-18 18:29:36,295 - brc - INFO - Average loss from batch 3951 to 4000 is 4.93862739563
2018-04-18 18:30:26,678 - brc - INFO - Evaluating the model ...
2018-04-18 18:48:18,934 - brc - INFO - Dev eval loss 8.25839715805
2018-04-18 18:48:18,951 - brc - INFO - Dev eval result: {'BLEU-4': 40.63, 'ROUGE-L': 48.24}
2018-04-18 18:49:23,987 - brc - INFO - Average loss from batch 4001 to 4050 is 5.01232150555
2018-04-18 18:51:21,287 - brc - INFO - Average loss from batch 4051 to 4100 is 4.92683371544
2018-04-18 18:53:19,360 - brc - INFO - Average loss from batch 4101 to 4150 is 5.15622573853
2018-04-18 18:55:16,730 - brc - INFO - Average loss from batch 4151 to 4200 is 5.02682307243
2018-04-18 18:57:13,382 - brc - INFO - Average loss from batch 4201 to 4250 is 4.9335976553
2018-04-18 18:59:47,295 - brc - INFO - Average loss from batch 4251 to 4300 is 5.0129117012
2018-04-18 19:01:43,751 - brc - INFO - Average loss from batch 4301 to 4350 is 5.08954786777
2018-04-18 19:03:40,420 - brc - INFO - Average loss from batch 4351 to 4400 is 4.88789631367
2018-04-18 19:05:37,746 - brc - INFO - Average loss from batch 4401 to 4450 is 4.92505577564
2018-04-18 19:07:34,107 - brc - INFO - Average loss from batch 4451 to 4500 is 5.04321932793
2018-04-18 19:09:29,108 - brc - INFO - Average loss from batch 4501 to 4550 is 4.93995520592
2018-04-18 19:11:26,250 - brc - INFO - Average loss from batch 4551 to 4600 is 4.96959762096
2018-04-18 19:13:22,615 - brc - INFO - Average loss from batch 4601 to 4650 is 5.04550198555
2018-04-18 19:15:20,025 - brc - INFO - Average loss from batch 4651 to 4700 is 5.11433712482
2018-04-18 19:17:15,698 - brc - INFO - Average loss from batch 4701 to 4750 is 4.9971594429
2018-04-18 19:19:11,840 - brc - INFO - Average loss from batch 4751 to 4800 is 4.97890834808
2018-04-18 19:21:08,035 - brc - INFO - Average loss from batch 4801 to 4850 is 4.94921370506
2018-04-18 19:23:03,091 - brc - INFO - Average loss from batch 4851 to 4900 is 4.96718710899
2018-04-18 19:25:35,748 - brc - INFO - Average loss from batch 4901 to 4950 is 4.8673205471
2018-04-18 19:27:32,494 - brc - INFO - Average loss from batch 4951 to 5000 is 4.96735488892
2018-04-18 19:29:28,340 - brc - INFO - Average loss from batch 5001 to 5050 is 4.95059410095
2018-04-18 19:31:26,419 - brc - INFO - Average loss from batch 5051 to 5100 is 4.96445408821
2018-04-18 19:33:22,904 - brc - INFO - Average loss from batch 5101 to 5150 is 4.91629750729
2018-04-18 19:35:18,559 - brc - INFO - Average loss from batch 5151 to 5200 is 5.02515717506
2018-04-18 19:37:14,127 - brc - INFO - Average loss from batch 5201 to 5250 is 5.04734689236
2018-04-18 19:39:10,928 - brc - INFO - Average loss from batch 5251 to 5300 is 4.86312645912
2018-04-18 19:41:07,065 - brc - INFO - Average loss from batch 5301 to 5350 is 4.89584857941
2018-04-18 19:43:01,756 - brc - INFO - Average loss from batch 5351 to 5400 is 5.03676127911
2018-04-18 19:44:57,792 - brc - INFO - Average loss from batch 5401 to 5450 is 4.93145577431
2018-04-18 19:46:55,030 - brc - INFO - Average loss from batch 5451 to 5500 is 4.90358944893
2018-04-18 19:48:51,348 - brc - INFO - Average loss from batch 5501 to 5550 is 4.86880096436
2018-04-18 19:51:25,482 - brc - INFO - Average loss from batch 5551 to 5600 is 5.08535388947
2018-04-18 19:53:22,279 - brc - INFO - Average loss from batch 5601 to 5650 is 4.89004674435
2018-04-18 19:55:18,113 - brc - INFO - Average loss from batch 5651 to 5700 is 4.85515367985
2018-04-18 19:57:13,956 - brc - INFO - Average loss from batch 5701 to 5750 is 4.92248038292
2018-04-18 19:59:10,179 - brc - INFO - Average loss from batch 5751 to 5800 is 4.89621768951
2018-04-18 20:01:06,309 - brc - INFO - Average loss from batch 5801 to 5850 is 4.87593929768
2018-04-18 20:03:01,998 - brc - INFO - Average loss from batch 5851 to 5900 is 4.94427804947
2018-04-18 20:04:58,163 - brc - INFO - Average loss from batch 5901 to 5950 is 5.0598651886
2018-04-18 20:06:55,111 - brc - INFO - Average loss from batch 5951 to 6000 is 5.00611314297
2018-04-18 20:08:11,996 - brc - INFO - Evaluating the model ...
2018-04-18 20:26:40,880 - brc - INFO - Dev eval loss 8.21304933243
2018-04-18 20:26:40,882 - brc - INFO - Dev eval result: {'BLEU-4': 40.14, 'ROUGE-L': 48.38}
2018-04-18 20:26:49,135 - brc - INFO - Model saved in model/, with prefix BIDAF.
2018-04-18 20:27:28,806 - brc - INFO - Average loss from batch 6001 to 6050 is 4.93933196545
2018-04-18 20:29:25,781 - brc - INFO - Average loss from batch 6051 to 6100 is 4.92695212364
2018-04-18 20:31:22,477 - brc - INFO - Average loss from batch 6101 to 6150 is 4.9239802599
2018-04-18 20:33:19,240 - brc - INFO - Average loss from batch 6151 to 6200 is 4.9492995739
2018-04-18 20:35:15,964 - brc - INFO - Average loss from batch 6201 to 6250 is 5.02738884926
2018-04-18 20:37:11,485 - brc - INFO - Average loss from batch 6251 to 6300 is 4.99390509129
2018-04-18 20:39:06,197 - brc - INFO - Average loss from batch 6301 to 6350 is 4.91922008038
2018-04-18 20:41:01,083 - brc - INFO - Average loss from batch 6351 to 6400 is 4.99310415268
2018-04-18 20:42:57,028 - brc - INFO - Average loss from batch 6401 to 6450 is 5.1231784153
2018-04-18 20:44:52,218 - brc - INFO - Average loss from batch 6451 to 6500 is 5.068835392
2018-04-18 20:46:48,718 - brc - INFO - Average loss from batch 6501 to 6550 is 4.94875727654
2018-04-18 20:49:27,790 - brc - INFO - Average loss from batch 6551 to 6600 is 4.92917877197
2018-04-18 20:51:24,110 - brc - INFO - Average loss from batch 6601 to 6650 is 4.97858148098
2018-04-18 20:53:19,951 - brc - INFO - Average loss from batch 6651 to 6700 is 4.90719537735
2018-04-18 20:55:16,183 - brc - INFO - Average loss from batch 6701 to 6750 is 4.87350495815
2018-04-18 20:57:13,350 - brc - INFO - Average loss from batch 6751 to 6800 is 4.9582942152
2018-04-18 20:59:12,325 - brc - INFO - Average loss from batch 6801 to 6850 is 5.06102142334
2018-04-18 21:01:10,920 - brc - INFO - Average loss from batch 6851 to 6900 is 4.97609239101
2018-04-18 21:03:09,402 - brc - INFO - Average loss from batch 6901 to 6950 is 5.00145277977
2018-04-18 21:05:05,509 - brc - INFO - Average loss from batch 6951 to 7000 is 4.98874848366
2018-04-18 21:07:01,350 - brc - INFO - Average loss from batch 7001 to 7050 is 4.86920214653
2018-04-18 21:08:56,630 - brc - INFO - Average loss from batch 7051 to 7100 is 4.93991030693
2018-04-18 21:10:50,702 - brc - INFO - Average loss from batch 7101 to 7150 is 5.20012743473
2018-04-18 21:12:45,309 - brc - INFO - Average loss from batch 7151 to 7200 is 5.01909199238
2018-04-18 21:14:39,976 - brc - INFO - Average loss from batch 7201 to 7250 is 4.98813934326
2018-04-18 21:17:17,222 - brc - INFO - Average loss from batch 7251 to 7300 is 5.00615543365
2018-04-18 21:19:15,706 - brc - INFO - Average loss from batch 7301 to 7350 is 5.01959815025
2018-04-18 21:21:12,574 - brc - INFO - Average loss from batch 7351 to 7400 is 4.93971483231
2018-04-18 21:23:08,567 - brc - INFO - Average loss from batch 7401 to 7450 is 4.92484991074
2018-04-18 21:25:05,020 - brc - INFO - Average loss from batch 7451 to 7500 is 5.00339420319
2018-04-18 21:27:00,092 - brc - INFO - Average loss from batch 7501 to 7550 is 4.86908838272
2018-04-18 21:28:56,908 - brc - INFO - Average loss from batch 7551 to 7600 is 5.01285999298
2018-04-18 21:30:54,407 - brc - INFO - Average loss from batch 7601 to 7650 is 5.06737554073
2018-04-18 21:32:51,580 - brc - INFO - Average loss from batch 7651 to 7700 is 4.87656704426
2018-04-18 21:34:48,812 - brc - INFO - Average loss from batch 7701 to 7750 is 5.04159803391
2018-04-18 21:36:45,624 - brc - INFO - Average loss from batch 7751 to 7800 is 4.98552984238
2018-04-18 21:38:43,906 - brc - INFO - Average loss from batch 7801 to 7850 is 4.79261523247
2018-04-18 21:40:41,919 - brc - INFO - Average loss from batch 7851 to 7900 is 4.98782845497
2018-04-18 21:43:22,429 - brc - INFO - Average loss from batch 7901 to 7950 is 4.93394590855
2018-04-18 21:45:21,235 - brc - INFO - Average loss from batch 7951 to 8000 is 5.01273460865
2018-04-18 21:47:04,391 - brc - INFO - Evaluating the model ...
2018-04-18 22:04:37,996 - brc - INFO - Dev eval loss 8.23428671417
2018-04-18 22:04:37,999 - brc - INFO - Dev eval result: {'BLEU-4': 40.64, 'ROUGE-L': 48.3}
2018-04-18 22:04:42,570 - brc - INFO - Average train loss for epoch 1 is 4.98349849958
2018-04-18 22:04:42,573 - brc - INFO - Evaluating the model after epoch 1
2018-04-18 22:23:02,612 - brc - INFO - Dev eval loss 8.2333248558
2018-04-18 22:23:02,612 - brc - INFO - Dev eval result: {'BLEU-4': 40.7, 'ROUGE-L': 48.3}
2018-04-18 22:23:02,612 - brc - INFO - Training the model for epoch 2
2018-04-18 22:25:01,636 - brc - INFO - Average loss from batch 1 to 50 is 4.87578233719
2018-04-18 22:27:02,363 - brc - INFO - Average loss from batch 51 to 100 is 4.75720907688
2018-04-18 22:29:03,106 - brc - INFO - Average loss from batch 101 to 150 is 4.79823080063
2018-04-18 22:31:03,523 - brc - INFO - Average loss from batch 151 to 200 is 4.86507297039
2018-04-18 22:33:04,370 - brc - INFO - Average loss from batch 201 to 250 is 4.85318009377
2018-04-18 22:35:05,699 - brc - INFO - Average loss from batch 251 to 300 is 5.00105368614
2018-04-18 22:37:07,057 - brc - INFO - Average loss from batch 301 to 350 is 4.79704070091
2018-04-18 22:39:07,692 - brc - INFO - Average loss from batch 351 to 400 is 4.8931128931
2018-04-18 22:41:09,076 - brc - INFO - Average loss from batch 401 to 450 is 4.78844619751
2018-04-18 22:43:10,211 - brc - INFO - Average loss from batch 451 to 500 is 4.89322123051
2018-04-18 22:45:10,600 - brc - INFO - Average loss from batch 501 to 550 is 4.87697248459
2018-04-18 22:47:12,291 - brc - INFO - Average loss from batch 551 to 600 is 4.90311864376
2018-04-18 22:49:57,943 - brc - INFO - Average loss from batch 601 to 650 is 4.69967702389
2018-04-18 22:51:58,232 - brc - INFO - Average loss from batch 651 to 700 is 4.766252141
2018-04-18 22:53:58,046 - brc - INFO - Average loss from batch 701 to 750 is 4.8437915802
2018-04-18 22:55:58,764 - brc - INFO - Average loss from batch 751 to 800 is 4.95207233906
2018-04-18 22:57:57,267 - brc - INFO - Average loss from batch 801 to 850 is 4.78835988522
2018-04-18 22:59:57,076 - brc - INFO - Average loss from batch 851 to 900 is 4.85250605106
2018-04-18 23:01:57,111 - brc - INFO - Average loss from batch 901 to 950 is 4.89419900894
2018-04-18 23:03:56,680 - brc - INFO - Average loss from batch 951 to 1000 is 4.79274578571
2018-04-18 23:05:55,688 - brc - INFO - Average loss from batch 1001 to 1050 is 4.84781321049
2018-04-18 23:07:57,723 - brc - INFO - Average loss from batch 1051 to 1100 is 4.78612156391
2018-04-18 23:09:59,027 - brc - INFO - Average loss from batch 1101 to 1150 is 4.87659736633
2018-04-18 23:12:01,237 - brc - INFO - Average loss from batch 1151 to 1200 is 4.80813182831
2018-04-18 23:14:03,269 - brc - INFO - Average loss from batch 1201 to 1250 is 4.97436688423
2018-04-18 23:16:49,653 - brc - INFO - Average loss from batch 1251 to 1300 is 4.94428896427
2018-04-18 23:18:52,282 - brc - INFO - Average loss from batch 1301 to 1350 is 4.83125497818
2018-04-18 23:20:54,878 - brc - INFO - Average loss from batch 1351 to 1400 is 4.88537922859
2018-04-18 23:22:57,657 - brc - INFO - Average loss from batch 1401 to 1450 is 4.75575919151
2018-04-18 23:25:01,061 - brc - INFO - Average loss from batch 1451 to 1500 is 4.83123032093
2018-04-18 23:27:04,406 - brc - INFO - Average loss from batch 1501 to 1550 is 4.81586676598
2018-04-18 23:29:07,104 - brc - INFO - Average loss from batch 1551 to 1600 is 4.70456224442
2018-04-18 23:31:10,166 - brc - INFO - Average loss from batch 1601 to 1650 is 4.90902358532
2018-04-18 23:33:12,203 - brc - INFO - Average loss from batch 1651 to 1700 is 4.87873143673
2018-04-18 23:35:15,346 - brc - INFO - Average loss from batch 1701 to 1750 is 4.84362798691
2018-04-18 23:37:17,613 - brc - INFO - Average loss from batch 1751 to 1800 is 4.87500987053
2018-04-18 23:39:20,564 - brc - INFO - Average loss from batch 1801 to 1850 is 4.78431699753
2018-04-18 23:41:22,912 - brc - INFO - Average loss from batch 1851 to 1900 is 4.90135390759
2018-04-18 23:43:25,730 - brc - INFO - Average loss from batch 1901 to 1950 is 4.79800655365
2018-04-18 23:46:12,036 - brc - INFO - Average loss from batch 1951 to 2000 is 4.87269698143
2018-04-18 23:46:39,519 - brc - INFO - Evaluating the model ...
2018-04-19 00:04:27,168 - brc - INFO - Dev eval loss 8.32009555359
2018-04-19 00:04:27,169 - brc - INFO - Dev eval result: {'BLEU-4': 41.03, 'ROUGE-L': 48.43}
2018-04-19 00:04:35,467 - brc - INFO - Model saved in model/, with prefix BIDAF.
2018-04-19 00:06:11,021 - brc - INFO - Average loss from batch 2001 to 2050 is 4.83768604279
2018-04-19 00:08:14,089 - brc - INFO - Average loss from batch 2051 to 2100 is 4.80468648434
2018-04-19 00:10:18,012 - brc - INFO - Average loss from batch 2101 to 2150 is 4.77852472782
2018-04-19 00:12:22,288 - brc - INFO - Average loss from batch 2151 to 2200 is 4.77726392269
2018-04-19 00:14:26,244 - brc - INFO - Average loss from batch 2201 to 2250 is 4.95945026398
2018-04-19 00:16:29,000 - brc - INFO - Average loss from batch 2251 to 2300 is 4.74387018681
2018-04-19 00:19:15,443 - brc - INFO - Average loss from batch 2301 to 2350 is 4.79952325821
2018-04-19 00:21:19,246 - brc - INFO - Average loss from batch 2351 to 2400 is 4.81436206341
2018-04-19 00:23:20,990 - brc - INFO - Average loss from batch 2401 to 2450 is 4.84262539864
2018-04-19 00:25:23,819 - brc - INFO - Average loss from batch 2451 to 2500 is 4.90004675865
2018-04-19 00:27:24,894 - brc - INFO - Average loss from batch 2501 to 2550 is 4.8076832819
2018-04-19 00:29:26,059 - brc - INFO - Average loss from batch 2551 to 2600 is 4.68648327827
2018-04-19 00:31:26,398 - brc - INFO - Average loss from batch 2601 to 2650 is 4.93865149021
2018-04-19 00:33:27,678 - brc - INFO - Average loss from batch 2651 to 2700 is 4.91833461285
2018-04-19 00:35:28,409 - brc - INFO - Average loss from batch 2701 to 2750 is 4.85390269756
2018-04-19 00:37:28,549 - brc - INFO - Average loss from batch 2751 to 2800 is 4.85313789845
2018-04-19 00:39:29,333 - brc - INFO - Average loss from batch 2801 to 2850 is 4.70288915634
2018-04-19 00:41:28,872 - brc - INFO - Average loss from batch 2851 to 2900 is 4.97491207123
2018-04-19 00:43:28,540 - brc - INFO - Average loss from batch 2901 to 2950 is 4.82546874523
2018-04-19 00:45:31,182 - brc - INFO - Average loss from batch 2951 to 3000 is 4.89690560818
2018-04-19 00:48:19,874 - brc - INFO - Average loss from batch 3001 to 3050 is 4.8391185236
2018-04-19 00:50:23,342 - brc - INFO - Average loss from batch 3051 to 3100 is 4.89960907936
2018-04-19 00:52:26,229 - brc - INFO - Average loss from batch 3101 to 3150 is 4.81445349693
2018-04-19 00:54:28,899 - brc - INFO - Average loss from batch 3151 to 3200 is 4.83337235451
2018-04-19 00:56:31,518 - brc - INFO - Average loss from batch 3201 to 3250 is 4.84293755054
2018-04-19 00:58:33,678 - brc - INFO - Average loss from batch 3251 to 3300 is 4.74549479485
2018-04-19 01:00:36,108 - brc - INFO - Average loss from batch 3301 to 3350 is 4.8427971983
2018-04-19 01:02:37,441 - brc - INFO - Average loss from batch 3351 to 3400 is 4.74411673069
2018-04-19 01:04:42,143 - brc - INFO - Average loss from batch 3401 to 3450 is 4.88700558662
2018-04-19 01:06:44,924 - brc - INFO - Average loss from batch 3451 to 3500 is 4.88136122704
2018-04-19 01:08:47,558 - brc - INFO - Average loss from batch 3501 to 3550 is 4.77863302231
2018-04-19 01:10:49,414 - brc - INFO - Average loss from batch 3551 to 3600 is 4.86210708141
2018-04-19 01:12:52,409 - brc - INFO - Average loss from batch 3601 to 3650 is 4.88128869534
2018-04-19 01:15:40,486 - brc - INFO - Average loss from batch 3651 to 3700 is 4.97990107536
2018-04-19 01:17:44,160 - brc - INFO - Average loss from batch 3701 to 3750 is 4.89775627136
2018-04-19 01:19:47,568 - brc - INFO - Average loss from batch 3751 to 3800 is 4.87016161919
2018-04-19 01:21:50,887 - brc - INFO - Average loss from batch 3801 to 3850 is 4.92397267818
2018-04-19 01:23:53,082 - brc - INFO - Average loss from batch 3851 to 3900 is 4.9310171032
2018-04-19 01:25:55,694 - brc - INFO - Average loss from batch 3901 to 3950 is 4.92818236351
2018-04-19 01:27:59,481 - brc - INFO - Average loss from batch 3951 to 4000 is 4.92397107601
2018-04-19 01:28:53,317 - brc - INFO - Evaluating the model ...
2018-04-19 01:46:50,289 - brc - INFO - Dev eval loss 8.31215200958
2018-04-19 01:46:50,290 - brc - INFO - Dev eval result: {'BLEU-4': 40.5, 'ROUGE-L': 48.28}
2018-04-19 01:48:44,135 - brc - INFO - Average loss from batch 4001 to 4050 is 4.89913170815
2018-04-19 01:50:46,239 - brc - INFO - Average loss from batch 4051 to 4100 is 4.85847365856
2018-04-19 01:52:49,273 - brc - INFO - Average loss from batch 4101 to 4150 is 4.94453071594
2018-04-19 01:54:51,359 - brc - INFO - Average loss from batch 4151 to 4200 is 4.95946819305
2018-04-19 01:56:55,586 - brc - INFO - Average loss from batch 4201 to 4250 is 4.91068603992
2018-04-19 01:58:58,478 - brc - INFO - Average loss from batch 4251 to 4300 is 4.80913609982
2018-04-19 02:01:02,034 - brc - INFO - Average loss from batch 4301 to 4350 is 4.90830373764
2018-04-19 02:03:04,009 - brc - INFO - Average loss from batch 4351 to 4400 is 4.94954308987
2018-04-19 02:05:05,162 - brc - INFO - Average loss from batch 4401 to 4450 is 4.79865438938
2018-04-19 02:07:06,696 - brc - INFO - Average loss from batch 4451 to 4500 is 4.88470223904
2018-04-19 02:09:08,514 - brc - INFO - Average loss from batch 4501 to 4550 is 4.81757453442
2018-04-19 02:11:08,334 - brc - INFO - Average loss from batch 4551 to 4600 is 4.95528114796
2018-04-19 02:13:08,223 - brc - INFO - Average loss from batch 4601 to 4650 is 4.87162343025
2018-04-19 02:15:08,574 - brc - INFO - Average loss from batch 4651 to 4700 is 4.73838230133
2018-04-19 02:17:53,382 - brc - INFO - Average loss from batch 4701 to 4750 is 4.98169772148
2018-04-19 02:19:55,922 - brc - INFO - Average loss from batch 4751 to 4800 is 4.89022087574
2018-04-19 02:21:59,436 - brc - INFO - Average loss from batch 4801 to 4850 is 5.0034000206
2018-04-19 02:24:02,171 - brc - INFO - Average loss from batch 4851 to 4900 is 4.81838887215
2018-04-19 02:26:05,551 - brc - INFO - Average loss from batch 4901 to 4950 is 4.84813482285
2018-04-19 02:28:09,149 - brc - INFO - Average loss from batch 4951 to 5000 is 4.88577341557
2018-04-19 02:30:12,704 - brc - INFO - Average loss from batch 5001 to 5050 is 4.91111219883
2018-04-19 02:32:16,287 - brc - INFO - Average loss from batch 5051 to 5100 is 4.72490828514
2018-04-19 02:34:18,873 - brc - INFO - Average loss from batch 5101 to 5150 is 4.81634819031
2018-04-19 02:36:21,976 - brc - INFO - Average loss from batch 5151 to 5200 is 4.907045784
2018-04-19 02:38:24,465 - brc - INFO - Average loss from batch 5201 to 5250 is 4.81703735352
2018-04-19 02:40:26,295 - brc - INFO - Average loss from batch 5251 to 5300 is 4.70913350105
2018-04-19 02:42:28,248 - brc - INFO - Average loss from batch 5301 to 5350 is 4.84213962555
2018-04-19 02:44:30,376 - brc - INFO - Average loss from batch 5351 to 5400 is 4.89994006157
2018-04-19 02:47:19,419 - brc - INFO - Average loss from batch 5401 to 5450 is 4.94362654686
2018-04-19 02:49:21,654 - brc - INFO - Average loss from batch 5451 to 5500 is 4.78275493145
2018-04-19 02:51:23,970 - brc - INFO - Average loss from batch 5501 to 5550 is 4.80622841835
2018-04-19 02:53:26,893 - brc - INFO - Average loss from batch 5551 to 5600 is 4.86780221462
2018-04-19 02:55:30,219 - brc - INFO - Average loss from batch 5601 to 5650 is 4.92283920288
2018-04-19 02:57:32,276 - brc - INFO - Average loss from batch 5651 to 5700 is 4.86532177448
2018-04-19 02:59:34,809 - brc - INFO - Average loss from batch 5701 to 5750 is 4.89753787518
2018-04-19 03:01:37,742 - brc - INFO - Average loss from batch 5751 to 5800 is 4.83798055649
2018-04-19 03:03:40,855 - brc - INFO - Average loss from batch 5801 to 5850 is 4.95396163464
2018-04-19 03:05:44,234 - brc - INFO - Average loss from batch 5851 to 5900 is 4.8327899456
2018-04-19 03:07:47,839 - brc - INFO - Average loss from batch 5901 to 5950 is 4.78366519928
2018-04-19 03:09:50,946 - brc - INFO - Average loss from batch 5951 to 6000 is 4.85333025932
2018-04-19 03:11:12,304 - brc - INFO - Evaluating the model ...
2018-04-19 03:30:01,122 - brc - INFO - Dev eval loss 8.38661351013
2018-04-19 03:30:01,125 - brc - INFO - Dev eval result: {'BLEU-4': 41.33, 'ROUGE-L': 48.49}
2018-04-19 03:30:08,317 - brc - INFO - Model saved in model/, with prefix BIDAF.
2018-04-19 03:30:49,729 - brc - INFO - Average loss from batch 6001 to 6050 is 4.77289340019
2018-04-19 03:32:53,094 - brc - INFO - Average loss from batch 6051 to 6100 is 4.91050391197
2018-04-19 03:34:56,435 - brc - INFO - Average loss from batch 6101 to 6150 is 4.82347418785
2018-04-19 03:36:59,867 - brc - INFO - Average loss from batch 6151 to 6200 is 4.81910563469
2018-04-19 03:39:02,453 - brc - INFO - Average loss from batch 6201 to 6250 is 4.8822034502
2018-04-19 03:41:03,312 - brc - INFO - Average loss from batch 6251 to 6300 is 4.85703454018
2018-04-19 03:43:04,358 - brc - INFO - Average loss from batch 6301 to 6350 is 4.87419350624
2018-04-19 03:45:04,448 - brc - INFO - Average loss from batch 6351 to 6400 is 4.74184947968
2018-04-19 03:47:52,913 - brc - INFO - Average loss from batch 6401 to 6450 is 4.89612865448
2018-04-19 03:49:53,303 - brc - INFO - Average loss from batch 6451 to 6500 is 4.79732960701
2018-04-19 03:51:54,593 - brc - INFO - Average loss from batch 6501 to 6550 is 5.00340179443
2018-04-19 03:53:54,300 - brc - INFO - Average loss from batch 6551 to 6600 is 4.84273753166
2018-04-19 03:55:54,859 - brc - INFO - Average loss from batch 6601 to 6650 is 4.77520747185
2018-04-19 03:57:55,615 - brc - INFO - Average loss from batch 6651 to 6700 is 5.04039495468
2018-04-19 03:59:56,151 - brc - INFO - Average loss from batch 6701 to 6750 is 4.82569051743
2018-04-19 04:01:56,845 - brc - INFO - Average loss from batch 6751 to 6800 is 4.90660522461
2018-04-19 04:03:58,031 - brc - INFO - Average loss from batch 6801 to 6850 is 5.0843255806
2018-04-19 04:05:59,159 - brc - INFO - Average loss from batch 6851 to 6900 is 4.75525410175
2018-04-19 04:08:00,633 - brc - INFO - Average loss from batch 6901 to 6950 is 4.81839667797
2018-04-19 04:10:00,693 - brc - INFO - Average loss from batch 6951 to 7000 is 4.82372896194
2018-04-19 04:12:00,644 - brc - INFO - Average loss from batch 7001 to 7050 is 4.75196889877
2018-04-19 04:14:00,530 - brc - INFO - Average loss from batch 7051 to 7100 is 4.81297802448
2018-04-19 04:16:50,948 - brc - INFO - Average loss from batch 7101 to 7150 is 4.79536896706
2018-04-19 04:18:52,686 - brc - INFO - Average loss from batch 7151 to 7200 is 4.78358523369
2018-04-19 04:20:55,438 - brc - INFO - Average loss from batch 7201 to 7250 is 4.85308535576
2018-04-19 04:22:57,023 - brc - INFO - Average loss from batch 7251 to 7300 is 4.91533276081
2018-04-19 04:25:00,997 - brc - INFO - Average loss from batch 7301 to 7350 is 4.78619812965
2018-04-19 04:27:04,339 - brc - INFO - Average loss from batch 7351 to 7400 is 4.9029637146
2018-04-19 04:29:06,839 - brc - INFO - Average loss from batch 7401 to 7450 is 4.73929229259
2018-04-19 04:31:10,153 - brc - INFO - Average loss from batch 7451 to 7500 is 4.77360826492
2018-04-19 04:33:12,490 - brc - INFO - Average loss from batch 7501 to 7550 is 4.87937029839
2018-04-19 04:35:14,922 - brc - INFO - Average loss from batch 7551 to 7600 is 4.8541435194
2018-04-19 04:37:16,095 - brc - INFO - Average loss from batch 7601 to 7650 is 4.83539074898
2018-04-19 04:39:18,772 - brc - INFO - Average loss from batch 7651 to 7700 is 4.82856764317
2018-04-19 04:41:21,418 - brc - INFO - Average loss from batch 7701 to 7750 is 4.89407360077
2018-04-19 04:43:23,061 - brc - INFO - Average loss from batch 7751 to 7800 is 4.79452263355
2018-04-19 04:46:14,837 - brc - INFO - Average loss from batch 7801 to 7850 is 4.87468401432
2018-04-19 04:48:18,095 - brc - INFO - Average loss from batch 7851 to 7900 is 5.06436686993
2018-04-19 04:50:20,429 - brc - INFO - Average loss from batch 7901 to 7950 is 4.81303288937
2018-04-19 04:52:24,337 - brc - INFO - Average loss from batch 7951 to 8000 is 4.94399702072
2018-04-19 04:54:11,756 - brc - INFO - Evaluating the model ...
2018-04-19 05:12:10,606 - brc - INFO - Dev eval loss 8.34648056946
2018-04-19 05:12:10,608 - brc - INFO - Dev eval result: {'BLEU-4': 40.94, 'ROUGE-L': 48.29}
2018-04-19 05:12:15,379 - brc - INFO - Average train loss for epoch 2 is 4.85457848782
2018-04-19 05:12:15,390 - brc - INFO - Evaluating the model after epoch 2
2018-04-19 05:30:55,017 - brc - INFO - Dev eval loss 8.34665107727
2018-04-19 05:30:55,018 - brc - INFO - Dev eval result: {'BLEU-4': 40.98, 'ROUGE-L': 48.31}
2018-04-19 05:30:55,019 - brc - INFO - Training the model for epoch 3
2018-04-19 05:32:57,098 - brc - INFO - Average loss from batch 1 to 50 is 4.69909700394
2018-04-19 05:34:59,633 - brc - INFO - Average loss from batch 51 to 100 is 4.73553020954
2018-04-19 05:37:00,281 - brc - INFO - Average loss from batch 101 to 150 is 4.70253992081
2018-04-19 05:39:01,158 - brc - INFO - Average loss from batch 151 to 200 is 4.77677982807
2018-04-19 05:41:01,020 - brc - INFO - Average loss from batch 201 to 250 is 4.6740110302
2018-04-19 05:43:01,720 - brc - INFO - Average loss from batch 251 to 300 is 4.73367499828
2018-04-19 05:45:02,670 - brc - INFO - Average loss from batch 301 to 350 is 4.6644193697
2018-04-19 05:47:04,541 - brc - INFO - Average loss from batch 351 to 400 is 4.68997301579
2018-04-19 05:49:04,343 - brc - INFO - Average loss from batch 401 to 450 is 4.64372692108
2018-04-19 05:51:54,004 - brc - INFO - Average loss from batch 451 to 500 is 4.76247279167
2018-04-19 05:53:55,262 - brc - INFO - Average loss from batch 501 to 550 is 4.75416875839
2018-04-19 05:55:57,790 - brc - INFO - Average loss from batch 551 to 600 is 4.60121493816
2018-04-19 05:58:01,267 - brc - INFO - Average loss from batch 601 to 650 is 4.7210005188
2018-04-19 06:00:02,298 - brc - INFO - Average loss from batch 651 to 700 is 4.83988030434
2018-04-19 06:02:04,796 - brc - INFO - Average loss from batch 701 to 750 is 4.64784977913
2018-04-19 06:04:08,999 - brc - INFO - Average loss from batch 751 to 800 is 4.69332029343
2018-04-19 06:06:13,073 - brc - INFO - Average loss from batch 801 to 850 is 4.73956562996
2018-04-19 06:08:15,493 - brc - INFO - Average loss from batch 851 to 900 is 4.76750757694
2018-04-19 06:10:18,729 - brc - INFO - Average loss from batch 901 to 950 is 4.62640567303
2018-04-19 06:12:21,986 - brc - INFO - Average loss from batch 951 to 1000 is 4.67608767986
2018-04-19 06:14:24,546 - brc - INFO - Average loss from batch 1001 to 1050 is 4.76598517418
2018-04-19 06:16:28,178 - brc - INFO - Average loss from batch 1051 to 1100 is 4.67276400566
2018-04-19 06:18:30,173 - brc - INFO - Average loss from batch 1101 to 1150 is 4.82792936325
2018-04-19 06:21:23,794 - brc - INFO - Average loss from batch 1151 to 1200 is 4.70495777607
2018-04-19 06:23:27,670 - brc - INFO - Average loss from batch 1201 to 1250 is 4.80786740303
2018-04-19 06:25:29,201 - brc - INFO - Average loss from batch 1251 to 1300 is 4.754377985
2018-04-19 06:27:31,532 - brc - INFO - Average loss from batch 1301 to 1350 is 4.75206341743
2018-04-19 06:29:35,602 - brc - INFO - Average loss from batch 1351 to 1400 is 4.71132834911
2018-04-19 06:31:38,855 - brc - INFO - Average loss from batch 1401 to 1450 is 4.67766940594
2018-04-19 06:33:40,974 - brc - INFO - Average loss from batch 1451 to 1500 is 4.67045619965
2018-04-19 06:35:44,131 - brc - INFO - Average loss from batch 1501 to 1550 is 4.73907998085
2018-04-19 06:37:46,754 - brc - INFO - Average loss from batch 1551 to 1600 is 4.78733891487
2018-04-19 06:39:49,700 - brc - INFO - Average loss from batch 1601 to 1650 is 4.67444722176
2018-04-19 06:41:51,529 - brc - INFO - Average loss from batch 1651 to 1700 is 4.77553803921
2018-04-19 06:43:55,771 - brc - INFO - Average loss from batch 1701 to 1750 is 4.70499488831
2018-04-19 06:45:59,053 - brc - INFO - Average loss from batch 1751 to 1800 is 4.76574321747
2018-04-19 06:48:51,044 - brc - INFO - Average loss from batch 1801 to 1850 is 4.79427793026
2018-04-19 06:50:53,697 - brc - INFO - Average loss from batch 1851 to 1900 is 4.67534229755
2018-04-19 06:52:55,505 - brc - INFO - Average loss from batch 1901 to 1950 is 4.76794661045
2018-04-19 06:54:58,834 - brc - INFO - Average loss from batch 1951 to 2000 is 4.83606282234
2018-04-19 06:55:25,465 - brc - INFO - Evaluating the model ...
2018-04-19 07:13:31,296 - brc - INFO - Dev eval loss 8.44881793823
2018-04-19 07:13:31,299 - brc - INFO - Dev eval result: {'BLEU-4': 41.2, 'ROUGE-L': 48.35}
2018-04-19 07:15:05,532 - brc - INFO - Average loss from batch 2001 to 2050 is 4.81099390984
2018-04-19 07:17:09,776 - brc - INFO - Average loss from batch 2051 to 2100 is 4.68399559021
2018-04-19 07:19:11,068 - brc - INFO - Average loss from batch 2101 to 2150 is 4.77240198612
2018-04-19 07:22:00,119 - brc - INFO - Average loss from batch 2151 to 2200 is 4.74094718456
2018-04-19 07:24:00,504 - brc - INFO - Average loss from batch 2201 to 2250 is 4.72614202976
2018-04-19 07:26:01,436 - brc - INFO - Average loss from batch 2251 to 2300 is 4.76998603821
2018-04-19 07:28:02,591 - brc - INFO - Average loss from batch 2301 to 2350 is 4.78245955944
2018-04-19 07:30:02,635 - brc - INFO - Average loss from batch 2351 to 2400 is 4.73792075634
2018-04-19 07:32:03,394 - brc - INFO - Average loss from batch 2401 to 2450 is 4.72873839378
2018-04-19 07:34:04,332 - brc - INFO - Average loss from batch 2451 to 2500 is 4.69054991722
2018-04-19 07:36:06,302 - brc - INFO - Average loss from batch 2501 to 2550 is 4.68406019688
2018-04-19 07:38:08,402 - brc - INFO - Average loss from batch 2551 to 2600 is 4.77093720913
2018-04-19 07:40:11,150 - brc - INFO - Average loss from batch 2601 to 2650 is 4.84884985447
2018-04-19 07:42:13,343 - brc - INFO - Average loss from batch 2651 to 2700 is 4.82064791679
2018-04-19 07:44:15,718 - brc - INFO - Average loss from batch 2701 to 2750 is 4.74913825512
2018-04-19 07:46:19,626 - brc - INFO - Average loss from batch 2751 to 2800 is 4.70447045803
2018-04-19 07:48:22,465 - brc - INFO - Average loss from batch 2801 to 2850 is 4.65274330616
2018-04-19 07:51:14,804 - brc - INFO - Average loss from batch 2851 to 2900 is 4.6869880724
2018-04-19 07:53:17,914 - brc - INFO - Average loss from batch 2901 to 2950 is 4.85117513657
2018-04-19 07:55:21,137 - brc - INFO - Average loss from batch 2951 to 3000 is 4.84429932594
2018-04-19 07:57:22,642 - brc - INFO - Average loss from batch 3001 to 3050 is 4.68348304272
2018-04-19 07:59:25,568 - brc - INFO - Average loss from batch 3051 to 3100 is 4.68976514339
2018-04-19 08:01:28,273 - brc - INFO - Average loss from batch 3101 to 3150 is 4.76519941807
2018-04-19 08:03:31,027 - brc - INFO - Average loss from batch 3151 to 3200 is 4.82404533386
2018-04-19 08:05:35,530 - brc - INFO - Average loss from batch 3201 to 3250 is 4.77843164444
2018-04-19 08:07:37,623 - brc - INFO - Average loss from batch 3251 to 3300 is 4.80273736954
2018-04-19 08:09:39,135 - brc - INFO - Average loss from batch 3301 to 3350 is 4.80430319786
2018-04-19 08:11:42,675 - brc - INFO - Average loss from batch 3351 to 3400 is 4.9235359478
2018-04-19 08:13:46,138 - brc - INFO - Average loss from batch 3401 to 3450 is 4.80142799377
2018-04-19 08:15:49,388 - brc - INFO - Average loss from batch 3451 to 3500 is 4.72912122726
2018-04-19 08:17:52,787 - brc - INFO - Average loss from batch 3501 to 3550 is 4.5663051939
2018-04-19 08:20:45,774 - brc - INFO - Average loss from batch 3551 to 3600 is 4.72042093754
2018-04-19 08:22:49,038 - brc - INFO - Average loss from batch 3601 to 3650 is 4.8488061142
2018-04-19 08:24:52,000 - brc - INFO - Average loss from batch 3651 to 3700 is 4.81658122063
2018-04-19 08:26:55,326 - brc - INFO - Average loss from batch 3701 to 3750 is 4.73702538013
2018-04-19 08:28:58,802 - brc - INFO - Average loss from batch 3751 to 3800 is 4.79238449574
2018-04-19 08:31:00,402 - brc - INFO - Average loss from batch 3801 to 3850 is 4.83617218494
2018-04-19 08:34:08,797 - brc - INFO - Running with args : Namespace(algo='BIDAF', batch_size=64, brc_dir='model/', char_embed='../../data/embedding/wiki_brc/wiki_brc.char.vec', char_hidden_size=100, dev_files=['../../data/preprocessed_ltp/devset/search.dev.filter.json', '../../data/preprocessed_ltp/devset/zhidao.dev.filter.json'], dropout_keep_prob=1, epochs=10, evaluate=False, gpu='0', hidden_size=150, learning_rate=0.001, log_path='model/log', max_a_len=500, max_p_len=500, max_p_num=5, max_q_len=60, max_w_len=4, model_dir='model/', optim='adam', pos_embed_dim=10, pr_rate=0.2, predict=True, prepare=False, restore=False, result_dir='model/', summary_dir='model/', test_files=['../../data/preprocessed_ltp/test1set/search.test1.filter.json', '../../data/preprocessed_ltp/test1set/zhidao.test1.filter.json'], train=False, train_files=['../../data/preprocessed_ltp/trainset/search.train.filter.json', '../../data/preprocessed_ltp/trainset/zhidao.train.filter.json'], vocab_dir='model/', weight_decay=0, word_embed='../../data/embedding/wiki_brc/wiki_brc.word.vec')
2018-04-19 08:34:08,797 - brc - INFO - Load data_set and vocab...
2018-04-19 08:40:41,589 - brc - INFO - Test set size: 60000 questions.
2018-04-19 08:40:41,589 - brc - INFO - Converting text into ids...
2018-04-19 08:43:04,946 - brc - INFO - Restoring the model...
2018-04-19 08:43:10,202 - brc - INFO - Time to build graph: 4.54273581505 s
2018-04-19 08:43:24,161 - brc - INFO - There are 3865506 parameters in the model
2018-04-19 08:43:27,905 - brc - INFO - Model restored from model/, with prefix BIDAF
2018-04-19 08:43:27,906 - brc - INFO - Predicting answers for test set...
2018-04-19 09:41:12,807 - brc - INFO - Saving test.predicted results to model/test.predicted.json
2018-04-22 10:19:49,349 - brc - INFO - Running with args : Namespace(algo='BIDAF', batch_size=32, brc_dir='model/', char_embed='../../data/embedding/wiki_brc/wiki_brc.char.vec', char_hidden_size=100, dev_files=['../../data/preprocessed_ltp/devset/search.dev.filter.json', '../../data/preprocessed_ltp/devset/zhidao.dev.filter.json'], dropout_keep_prob=1, epochs=10, evaluate=False, gpu='0', hidden_size=150, learning_rate=3e-05, log_path='model/log', max_a_len=500, max_p_len=500, max_p_num=5, max_q_len=60, max_w_len=4, model_dir='model/', optim='adam', pos_embed_dim=10, pr_rate=0.2, predict=False, prepare=False, restore=True, result_dir='model/', summary_dir='model/', test_files=['../../data/test1set/preprocessed/search.test1.json', '../../data/test1set/preprocessed/zhidao.test1.json'], train=True, train_files=['../../data/preprocessed_ltp/trainset/search.train.filter.json', '../../data/preprocessed_ltp/trainset/zhidao.train.filter.json'], vocab_dir='model/', weight_decay=0, word_embed='../../data/embedding/wiki_brc/wiki_brc.word.vec')
2018-04-22 10:19:49,349 - brc - INFO - Load data_set and vocab...
2018-04-22 10:25:54,775 - brc - INFO - Train set size: 257469 questions.
2018-04-22 10:26:49,049 - brc - INFO - Dev set size: 10000 questions.
2018-04-22 10:26:49,049 - brc - INFO - Converting text into ids...
2018-04-22 10:36:58,533 - brc - INFO - Initialize the model...
2018-04-22 10:37:04,346 - brc - INFO - Time to build graph: 5.07579994202 s
2018-04-22 10:37:21,120 - brc - INFO - There are 3865506 parameters in the model
2018-04-22 10:37:23,497 - brc - INFO - Restoring the model...
2018-04-22 10:37:24,976 - brc - INFO - Model restored from model/, with prefix BIDAF
2018-04-22 10:37:24,977 - brc - INFO - Evaluating the model on dev set...
2018-04-22 10:55:14,778 - brc - INFO - Training the model...
2018-04-22 10:55:14,778 - brc - INFO - Training the model for epoch 1
2018-04-22 10:57:12,148 - brc - INFO - Average loss from batch 1 to 50 is 4.67465045929
2018-04-22 10:59:08,269 - brc - INFO - Average loss from batch 51 to 100 is 4.74307370663
2018-04-22 11:01:04,987 - brc - INFO - Average loss from batch 101 to 150 is 4.73423585415
2018-04-22 11:03:03,320 - brc - INFO - Average loss from batch 151 to 200 is 4.5915265131
2018-04-22 11:04:59,461 - brc - INFO - Average loss from batch 201 to 250 is 4.66156368256
2018-04-22 11:06:55,625 - brc - INFO - Average loss from batch 251 to 300 is 4.79327361107
2018-04-22 11:09:21,016 - brc - INFO - Average loss from batch 301 to 350 is 4.73025541306
2018-04-22 11:11:17,189 - brc - INFO - Average loss from batch 351 to 400 is 4.74142874718
2018-04-22 11:13:14,258 - brc - INFO - Average loss from batch 401 to 450 is 4.89038161278
2018-04-22 11:15:12,230 - brc - INFO - Average loss from batch 451 to 500 is 4.76427728653
2018-04-22 11:17:09,039 - brc - INFO - Average loss from batch 501 to 550 is 4.72099736691
2018-04-22 11:19:05,048 - brc - INFO - Average loss from batch 551 to 600 is 4.63876066685
2018-04-22 11:21:01,459 - brc - INFO - Average loss from batch 601 to 650 is 4.78171779156
2018-04-22 11:22:59,073 - brc - INFO - Average loss from batch 651 to 700 is 4.79292974472
2018-04-22 11:24:58,214 - brc - INFO - Average loss from batch 701 to 750 is 4.74705864429
2018-04-22 11:26:56,123 - brc - INFO - Average loss from batch 751 to 800 is 4.83151242733
2018-04-22 11:28:58,110 - brc - INFO - Average loss from batch 801 to 850 is 4.86597403526
2018-04-22 11:30:59,815 - brc - INFO - Average loss from batch 851 to 900 is 4.69210320473
2018-04-22 11:33:00,111 - brc - INFO - Average loss from batch 901 to 950 is 4.64560590744
2018-04-22 11:35:32,098 - brc - INFO - Average loss from batch 951 to 1000 is 4.72028978348
2018-04-22 11:37:33,700 - brc - INFO - Average loss from batch 1001 to 1050 is 4.72463632107
2018-04-22 11:39:33,874 - brc - INFO - Average loss from batch 1051 to 1100 is 4.84330131054
2018-04-22 11:41:32,373 - brc - INFO - Average loss from batch 1101 to 1150 is 4.70247079372
2018-04-22 11:43:30,171 - brc - INFO - Average loss from batch 1151 to 1200 is 4.76458317757
2018-04-22 11:45:29,674 - brc - INFO - Average loss from batch 1201 to 1250 is 4.68756209373
2018-04-22 11:47:28,403 - brc - INFO - Average loss from batch 1251 to 1300 is 4.78744651794
2018-04-22 11:49:26,624 - brc - INFO - Average loss from batch 1301 to 1350 is 4.69049037933
2018-04-22 11:51:25,086 - brc - INFO - Average loss from batch 1351 to 1400 is 4.73190788269
2018-04-22 11:53:24,959 - brc - INFO - Average loss from batch 1401 to 1450 is 4.77780433655
2018-04-22 11:55:23,786 - brc - INFO - Average loss from batch 1451 to 1500 is 4.72103711605
2018-04-22 11:57:21,975 - brc - INFO - Average loss from batch 1501 to 1550 is 4.73205629349
2018-04-22 11:59:21,780 - brc - INFO - Average loss from batch 1551 to 1600 is 4.76779243946
2018-04-22 12:01:57,963 - brc - INFO - Average loss from batch 1601 to 1650 is 4.7235418272
2018-04-22 12:03:58,456 - brc - INFO - Average loss from batch 1651 to 1700 is 4.82511511803
2018-04-22 12:05:57,758 - brc - INFO - Average loss from batch 1701 to 1750 is 4.7594291687
2018-04-22 12:08:00,339 - brc - INFO - Average loss from batch 1751 to 1800 is 4.80517530441
2018-04-22 12:10:03,339 - brc - INFO - Average loss from batch 1801 to 1850 is 4.78788241863
2018-04-22 12:12:04,246 - brc - INFO - Average loss from batch 1851 to 1900 is 4.68552042961
2018-04-22 12:14:03,784 - brc - INFO - Average loss from batch 1901 to 1950 is 4.64744841099
2018-04-22 12:16:03,682 - brc - INFO - Average loss from batch 1951 to 2000 is 4.65745346069
2018-04-22 12:16:30,048 - brc - INFO - Evaluating the model ...
2018-04-22 12:34:54,793 - brc - INFO - Dev eval loss 8.45391433105
2018-04-22 12:34:54,796 - brc - INFO - Dev eval result: {'BLEU-4': 41.16, 'ROUGE-L': 48.26}
2018-04-22 12:36:27,114 - brc - INFO - Average loss from batch 2001 to 2050 is 4.80060909271
2018-04-22 12:38:25,772 - brc - INFO - Average loss from batch 2051 to 2100 is 4.61429496288
2018-04-22 12:40:24,538 - brc - INFO - Average loss from batch 2101 to 2150 is 4.87385818958
2018-04-22 12:42:22,970 - brc - INFO - Average loss from batch 2151 to 2200 is 4.67705533504
2018-04-22 12:44:22,164 - brc - INFO - Average loss from batch 2201 to 2250 is 4.83360736847
2018-04-22 12:46:21,462 - brc - INFO - Average loss from batch 2251 to 2300 is 4.7380882597
2018-04-22 12:48:19,924 - brc - INFO - Average loss from batch 2301 to 2350 is 4.78188232422
2018-04-22 12:50:18,064 - brc - INFO - Average loss from batch 2351 to 2400 is 4.69191737175
2018-04-22 12:52:15,703 - brc - INFO - Average loss from batch 2401 to 2450 is 4.70952648163
2018-04-22 12:54:14,830 - brc - INFO - Average loss from batch 2451 to 2500 is 4.84335346222
2018-04-22 12:56:13,157 - brc - INFO - Average loss from batch 2501 to 2550 is 4.64357108116
2018-04-22 12:58:12,141 - brc - INFO - Average loss from batch 2551 to 2600 is 4.80651893616
2018-04-22 13:00:45,096 - brc - INFO - Average loss from batch 2601 to 2650 is 4.75701769352
2018-04-22 13:02:43,409 - brc - INFO - Average loss from batch 2651 to 2700 is 4.81558213234
2018-04-22 13:04:41,775 - brc - INFO - Average loss from batch 2701 to 2750 is 4.74923632622
2018-04-22 13:06:39,672 - brc - INFO - Average loss from batch 2751 to 2800 is 4.79667425156
2018-04-22 13:08:38,475 - brc - INFO - Average loss from batch 2801 to 2850 is 4.87040808678
2018-04-22 13:10:36,569 - brc - INFO - Average loss from batch 2851 to 2900 is 4.73637509823
2018-04-22 13:12:35,141 - brc - INFO - Average loss from batch 2901 to 2950 is 4.70886893749
2018-04-22 13:14:33,592 - brc - INFO - Average loss from batch 2951 to 3000 is 4.70921272278
2018-04-22 13:16:32,749 - brc - INFO - Average loss from batch 3001 to 3050 is 4.79179065228
2018-04-22 13:18:30,921 - brc - INFO - Average loss from batch 3051 to 3100 is 4.6565892458
2018-04-22 13:20:28,974 - brc - INFO - Average loss from batch 3101 to 3150 is 4.81708387852
2018-04-22 13:22:27,836 - brc - INFO - Average loss from batch 3151 to 3200 is 4.80681576729
2018-04-22 13:24:26,734 - brc - INFO - Average loss from batch 3201 to 3250 is 4.58163285255
2018-04-22 13:26:59,644 - brc - INFO - Average loss from batch 3251 to 3300 is 4.66392078876
2018-04-22 13:28:58,635 - brc - INFO - Average loss from batch 3301 to 3350 is 4.8163073349
2018-04-22 13:30:57,143 - brc - INFO - Average loss from batch 3351 to 3400 is 4.79517295361
2018-04-22 13:32:55,998 - brc - INFO - Average loss from batch 3401 to 3450 is 4.73956160545
2018-04-22 13:34:54,595 - brc - INFO - Average loss from batch 3451 to 3500 is 4.72456837177
2018-04-22 13:36:53,454 - brc - INFO - Average loss from batch 3501 to 3550 is 4.8771069622
2018-04-22 13:38:51,595 - brc - INFO - Average loss from batch 3551 to 3600 is 4.82203756809
2018-04-22 13:40:49,639 - brc - INFO - Average loss from batch 3601 to 3650 is 4.66965368271
2018-04-22 13:42:47,636 - brc - INFO - Average loss from batch 3651 to 3700 is 4.83855857849
2018-04-22 13:44:46,710 - brc - INFO - Average loss from batch 3701 to 3750 is 4.75622517586
2018-04-22 13:46:45,515 - brc - INFO - Average loss from batch 3751 to 3800 is 4.82403256416
2018-04-22 13:48:43,745 - brc - INFO - Average loss from batch 3801 to 3850 is 4.73959076405
2018-04-22 13:50:40,564 - brc - INFO - Average loss from batch 3851 to 3900 is 4.79385087013
2018-04-22 13:53:15,520 - brc - INFO - Average loss from batch 3901 to 3950 is 4.67444144249
2018-04-22 13:55:14,628 - brc - INFO - Average loss from batch 3951 to 4000 is 4.71997411728
2018-04-22 13:56:06,232 - brc - INFO - Evaluating the model ...
2018-04-22 14:14:05,331 - brc - INFO - Dev eval loss 8.42835710297
2018-04-22 14:14:05,333 - brc - INFO - Dev eval result: {'BLEU-4': 40.96, 'ROUGE-L': 48.34}
2018-04-22 14:15:11,549 - brc - INFO - Average loss from batch 4001 to 4050 is 4.66029068947
2018-04-22 14:17:10,461 - brc - INFO - Average loss from batch 4051 to 4100 is 4.71786621094
2018-04-22 14:19:09,661 - brc - INFO - Average loss from batch 4101 to 4150 is 4.73033493996
2018-04-22 14:21:08,504 - brc - INFO - Average loss from batch 4151 to 4200 is 4.93305194378
2018-04-22 14:23:07,838 - brc - INFO - Average loss from batch 4201 to 4250 is 4.79998314857
2018-04-22 14:25:42,529 - brc - INFO - Average loss from batch 4251 to 4300 is 4.80651266098
2018-04-22 14:27:41,599 - brc - INFO - Average loss from batch 4301 to 4350 is 4.67357051373
2018-04-22 14:29:40,545 - brc - INFO - Average loss from batch 4351 to 4400 is 4.73083305836
2018-04-22 14:31:39,081 - brc - INFO - Average loss from batch 4401 to 4450 is 4.71998250008
2018-04-22 14:33:38,869 - brc - INFO - Average loss from batch 4451 to 4500 is 4.79183193684
2018-04-22 14:35:36,305 - brc - INFO - Average loss from batch 4501 to 4550 is 4.80893666744
2018-04-22 14:37:32,183 - brc - INFO - Average loss from batch 4551 to 4600 is 4.80881099701
2018-04-22 14:39:29,028 - brc - INFO - Average loss from batch 4601 to 4650 is 4.77749940395
2018-04-22 14:41:25,641 - brc - INFO - Average loss from batch 4651 to 4700 is 4.89599559784
2018-04-22 14:43:22,431 - brc - INFO - Average loss from batch 4701 to 4750 is 4.7268932724
2018-04-22 14:45:18,986 - brc - INFO - Average loss from batch 4751 to 4800 is 4.64932245731
2018-04-22 14:47:15,748 - brc - INFO - Average loss from batch 4801 to 4850 is 4.76900139809
2018-04-22 14:49:12,505 - brc - INFO - Average loss from batch 4851 to 4900 is 4.87708563328
2018-04-22 14:51:45,759 - brc - INFO - Average loss from batch 4901 to 4950 is 4.71710610867
2018-04-22 14:53:41,989 - brc - INFO - Average loss from batch 4951 to 5000 is 4.78129889965
2018-04-22 14:55:39,660 - brc - INFO - Average loss from batch 5001 to 5050 is 4.76308912277
2018-04-22 14:57:37,614 - brc - INFO - Average loss from batch 5051 to 5100 is 4.75061569214
2018-04-22 14:59:36,396 - brc - INFO - Average loss from batch 5101 to 5150 is 4.73430269718
2018-04-22 15:01:35,972 - brc - INFO - Average loss from batch 5151 to 5200 is 4.77484944344
2018-04-22 15:03:34,481 - brc - INFO - Average loss from batch 5201 to 5250 is 4.71802269936
2018-04-22 15:05:34,021 - brc - INFO - Average loss from batch 5251 to 5300 is 4.88618169308
2018-04-22 15:07:33,998 - brc - INFO - Average loss from batch 5301 to 5350 is 4.82056434631
2018-04-22 15:09:33,447 - brc - INFO - Average loss from batch 5351 to 5400 is 4.71127654076
2018-04-22 15:11:31,825 - brc - INFO - Average loss from batch 5401 to 5450 is 4.73239155293
2018-04-22 15:13:30,027 - brc - INFO - Average loss from batch 5451 to 5500 is 4.63076773643
2018-04-22 15:15:27,800 - brc - INFO - Average loss from batch 5501 to 5550 is 4.83142119884
2018-04-22 15:18:05,336 - brc - INFO - Average loss from batch 5551 to 5600 is 4.74394006729
2018-04-22 15:20:03,185 - brc - INFO - Average loss from batch 5601 to 5650 is 4.8309134388
2018-04-22 15:22:01,801 - brc - INFO - Average loss from batch 5651 to 5700 is 4.79312536716
2018-04-22 15:24:01,209 - brc - INFO - Average loss from batch 5701 to 5750 is 4.66008830547
2018-04-22 15:26:01,255 - brc - INFO - Average loss from batch 5751 to 5800 is 4.91414700985
2018-04-22 15:27:59,987 - brc - INFO - Average loss from batch 5801 to 5850 is 4.74331809521
2018-04-22 15:29:59,567 - brc - INFO - Average loss from batch 5851 to 5900 is 4.84940978527
2018-04-22 15:31:58,941 - brc - INFO - Average loss from batch 5901 to 5950 is 4.63324837208
2018-04-22 15:33:57,789 - brc - INFO - Average loss from batch 5951 to 6000 is 4.79169039726
2018-04-22 15:35:15,875 - brc - INFO - Evaluating the model ...
2018-04-22 15:53:53,635 - brc - INFO - Dev eval loss 8.43490649261
2018-04-22 15:53:53,637 - brc - INFO - Dev eval result: {'BLEU-4': 40.76, 'ROUGE-L': 48.43}
2018-04-22 15:54:34,816 - brc - INFO - Average loss from batch 6001 to 6050 is 4.76454174042
2018-04-22 15:56:32,730 - brc - INFO - Average loss from batch 6051 to 6100 is 4.67209840298
2018-04-22 15:58:31,778 - brc - INFO - Average loss from batch 6101 to 6150 is 4.67900571823
2018-04-22 16:00:32,596 - brc - INFO - Average loss from batch 6151 to 6200 is 4.74750677109
2018-04-22 16:02:34,109 - brc - INFO - Average loss from batch 6201 to 6250 is 4.76486227989
2018-04-22 16:04:35,905 - brc - INFO - Average loss from batch 6251 to 6300 is 4.63754345894
2018-04-22 16:06:36,921 - brc - INFO - Average loss from batch 6301 to 6350 is 4.60751266479
2018-04-22 16:08:38,847 - brc - INFO - Average loss from batch 6351 to 6400 is 4.86654566765
2018-04-22 16:10:38,772 - brc - INFO - Average loss from batch 6401 to 6450 is 4.73507885933
2018-04-22 16:12:38,466 - brc - INFO - Average loss from batch 6451 to 6500 is 4.69004153252
2018-04-22 16:14:38,417 - brc - INFO - Average loss from batch 6501 to 6550 is 4.8902674675
2018-04-22 16:17:19,451 - brc - INFO - Average loss from batch 6551 to 6600 is 4.60292293549
2018-04-22 16:19:17,215 - brc - INFO - Average loss from batch 6601 to 6650 is 4.88585705757
2018-04-22 16:21:16,038 - brc - INFO - Average loss from batch 6651 to 6700 is 4.79224450588
2018-04-22 16:23:14,842 - brc - INFO - Average loss from batch 6701 to 6750 is 4.87202283382
2018-04-22 16:25:12,912 - brc - INFO - Average loss from batch 6751 to 6800 is 4.66320893288
2018-04-22 16:27:12,000 - brc - INFO - Average loss from batch 6801 to 6850 is 4.76723506451
2018-04-22 16:29:11,567 - brc - INFO - Average loss from batch 6851 to 6900 is 4.70890881062
2018-04-22 16:31:10,121 - brc - INFO - Average loss from batch 6901 to 6950 is 4.88657363892
2018-04-22 16:33:08,015 - brc - INFO - Average loss from batch 6951 to 7000 is 4.81314366341
2018-04-22 16:35:07,083 - brc - INFO - Average loss from batch 7001 to 7050 is 4.78413816452
2018-04-22 16:37:06,056 - brc - INFO - Average loss from batch 7051 to 7100 is 4.73586661339
2018-04-22 16:39:04,196 - brc - INFO - Average loss from batch 7101 to 7150 is 4.83429902077
2018-04-22 16:41:03,447 - brc - INFO - Average loss from batch 7151 to 7200 is 4.81024018764
2018-04-22 16:43:02,466 - brc - INFO - Average loss from batch 7201 to 7250 is 4.73228041172
2018-04-22 16:45:41,767 - brc - INFO - Average loss from batch 7251 to 7300 is 4.62022584438
2018-04-22 16:47:39,973 - brc - INFO - Average loss from batch 7301 to 7350 is 4.79689219952
2018-04-22 16:49:38,938 - brc - INFO - Average loss from batch 7351 to 7400 is 4.79847091198
2018-04-22 16:51:37,367 - brc - INFO - Average loss from batch 7401 to 7450 is 4.72246578217
2018-04-22 16:53:36,024 - brc - INFO - Average loss from batch 7451 to 7500 is 4.73018827438
2018-04-22 16:55:35,182 - brc - INFO - Average loss from batch 7501 to 7550 is 4.81899734497
2018-04-22 16:57:34,430 - brc - INFO - Average loss from batch 7551 to 7600 is 4.77054149628
2018-04-22 16:59:32,651 - brc - INFO - Average loss from batch 7601 to 7650 is 4.78560713291
2018-04-22 17:01:31,648 - brc - INFO - Average loss from batch 7651 to 7700 is 4.8474600172
2018-04-22 17:03:30,223 - brc - INFO - Average loss from batch 7701 to 7750 is 4.83774419785
2018-04-22 17:05:28,763 - brc - INFO - Average loss from batch 7751 to 7800 is 4.67684161663
2018-04-22 17:07:26,586 - brc - INFO - Average loss from batch 7801 to 7850 is 4.66152746677
2018-04-22 17:09:25,284 - brc - INFO - Average loss from batch 7851 to 7900 is 4.68161428452
2018-04-22 17:12:06,067 - brc - INFO - Average loss from batch 7901 to 7950 is 4.76176612377
2018-04-22 17:14:04,568 - brc - INFO - Average loss from batch 7951 to 8000 is 4.80844087601
2018-04-22 17:15:48,622 - brc - INFO - Evaluating the model ...
2018-04-22 17:33:44,546 - brc - INFO - Dev eval loss 8.44028720856
2018-04-22 17:33:44,548 - brc - INFO - Dev eval result: {'BLEU-4': 40.63, 'ROUGE-L': 48.23}
2018-04-22 17:33:49,156 - brc - INFO - Average train loss for epoch 1 is 4.75573796506
2018-04-22 17:33:49,160 - brc - INFO - Evaluating the model after epoch 1
2018-04-22 17:52:25,366 - brc - INFO - Dev eval loss 8.44039520798
2018-04-22 17:52:25,367 - brc - INFO - Dev eval result: {'BLEU-4': 40.67, 'ROUGE-L': 48.24}
2018-04-22 17:52:25,367 - brc - INFO - Training the model for epoch 2
2018-04-22 17:54:26,023 - brc - INFO - Average loss from batch 1 to 50 is 4.77905348301
2018-04-22 17:56:26,573 - brc - INFO - Average loss from batch 51 to 100 is 4.81390742302
2018-04-22 17:58:28,770 - brc - INFO - Average loss from batch 101 to 150 is 4.68130829334
2018-04-22 18:00:30,279 - brc - INFO - Average loss from batch 151 to 200 is 4.75981948853
2018-04-22 18:02:26,436 - brc - INFO - Running with args : Namespace(algo='BIDAF', batch_size=32, brc_dir='model/', char_embed='../../data/embedding/wiki_brc/wiki_brc.char.vec', char_hidden_size=100, dev_files=['../../data/preprocessed_ltp/devset/search.dev.filter.json', '../../data/preprocessed_ltp/devset/zhidao.dev.filter.json'], dropout_keep_prob=1, epochs=10, evaluate=False, gpu='0', hidden_size=150, learning_rate=1e-05, log_path='model/log', max_a_len=500, max_p_len=500, max_p_num=5, max_q_len=60, max_w_len=4, model_dir='model/', optim='adam', pos_embed_dim=10, pr_rate=0.2, predict=False, prepare=False, restore=True, result_dir='model/', summary_dir='model/', test_files=['../../data/test1set/preprocessed/search.test1.json', '../../data/test1set/preprocessed/zhidao.test1.json'], train=True, train_files=['../../data/preprocessed_ltp/trainset/search.train.filter.json', '../../data/preprocessed_ltp/trainset/zhidao.train.filter.json'], vocab_dir='model/', weight_decay=0, word_embed='../../data/embedding/wiki_brc/wiki_brc.word.vec')
2018-04-22 18:02:26,436 - brc - INFO - Load data_set and vocab...
2018-04-22 18:08:12,960 - brc - INFO - Train set size: 257469 questions.
2018-04-22 18:09:09,078 - brc - INFO - Dev set size: 10000 questions.
2018-04-22 18:09:09,079 - brc - INFO - Converting text into ids...
2018-04-22 18:19:19,344 - brc - INFO - Initialize the model...
2018-04-22 18:19:24,630 - brc - INFO - Time to build graph: 4.53623795509 s
2018-04-22 18:19:40,797 - brc - INFO - There are 3865506 parameters in the model
2018-04-22 18:19:42,913 - brc - INFO - Restoring the model...
2018-04-22 18:19:44,168 - brc - INFO - Model restored from model/, with prefix BIDAF
2018-04-22 18:19:44,169 - brc - INFO - Evaluating the model on dev set...
2018-04-22 18:37:57,828 - brc - INFO - Training the model...
2018-04-22 18:37:57,829 - brc - INFO - Training the model for epoch 1
2018-04-22 18:39:53,129 - brc - INFO - Average loss from batch 1 to 50 is 4.76340624809
2018-04-22 18:41:49,293 - brc - INFO - Average loss from batch 51 to 100 is 4.75351977825
2018-04-22 18:43:45,568 - brc - INFO - Average loss from batch 101 to 150 is 4.80397742748
2018-04-22 18:45:42,516 - brc - INFO - Average loss from batch 151 to 200 is 4.78953625202
2018-04-22 18:47:39,410 - brc - INFO - Average loss from batch 201 to 250 is 4.77972528934
2018-04-22 18:49:33,893 - brc - INFO - Average loss from batch 251 to 300 is 4.79725867748
2018-04-22 18:51:59,075 - brc - INFO - Average loss from batch 301 to 350 is 4.71636365891
2018-04-22 18:53:56,739 - brc - INFO - Average loss from batch 351 to 400 is 4.74073730469
2018-04-22 18:55:55,404 - brc - INFO - Average loss from batch 401 to 450 is 4.68046814442
2018-04-22 18:57:54,661 - brc - INFO - Average loss from batch 451 to 500 is 4.84739633083
2018-04-22 18:59:53,595 - brc - INFO - Average loss from batch 501 to 550 is 4.77786571026
2018-04-22 19:01:52,053 - brc - INFO - Average loss from batch 551 to 600 is 4.83517967224
2018-04-22 19:03:50,618 - brc - INFO - Average loss from batch 601 to 650 is 4.81992437363
2018-04-22 19:05:49,744 - brc - INFO - Average loss from batch 651 to 700 is 4.80074886799
2018-04-22 19:07:48,234 - brc - INFO - Average loss from batch 701 to 750 is 4.82855747223
2018-04-22 19:09:45,797 - brc - INFO - Average loss from batch 751 to 800 is 4.7124860096
2018-04-22 19:11:45,066 - brc - INFO - Average loss from batch 801 to 850 is 4.80942401409
2018-04-22 19:13:44,157 - brc - INFO - Average loss from batch 851 to 900 is 4.74419221401
2018-04-22 19:15:43,307 - brc - INFO - Average loss from batch 901 to 950 is 4.84845404148
2018-04-22 19:18:15,577 - brc - INFO - Average loss from batch 951 to 1000 is 4.85426945686
2018-04-22 19:20:17,737 - brc - INFO - Average loss from batch 1001 to 1050 is 4.78193386555
2018-04-22 19:22:18,783 - brc - INFO - Average loss from batch 1051 to 1100 is 4.63960570335
2018-04-22 19:24:21,100 - brc - INFO - Average loss from batch 1101 to 1150 is 4.63533401489
2018-04-22 19:26:22,948 - brc - INFO - Average loss from batch 1151 to 1200 is 4.7166171217
2018-04-22 19:28:22,920 - brc - INFO - Average loss from batch 1201 to 1250 is 4.77818046093
2018-04-22 19:30:20,524 - brc - INFO - Average loss from batch 1251 to 1300 is 4.80358111382
2018-04-22 19:32:22,006 - brc - INFO - Average loss from batch 1301 to 1350 is 4.80697053909
2018-04-22 19:34:23,393 - brc - INFO - Average loss from batch 1351 to 1400 is 4.7835374403
2018-04-22 19:36:23,009 - brc - INFO - Average loss from batch 1401 to 1450 is 4.86802917957
2018-04-22 19:38:22,693 - brc - INFO - Average loss from batch 1451 to 1500 is 4.6784383297
2018-04-22 19:40:22,277 - brc - INFO - Average loss from batch 1501 to 1550 is 4.67735434532
2018-04-22 19:42:22,722 - brc - INFO - Average loss from batch 1551 to 1600 is 4.71486586094
2018-04-22 19:44:56,041 - brc - INFO - Average loss from batch 1601 to 1650 is 4.7324773407
2018-04-22 19:46:56,052 - brc - INFO - Average loss from batch 1651 to 1700 is 4.76855840206
2018-04-22 19:48:54,820 - brc - INFO - Average loss from batch 1701 to 1750 is 4.77762229919
2018-04-22 19:50:52,999 - brc - INFO - Average loss from batch 1751 to 1800 is 4.74498614311
2018-04-22 19:52:50,605 - brc - INFO - Average loss from batch 1801 to 1850 is 4.74307745934
2018-04-22 19:54:49,490 - brc - INFO - Average loss from batch 1851 to 1900 is 4.82952545643
2018-04-22 19:56:47,987 - brc - INFO - Average loss from batch 1901 to 1950 is 4.75907128811
2018-04-22 19:58:46,509 - brc - INFO - Average loss from batch 1951 to 2000 is 4.71103937626
2018-04-22 19:59:12,572 - brc - INFO - Evaluating the model ...
2018-04-22 20:17:30,366 - brc - INFO - Dev eval loss 8.41217967911
2018-04-22 20:17:30,368 - brc - INFO - Dev eval result: {'BLEU-4': 41.05, 'ROUGE-L': 48.4}
2018-04-22 20:19:02,189 - brc - INFO - Average loss from batch 2001 to 2050 is 4.6929460144
2018-04-22 20:21:01,449 - brc - INFO - Average loss from batch 2051 to 2100 is 4.67627848148
2018-04-22 20:22:59,508 - brc - INFO - Average loss from batch 2101 to 2150 is 4.73589942932
2018-04-22 20:24:58,082 - brc - INFO - Average loss from batch 2151 to 2200 is 4.80030233383
2018-04-22 20:26:56,187 - brc - INFO - Average loss from batch 2201 to 2250 is 4.66243226051
2018-04-22 20:28:53,785 - brc - INFO - Average loss from batch 2251 to 2300 is 4.80098565102
2018-04-22 20:30:52,914 - brc - INFO - Average loss from batch 2301 to 2350 is 4.84285506248
2018-04-22 20:32:50,794 - brc - INFO - Average loss from batch 2351 to 2400 is 4.67916158199
2018-04-22 20:34:49,779 - brc - INFO - Average loss from batch 2401 to 2450 is 4.75367866039
2018-04-22 20:36:48,574 - brc - INFO - Average loss from batch 2451 to 2500 is 4.71740510941
2018-04-22 20:38:46,858 - brc - INFO - Average loss from batch 2501 to 2550 is 4.80465155125
2018-04-22 20:40:44,709 - brc - INFO - Average loss from batch 2551 to 2600 is 4.69394015789
2018-04-22 20:43:17,150 - brc - INFO - Average loss from batch 2601 to 2650 is 4.70344637394
2018-04-22 20:45:15,488 - brc - INFO - Average loss from batch 2651 to 2700 is 4.73500043392
2018-04-22 20:47:13,863 - brc - INFO - Average loss from batch 2701 to 2750 is 4.72910197258
2018-04-22 20:49:12,641 - brc - INFO - Average loss from batch 2751 to 2800 is 4.63663378239
2018-04-22 20:51:10,339 - brc - INFO - Average loss from batch 2801 to 2850 is 4.73701132298
2018-04-22 20:53:08,717 - brc - INFO - Average loss from batch 2851 to 2900 is 4.74677021503
2018-04-22 20:55:06,991 - brc - INFO - Average loss from batch 2901 to 2950 is 4.73339875221
2018-04-22 20:57:04,801 - brc - INFO - Average loss from batch 2951 to 3000 is 4.74843174934
2018-04-22 20:59:03,165 - brc - INFO - Average loss from batch 3001 to 3050 is 4.81096487045
2018-04-22 21:01:02,198 - brc - INFO - Average loss from batch 3051 to 3100 is 4.74959549427
2018-04-22 21:03:01,395 - brc - INFO - Average loss from batch 3101 to 3150 is 4.8006439352
2018-04-22 21:04:58,667 - brc - INFO - Average loss from batch 3151 to 3200 is 4.70845471382
2018-04-22 21:06:56,600 - brc - INFO - Average loss from batch 3201 to 3250 is 4.86616001129
2018-04-22 21:09:30,867 - brc - INFO - Average loss from batch 3251 to 3300 is 4.73974826813
2018-04-22 21:11:30,101 - brc - INFO - Average loss from batch 3301 to 3350 is 4.7286068821
2018-04-22 21:13:27,425 - brc - INFO - Average loss from batch 3351 to 3400 is 4.66185107231
2018-04-22 21:15:26,053 - brc - INFO - Average loss from batch 3401 to 3450 is 4.74448553085
2018-04-22 21:17:23,680 - brc - INFO - Average loss from batch 3451 to 3500 is 4.74645730972
2018-04-22 21:19:22,014 - brc - INFO - Average loss from batch 3501 to 3550 is 4.53949979782
2018-04-22 21:21:20,322 - brc - INFO - Average loss from batch 3551 to 3600 is 4.76751565933
2018-04-22 21:23:18,527 - brc - INFO - Average loss from batch 3601 to 3650 is 4.75081897736
2018-04-22 21:25:16,054 - brc - INFO - Average loss from batch 3651 to 3700 is 4.66926053524
2018-04-22 21:27:14,099 - brc - INFO - Average loss from batch 3701 to 3750 is 4.7513160944
2018-04-22 21:29:12,779 - brc - INFO - Average loss from batch 3751 to 3800 is 4.95305414677
2018-04-22 21:31:10,858 - brc - INFO - Average loss from batch 3801 to 3850 is 4.75961282253
2018-04-22 21:33:09,145 - brc - INFO - Average loss from batch 3851 to 3900 is 4.74551377296
2018-04-22 21:35:43,701 - brc - INFO - Average loss from batch 3901 to 3950 is 4.7855202198
2018-04-22 21:37:42,491 - brc - INFO - Average loss from batch 3951 to 4000 is 4.69486798763
2018-04-22 21:38:34,728 - brc - INFO - Evaluating the model ...
2018-04-22 21:56:24,472 - brc - INFO - Dev eval loss 8.41753679657
2018-04-22 21:56:24,474 - brc - INFO - Dev eval result: {'BLEU-4': 40.85, 'ROUGE-L': 48.45}
2018-04-22 21:57:30,090 - brc - INFO - Average loss from batch 4001 to 4050 is 4.60282004356
2018-04-22 21:59:29,506 - brc - INFO - Average loss from batch 4051 to 4100 is 4.67499028683
2018-04-22 22:01:28,174 - brc - INFO - Average loss from batch 4101 to 4150 is 4.72453598022
2018-04-22 22:03:26,614 - brc - INFO - Average loss from batch 4151 to 4200 is 4.85621162891
2018-04-22 22:05:24,513 - brc - INFO - Average loss from batch 4201 to 4250 is 4.71654860973
2018-04-22 22:07:58,959 - brc - INFO - Average loss from batch 4251 to 4300 is 4.74577001572
2018-04-22 22:09:55,804 - brc - INFO - Average loss from batch 4301 to 4350 is 4.81604147911
2018-04-22 22:11:52,297 - brc - INFO - Average loss from batch 4351 to 4400 is 4.82693549156
2018-04-22 22:13:48,560 - brc - INFO - Average loss from batch 4401 to 4450 is 4.70582422733
2018-04-22 22:15:44,713 - brc - INFO - Average loss from batch 4451 to 4500 is 4.72804377556
2018-04-22 22:17:40,836 - brc - INFO - Average loss from batch 4501 to 4550 is 4.74868201256
2018-04-22 22:19:37,335 - brc - INFO - Average loss from batch 4551 to 4600 is 4.71858086109
2018-04-22 22:21:35,027 - brc - INFO - Average loss from batch 4601 to 4650 is 4.83132466316
2018-04-22 22:23:33,172 - brc - INFO - Average loss from batch 4651 to 4700 is 4.81090616703
2018-04-22 22:25:29,021 - brc - INFO - Average loss from batch 4701 to 4750 is 4.80920807362
2018-04-22 22:27:25,292 - brc - INFO - Average loss from batch 4751 to 4800 is 4.79855132103
2018-04-22 22:29:22,656 - brc - INFO - Average loss from batch 4801 to 4850 is 4.64830665112
2018-04-22 22:31:21,368 - brc - INFO - Average loss from batch 4851 to 4900 is 4.80224278927
2018-04-22 22:33:57,927 - brc - INFO - Average loss from batch 4901 to 4950 is 4.79666845798
2018-04-22 22:35:56,416 - brc - INFO - Average loss from batch 4951 to 5000 is 4.79741368771
2018-04-22 22:37:54,797 - brc - INFO - Average loss from batch 5001 to 5050 is 4.65017543316
2018-04-22 22:39:52,778 - brc - INFO - Average loss from batch 5051 to 5100 is 4.69899943352
2018-04-22 22:41:50,864 - brc - INFO - Average loss from batch 5101 to 5150 is 4.75267328262
2018-04-22 22:43:49,522 - brc - INFO - Average loss from batch 5151 to 5200 is 4.71680143356
2018-04-22 22:45:48,522 - brc - INFO - Average loss from batch 5201 to 5250 is 4.78470062733
2018-04-22 22:47:47,581 - brc - INFO - Average loss from batch 5251 to 5300 is 4.70438427925
2018-04-22 22:49:45,442 - brc - INFO - Average loss from batch 5301 to 5350 is 4.77006708622
2018-04-22 22:51:43,833 - brc - INFO - Average loss from batch 5351 to 5400 is 4.76967022419
2018-04-22 22:53:42,268 - brc - INFO - Average loss from batch 5401 to 5450 is 4.75745220184
2018-04-22 22:55:40,413 - brc - INFO - Average loss from batch 5451 to 5500 is 4.80342382431
2018-04-22 22:57:38,891 - brc - INFO - Average loss from batch 5501 to 5550 is 4.83944899082
2018-04-22 23:00:17,259 - brc - INFO - Average loss from batch 5551 to 5600 is 4.76792208195
2018-04-22 23:02:14,868 - brc - INFO - Average loss from batch 5601 to 5650 is 4.55551165581
2018-04-22 23:04:13,204 - brc - INFO - Average loss from batch 5651 to 5700 is 4.7674922657
2018-04-22 23:06:11,584 - brc - INFO - Average loss from batch 5701 to 5750 is 4.73950231075
2018-04-22 23:08:10,938 - brc - INFO - Average loss from batch 5751 to 5800 is 4.67458743095
2018-04-22 23:10:10,153 - brc - INFO - Average loss from batch 5801 to 5850 is 4.66751060486
2018-04-22 23:12:07,230 - brc - INFO - Average loss from batch 5851 to 5900 is 4.73678771019
2018-04-22 23:14:06,284 - brc - INFO - Average loss from batch 5901 to 5950 is 4.69586491108
2018-04-22 23:16:05,083 - brc - INFO - Average loss from batch 5951 to 6000 is 4.70120369911
2018-04-22 23:17:22,748 - brc - INFO - Evaluating the model ...
2018-04-22 23:35:51,956 - brc - INFO - Dev eval loss 8.43770168152
2018-04-22 23:35:51,958 - brc - INFO - Dev eval result: {'BLEU-4': 40.86, 'ROUGE-L': 48.33}
2018-04-22 23:36:31,457 - brc - INFO - Average loss from batch 6001 to 6050 is 4.73486709595
2018-04-22 23:38:31,630 - brc - INFO - Average loss from batch 6051 to 6100 is 4.73160643101
2018-04-22 23:40:29,603 - brc - INFO - Average loss from batch 6101 to 6150 is 4.8177647543
2018-04-22 23:42:28,176 - brc - INFO - Average loss from batch 6151 to 6200 is 4.88938279152
2018-04-22 23:44:26,887 - brc - INFO - Average loss from batch 6201 to 6250 is 4.68598261356
2018-04-22 23:46:25,074 - brc - INFO - Average loss from batch 6251 to 6300 is 4.76404361248
2018-04-22 23:48:23,659 - brc - INFO - Average loss from batch 6301 to 6350 is 4.80396952152
2018-04-22 23:50:21,200 - brc - INFO - Average loss from batch 6351 to 6400 is 4.92600996971
2018-04-22 23:52:18,542 - brc - INFO - Average loss from batch 6401 to 6450 is 4.85777634144
2018-04-22 23:54:17,409 - brc - INFO - Average loss from batch 6451 to 6500 is 4.78875434399
2018-04-22 23:56:15,351 - brc - INFO - Average loss from batch 6501 to 6550 is 4.72990210533
2018-04-22 23:58:53,638 - brc - INFO - Average loss from batch 6551 to 6600 is 4.78247742176
2018-04-23 00:00:51,003 - brc - INFO - Average loss from batch 6601 to 6650 is 4.77924350262
2018-04-23 00:02:48,747 - brc - INFO - Average loss from batch 6651 to 6700 is 4.69190423012
2018-04-23 00:04:46,354 - brc - INFO - Average loss from batch 6701 to 6750 is 4.65087936878
2018-04-23 00:06:44,349 - brc - INFO - Average loss from batch 6751 to 6800 is 4.58918058395
2018-04-23 00:08:42,545 - brc - INFO - Average loss from batch 6801 to 6850 is 4.69969151974
2018-04-23 00:10:41,506 - brc - INFO - Average loss from batch 6851 to 6900 is 4.67063921928
2018-04-23 00:12:40,503 - brc - INFO - Average loss from batch 6901 to 6950 is 4.78427487373
2018-04-23 00:14:39,169 - brc - INFO - Average loss from batch 6951 to 7000 is 4.70946741581
2018-04-23 00:16:37,450 - brc - INFO - Average loss from batch 7001 to 7050 is 4.76520833492
2018-04-23 00:18:35,101 - brc - INFO - Average loss from batch 7051 to 7100 is 4.86099083424
2018-04-23 00:20:32,848 - brc - INFO - Average loss from batch 7101 to 7150 is 4.8168676424
2018-04-23 00:22:30,075 - brc - INFO - Average loss from batch 7151 to 7200 is 4.7638623333
2018-04-23 00:24:28,298 - brc - INFO - Average loss from batch 7201 to 7250 is 4.7207689476
2018-04-23 00:27:08,793 - brc - INFO - Average loss from batch 7251 to 7300 is 4.59794844627
2018-04-23 00:29:06,904 - brc - INFO - Average loss from batch 7301 to 7350 is 4.71804156303
2018-04-23 00:31:05,294 - brc - INFO - Average loss from batch 7351 to 7400 is 4.78151988506
2018-04-23 00:33:03,895 - brc - INFO - Average loss from batch 7401 to 7450 is 4.64257464886
2018-04-23 00:35:01,903 - brc - INFO - Average loss from batch 7451 to 7500 is 4.90424659729
2018-04-23 00:37:01,043 - brc - INFO - Average loss from batch 7501 to 7550 is 4.82873680592
2018-04-23 00:38:59,043 - brc - INFO - Average loss from batch 7551 to 7600 is 4.80624559402
2018-04-23 00:40:55,958 - brc - INFO - Average loss from batch 7601 to 7650 is 4.91498638153
2018-04-23 00:42:54,158 - brc - INFO - Average loss from batch 7651 to 7700 is 4.81142751694
2018-04-23 00:44:52,621 - brc - INFO - Average loss from batch 7701 to 7750 is 4.61529907703
2018-04-23 00:46:50,711 - brc - INFO - Average loss from batch 7751 to 7800 is 4.87364798546
2018-04-23 00:48:48,035 - brc - INFO - Average loss from batch 7801 to 7850 is 4.69813158989
2018-04-23 00:50:44,246 - brc - INFO - Average loss from batch 7851 to 7900 is 4.74675036907
2018-04-23 00:53:22,688 - brc - INFO - Average loss from batch 7901 to 7950 is 4.77002185345
2018-04-23 00:55:18,651 - brc - INFO - Average loss from batch 7951 to 8000 is 4.8297567749
2018-04-23 00:57:01,301 - brc - INFO - Evaluating the model ...
2018-04-23 01:14:44,940 - brc - INFO - Dev eval loss 8.43241391602
2018-04-23 01:14:44,942 - brc - INFO - Dev eval result: {'BLEU-4': 40.88, 'ROUGE-L': 48.3}
2018-04-23 01:14:49,503 - brc - INFO - Average train loss for epoch 1 is 4.753497733
2018-04-23 01:14:49,507 - brc - INFO - Evaluating the model after epoch 1
2018-04-23 01:33:53,100 - brc - INFO - Dev eval loss 8.43251670532
2018-04-23 01:33:53,100 - brc - INFO - Dev eval result: {'BLEU-4': 40.89, 'ROUGE-L': 48.3}
2018-04-23 01:33:53,100 - brc - INFO - Training the model for epoch 2
2018-04-23 01:35:56,109 - brc - INFO - Average loss from batch 1 to 50 is 4.65760076046
2018-04-23 01:37:58,223 - brc - INFO - Average loss from batch 51 to 100 is 4.71259655476
2018-04-23 01:40:02,656 - brc - INFO - Average loss from batch 101 to 150 is 4.86807768345
2018-04-23 01:42:06,911 - brc - INFO - Average loss from batch 151 to 200 is 4.72850105762
2018-04-23 01:44:12,953 - brc - INFO - Average loss from batch 201 to 250 is 4.74034237862
2018-04-23 01:46:18,508 - brc - INFO - Average loss from batch 251 to 300 is 4.66822073936
2018-04-23 01:48:24,196 - brc - INFO - Average loss from batch 301 to 350 is 4.757867589
2018-04-23 01:50:30,314 - brc - INFO - Average loss from batch 351 to 400 is 4.71700972557
2018-04-23 01:52:37,072 - brc - INFO - Average loss from batch 401 to 450 is 4.84882698059
2018-04-23 01:54:45,105 - brc - INFO - Average loss from batch 451 to 500 is 4.76401305199
2018-04-23 01:56:51,769 - brc - INFO - Average loss from batch 501 to 550 is 4.5909331274
2018-04-23 01:58:59,309 - brc - INFO - Average loss from batch 551 to 600 is 4.71982065678
2018-04-23 02:01:52,464 - brc - INFO - Average loss from batch 601 to 650 is 4.71317047119
2018-04-23 02:04:01,563 - brc - INFO - Average loss from batch 651 to 700 is 4.61013874531
2018-04-23 02:06:08,018 - brc - INFO - Average loss from batch 701 to 750 is 4.73828557014
2018-04-23 02:08:15,433 - brc - INFO - Average loss from batch 751 to 800 is 4.83741687298
2018-04-23 02:10:23,358 - brc - INFO - Average loss from batch 801 to 850 is 4.72750109196
2018-04-23 02:12:29,739 - brc - INFO - Average loss from batch 851 to 900 is 4.72280511856
2018-04-23 02:14:36,380 - brc - INFO - Average loss from batch 901 to 950 is 4.7532490015
2018-04-23 02:16:44,526 - brc - INFO - Average loss from batch 951 to 1000 is 4.65141057014
2018-04-23 02:18:51,338 - brc - INFO - Average loss from batch 1001 to 1050 is 4.67441864967
2018-04-23 02:20:59,114 - brc - INFO - Average loss from batch 1051 to 1100 is 4.59533921719
2018-04-23 02:23:07,480 - brc - INFO - Average loss from batch 1101 to 1150 is 4.82153279781
2018-04-23 02:25:15,223 - brc - INFO - Average loss from batch 1151 to 1200 is 4.73329575062
2018-04-23 02:27:22,141 - brc - INFO - Average loss from batch 1201 to 1250 is 4.74391236305
2018-04-23 02:30:15,456 - brc - INFO - Average loss from batch 1251 to 1300 is 4.68953605175
2018-04-23 02:32:22,831 - brc - INFO - Average loss from batch 1301 to 1350 is 4.72709606647
2018-04-23 02:34:31,703 - brc - INFO - Average loss from batch 1351 to 1400 is 4.80418701172
2018-04-23 02:36:39,402 - brc - INFO - Average loss from batch 1401 to 1450 is 4.74522179127
2018-04-23 02:38:46,778 - brc - INFO - Average loss from batch 1451 to 1500 is 4.66317579746
2018-04-23 02:40:55,200 - brc - INFO - Average loss from batch 1501 to 1550 is 4.76688426971
2018-04-23 02:43:03,121 - brc - INFO - Average loss from batch 1551 to 1600 is 4.64474978924
2018-04-23 02:45:10,949 - brc - INFO - Average loss from batch 1601 to 1650 is 4.7666091013
2018-04-23 02:47:17,209 - brc - INFO - Average loss from batch 1651 to 1700 is 4.82528853893
2018-04-23 02:49:25,050 - brc - INFO - Average loss from batch 1701 to 1750 is 4.77195096016
2018-04-23 02:51:32,793 - brc - INFO - Average loss from batch 1751 to 1800 is 4.87503144264
2018-04-23 02:53:40,026 - brc - INFO - Average loss from batch 1801 to 1850 is 4.74155712128
2018-04-23 02:55:47,652 - brc - INFO - Average loss from batch 1851 to 1900 is 4.5772441721
2018-04-23 02:57:56,056 - brc - INFO - Average loss from batch 1901 to 1950 is 4.82225732327
2018-04-23 03:00:54,046 - brc - INFO - Average loss from batch 1951 to 2000 is 4.78745671272
2018-04-23 03:01:22,441 - brc - INFO - Evaluating the model ...
2018-04-23 03:20:19,992 - brc - INFO - Dev eval loss 8.43318650894
2018-04-23 03:20:19,992 - brc - INFO - Dev eval result: {'BLEU-4': 40.72, 'ROUGE-L': 48.38}
2018-04-23 03:21:59,756 - brc - INFO - Average loss from batch 2001 to 2050 is 4.61974281311
2018-04-23 03:24:08,299 - brc - INFO - Average loss from batch 2051 to 2100 is 4.67321782112
2018-04-23 03:26:16,239 - brc - INFO - Average loss from batch 2101 to 2150 is 4.81564601421
2018-04-23 03:28:23,186 - brc - INFO - Average loss from batch 2151 to 2200 is 4.69049175262
2018-04-23 03:30:30,767 - brc - INFO - Average loss from batch 2201 to 2250 is 4.73782752514
2018-04-23 03:32:38,264 - brc - INFO - Average loss from batch 2251 to 2300 is 4.84012631893
2018-04-23 03:35:31,971 - brc - INFO - Average loss from batch 2301 to 2350 is 4.78330370426
2018-04-23 03:37:40,523 - brc - INFO - Average loss from batch 2351 to 2400 is 4.65256266117
2018-04-23 03:39:46,590 - brc - INFO - Average loss from batch 2401 to 2450 is 4.8966349411
2018-04-23 03:41:49,103 - brc - INFO - Average loss from batch 2451 to 2500 is 4.7644614172
2018-04-23 03:43:51,138 - brc - INFO - Average loss from batch 2501 to 2550 is 4.87304043293
2018-04-23 03:45:51,274 - brc - INFO - Average loss from batch 2551 to 2600 is 4.76367512226
2018-04-23 03:47:52,483 - brc - INFO - Average loss from batch 2601 to 2650 is 4.66611832142
2018-04-23 03:49:52,199 - brc - INFO - Average loss from batch 2651 to 2700 is 4.72043386459
2018-04-23 03:51:52,775 - brc - INFO - Average loss from batch 2701 to 2750 is 4.74890049458
2018-04-23 03:53:53,316 - brc - INFO - Average loss from batch 2751 to 2800 is 4.79740999699
2018-04-23 03:55:52,605 - brc - INFO - Average loss from batch 2801 to 2850 is 4.72024359226
2018-04-23 03:57:52,487 - brc - INFO - Average loss from batch 2851 to 2900 is 4.84125100136
2018-04-23 03:59:51,840 - brc - INFO - Average loss from batch 2901 to 2950 is 4.68369884968
2018-04-23 04:01:51,376 - brc - INFO - Average loss from batch 2951 to 3000 is 4.77420309067
2018-04-23 04:04:39,844 - brc - INFO - Average loss from batch 3001 to 3050 is 4.53726719856
2018-04-23 04:06:43,622 - brc - INFO - Average loss from batch 3051 to 3100 is 4.71404983044
2018-04-23 04:08:46,566 - brc - INFO - Average loss from batch 3101 to 3150 is 4.89050811768
2018-04-23 04:10:49,671 - brc - INFO - Average loss from batch 3151 to 3200 is 4.61107675076
2018-04-23 04:12:52,460 - brc - INFO - Average loss from batch 3201 to 3250 is 4.71095552444
2018-04-23 04:14:56,655 - brc - INFO - Average loss from batch 3251 to 3300 is 4.67291949749
2018-04-23 04:16:59,373 - brc - INFO - Average loss from batch 3301 to 3350 is 4.71941628933
2018-04-23 04:19:01,773 - brc - INFO - Average loss from batch 3351 to 3400 is 4.63926245689
2018-04-23 04:21:04,711 - brc - INFO - Average loss from batch 3401 to 3450 is 4.86783376694
2018-04-23 04:23:07,144 - brc - INFO - Average loss from batch 3451 to 3500 is 4.72329768181
2018-04-23 04:25:09,577 - brc - INFO - Average loss from batch 3501 to 3550 is 4.73424278259
2018-04-23 04:27:12,620 - brc - INFO - Average loss from batch 3551 to 3600 is 4.70649048328
2018-04-23 04:29:14,277 - brc - INFO - Average loss from batch 3601 to 3650 is 4.90100819588
2018-04-23 04:32:00,455 - brc - INFO - Average loss from batch 3651 to 3700 is 4.71569004536
2018-04-23 04:34:03,842 - brc - INFO - Average loss from batch 3701 to 3750 is 4.76270598888
2018-04-23 04:36:06,968 - brc - INFO - Average loss from batch 3751 to 3800 is 4.78468380928
2018-04-23 04:38:10,278 - brc - INFO - Average loss from batch 3801 to 3850 is 4.84657678604
2018-04-23 04:40:13,646 - brc - INFO - Average loss from batch 3851 to 3900 is 4.80445848942
2018-04-23 04:42:15,603 - brc - INFO - Average loss from batch 3901 to 3950 is 4.60195312023
2018-04-23 04:44:18,444 - brc - INFO - Average loss from batch 3951 to 4000 is 4.73176055908
2018-04-23 04:45:12,304 - brc - INFO - Evaluating the model ...
2018-04-23 05:03:15,968 - brc - INFO - Dev eval loss 8.44102657852
2018-04-23 05:03:15,969 - brc - INFO - Dev eval result: {'BLEU-4': 40.71, 'ROUGE-L': 48.33}
2018-04-23 05:04:23,987 - brc - INFO - Average loss from batch 4001 to 4050 is 4.71299320698
2018-04-23 05:07:13,835 - brc - INFO - Average loss from batch 4051 to 4100 is 4.71669831276
2018-04-23 05:09:16,486 - brc - INFO - Average loss from batch 4101 to 4150 is 4.82159111023
2018-04-23 05:11:19,978 - brc - INFO - Average loss from batch 4151 to 4200 is 4.79604755878
2018-04-23 05:13:23,206 - brc - INFO - Average loss from batch 4201 to 4250 is 4.74586895943
2018-04-23 05:15:26,087 - brc - INFO - Average loss from batch 4251 to 4300 is 4.67246334076
2018-04-23 05:17:28,027 - brc - INFO - Average loss from batch 4301 to 4350 is 4.84862419128
2018-04-23 05:19:29,384 - brc - INFO - Average loss from batch 4351 to 4400 is 4.73353392601
2018-04-23 05:21:32,414 - brc - INFO - Average loss from batch 4401 to 4450 is 4.7775836277
2018-04-23 05:23:35,323 - brc - INFO - Average loss from batch 4451 to 4500 is 4.75106314182
2018-04-23 05:25:37,927 - brc - INFO - Average loss from batch 4501 to 4550 is 4.67209154129
2018-04-23 05:27:40,517 - brc - INFO - Average loss from batch 4551 to 4600 is 4.71714037895
2018-04-23 05:29:42,731 - brc - INFO - Average loss from batch 4601 to 4650 is 4.64140685558
2018-04-23 05:31:44,771 - brc - INFO - Average loss from batch 4651 to 4700 is 4.67627857685
2018-04-23 05:34:34,916 - brc - INFO - Average loss from batch 4701 to 4750 is 4.69357840538
2018-04-23 05:36:39,644 - brc - INFO - Average loss from batch 4751 to 4800 is 4.84043825626
2018-04-23 05:38:42,465 - brc - INFO - Average loss from batch 4801 to 4850 is 4.70772974491
2018-04-23 05:40:44,784 - brc - INFO - Average loss from batch 4851 to 4900 is 4.76070492744
2018-04-23 05:42:46,552 - brc - INFO - Average loss from batch 4901 to 4950 is 4.64218924046
2018-04-23 05:44:48,703 - brc - INFO - Average loss from batch 4951 to 5000 is 4.761965518
2018-04-23 05:46:48,542 - brc - INFO - Average loss from batch 5001 to 5050 is 4.74754695415
2018-04-23 05:48:49,145 - brc - INFO - Average loss from batch 5051 to 5100 is 4.62490906715
2018-04-23 05:50:49,934 - brc - INFO - Average loss from batch 5101 to 5150 is 4.8639352417
2018-04-23 05:52:50,385 - brc - INFO - Average loss from batch 5151 to 5200 is 4.68261401176
2018-04-23 05:54:50,320 - brc - INFO - Average loss from batch 5201 to 5250 is 4.66907063007
2018-04-23 05:56:49,483 - brc - INFO - Average loss from batch 5251 to 5300 is 4.74433013439
2018-04-23 05:58:50,268 - brc - INFO - Average loss from batch 5301 to 5350 is 4.72320453644
2018-04-23 06:00:48,975 - brc - INFO - Average loss from batch 5351 to 5400 is 4.71064678192
2018-04-23 06:03:38,505 - brc - INFO - Average loss from batch 5401 to 5450 is 4.80882223129
2018-04-23 06:05:40,679 - brc - INFO - Average loss from batch 5451 to 5500 is 4.70868191719
2018-04-23 06:07:44,066 - brc - INFO - Average loss from batch 5501 to 5550 is 4.63657223225
2018-04-23 06:09:46,587 - brc - INFO - Average loss from batch 5551 to 5600 is 4.77275525093
2018-04-23 06:11:49,648 - brc - INFO - Average loss from batch 5601 to 5650 is 4.75169538498
2018-04-23 06:13:53,934 - brc - INFO - Average loss from batch 5651 to 5700 is 4.72433492661
2018-04-23 06:15:56,364 - brc - INFO - Average loss from batch 5701 to 5750 is 4.69087203503
2018-04-23 06:17:58,458 - brc - INFO - Average loss from batch 5751 to 5800 is 4.71463467121
2018-04-23 06:20:02,477 - brc - INFO - Average loss from batch 5801 to 5850 is 4.86220888138
2018-04-23 06:22:05,008 - brc - INFO - Average loss from batch 5851 to 5900 is 4.86111645699
2018-04-23 06:24:08,614 - brc - INFO - Average loss from batch 5901 to 5950 is 4.72961128712
2018-04-23 06:26:11,104 - brc - INFO - Average loss from batch 5951 to 6000 is 4.67568575859
2018-04-23 06:27:31,575 - brc - INFO - Evaluating the model ...
2018-04-23 06:46:27,409 - brc - INFO - Dev eval loss 8.44903710785
2018-04-23 06:46:27,411 - brc - INFO - Dev eval result: {'BLEU-4': 40.78, 'ROUGE-L': 48.33}
2018-04-23 06:47:07,716 - brc - INFO - Average loss from batch 6001 to 6050 is 4.62534000874
2018-04-23 06:49:10,651 - brc - INFO - Average loss from batch 6051 to 6100 is 4.78556432247
2018-04-23 06:51:14,698 - brc - INFO - Average loss from batch 6101 to 6150 is 4.79961058617
2018-04-23 06:53:18,848 - brc - INFO - Average loss from batch 6151 to 6200 is 4.66892478943
2018-04-23 06:55:21,743 - brc - INFO - Average loss from batch 6201 to 6250 is 4.59977221489
2018-04-23 06:57:25,080 - brc - INFO - Average loss from batch 6251 to 6300 is 4.81114517689
2018-04-23 06:59:28,027 - brc - INFO - Average loss from batch 6301 to 6350 is 4.64065522671
2018-04-23 07:01:30,337 - brc - INFO - Average loss from batch 6351 to 6400 is 4.84019299507
2018-04-23 07:04:22,308 - brc - INFO - Average loss from batch 6401 to 6450 is 4.79457756042
2018-04-23 07:06:25,944 - brc - INFO - Average loss from batch 6451 to 6500 is 4.78510461807
2018-04-23 07:08:28,984 - brc - INFO - Average loss from batch 6501 to 6550 is 4.68424481392
2018-04-23 07:10:31,733 - brc - INFO - Average loss from batch 6551 to 6600 is 4.9006316185
2018-04-23 07:12:34,910 - brc - INFO - Average loss from batch 6601 to 6650 is 4.68131189346
2018-04-23 07:14:38,089 - brc - INFO - Average loss from batch 6651 to 6700 is 4.69311292648
2018-04-23 07:16:40,080 - brc - INFO - Average loss from batch 6701 to 6750 is 4.6962263298
2018-04-23 07:18:43,001 - brc - INFO - Average loss from batch 6751 to 6800 is 4.7072425127
2018-04-23 07:20:44,541 - brc - INFO - Average loss from batch 6801 to 6850 is 4.75280759811
2018-04-23 07:22:46,621 - brc - INFO - Average loss from batch 6851 to 6900 is 4.68394499302
2018-04-23 07:24:49,647 - brc - INFO - Average loss from batch 6901 to 6950 is 4.83392096519
2018-04-23 07:26:52,321 - brc - INFO - Average loss from batch 6951 to 7000 is 4.73154067516
2018-04-23 07:28:54,843 - brc - INFO - Average loss from batch 7001 to 7050 is 4.76637184143
2018-04-23 07:30:56,849 - brc - INFO - Average loss from batch 7051 to 7100 is 4.7687238121
2018-04-23 07:33:48,556 - brc - INFO - Average loss from batch 7101 to 7150 is 4.70167197704
2018-04-23 07:35:51,534 - brc - INFO - Average loss from batch 7151 to 7200 is 4.60675268173
2018-04-23 07:37:54,786 - brc - INFO - Average loss from batch 7201 to 7250 is 4.82764855862
2018-04-23 07:39:58,144 - brc - INFO - Average loss from batch 7251 to 7300 is 4.65221823215
2018-04-23 07:42:00,633 - brc - INFO - Average loss from batch 7301 to 7350 is 4.78802854061
2018-04-23 07:44:01,104 - brc - INFO - Average loss from batch 7351 to 7400 is 4.73156342506
2018-04-23 07:46:01,053 - brc - INFO - Average loss from batch 7401 to 7450 is 4.81516903877
2018-04-23 07:48:00,414 - brc - INFO - Average loss from batch 7451 to 7500 is 4.68353625298
2018-04-23 07:50:00,062 - brc - INFO - Average loss from batch 7501 to 7550 is 4.74642959595
2018-04-23 07:52:01,229 - brc - INFO - Average loss from batch 7551 to 7600 is 4.72082056046
2018-04-23 07:54:02,402 - brc - INFO - Average loss from batch 7601 to 7650 is 4.70610719204
2018-04-23 07:56:00,900 - brc - INFO - Average loss from batch 7651 to 7700 is 4.89781846046
2018-04-23 07:57:59,343 - brc - INFO - Average loss from batch 7701 to 7750 is 4.63292598724
2018-04-23 07:59:59,851 - brc - INFO - Average loss from batch 7751 to 7800 is 4.78573374748
2018-04-23 08:02:51,076 - brc - INFO - Average loss from batch 7801 to 7850 is 4.79946509838
2018-04-23 08:04:54,634 - brc - INFO - Average loss from batch 7851 to 7900 is 4.76960493565
2018-04-23 08:06:58,723 - brc - INFO - Average loss from batch 7901 to 7950 is 4.67677902222
2018-04-23 08:09:01,496 - brc - INFO - Average loss from batch 7951 to 8000 is 4.70041334152
2018-04-23 08:10:49,190 - brc - INFO - Evaluating the model ...
2018-04-23 08:28:56,366 - brc - INFO - Dev eval loss 8.45517083511
2018-04-23 08:28:56,368 - brc - INFO - Dev eval result: {'BLEU-4': 40.81, 'ROUGE-L': 48.35}
2018-04-23 08:29:01,245 - brc - INFO - Average train loss for epoch 2 is 4.73711327715
2018-04-23 08:29:01,256 - brc - INFO - Evaluating the model after epoch 2
2018-04-23 08:48:07,476 - brc - INFO - Dev eval loss 8.45512088928
2018-04-23 08:48:07,476 - brc - INFO - Dev eval result: {'BLEU-4': 40.83, 'ROUGE-L': 48.37}
2018-04-23 08:48:07,478 - brc - INFO - Training the model for epoch 3
2018-04-23 08:50:10,009 - brc - INFO - Average loss from batch 1 to 50 is 4.66378683567
2018-04-23 08:52:12,887 - brc - INFO - Average loss from batch 51 to 100 is 4.67022378922
2018-04-23 08:54:16,171 - brc - INFO - Average loss from batch 101 to 150 is 4.69201728821
2018-04-23 08:56:19,231 - brc - INFO - Average loss from batch 151 to 200 is 4.51770359993
2018-04-23 08:58:21,547 - brc - INFO - Average loss from batch 201 to 250 is 4.69804246426
2018-04-23 09:00:23,263 - brc - INFO - Average loss from batch 251 to 300 is 4.70096439362
2018-04-23 09:02:25,723 - brc - INFO - Average loss from batch 301 to 350 is 4.66893491268
2018-04-23 09:04:28,140 - brc - INFO - Average loss from batch 351 to 400 is 4.6320775795
2018-04-23 09:06:30,790 - brc - INFO - Average loss from batch 401 to 450 is 4.71429448128
2018-04-23 09:09:26,010 - brc - INFO - Average loss from batch 451 to 500 is 4.84567632198
2018-04-23 09:11:29,960 - brc - INFO - Average loss from batch 501 to 550 is 4.68130334377
2018-04-23 09:13:35,364 - brc - INFO - Average loss from batch 551 to 600 is 4.62094368935
2018-04-23 09:15:39,093 - brc - INFO - Average loss from batch 601 to 650 is 4.74973531723
2018-04-23 09:17:43,183 - brc - INFO - Average loss from batch 651 to 700 is 4.75783122063
2018-04-23 09:19:45,376 - brc - INFO - Average loss from batch 701 to 750 is 4.69406768799
2018-04-23 09:21:47,806 - brc - INFO - Average loss from batch 751 to 800 is 4.80187233448
2018-04-23 09:23:50,832 - brc - INFO - Average loss from batch 801 to 850 is 4.8196762991
2018-04-23 09:25:54,089 - brc - INFO - Average loss from batch 851 to 900 is 4.79067360878
2018-04-23 09:27:57,336 - brc - INFO - Average loss from batch 901 to 950 is 4.71114699841
2018-04-23 09:30:00,585 - brc - INFO - Average loss from batch 951 to 1000 is 4.76964945316
2018-04-23 09:32:03,264 - brc - INFO - Average loss from batch 1001 to 1050 is 4.82977822781
2018-04-23 09:34:06,590 - brc - INFO - Average loss from batch 1051 to 1100 is 4.65193564415
2018-04-23 09:36:08,400 - brc - INFO - Average loss from batch 1101 to 1150 is 4.66084551811
2018-04-23 09:39:02,593 - brc - INFO - Average loss from batch 1151 to 1200 is 4.72779149055
2018-04-23 09:41:05,411 - brc - INFO - Average loss from batch 1201 to 1250 is 4.78474839211
2018-04-23 09:43:06,710 - brc - INFO - Average loss from batch 1251 to 1300 is 4.76062485218
2018-04-23 09:45:07,884 - brc - INFO - Average loss from batch 1301 to 1350 is 4.78865980625
2018-04-23 09:47:08,797 - brc - INFO - Average loss from batch 1351 to 1400 is 4.77609876633
2018-04-23 09:49:10,328 - brc - INFO - Average loss from batch 1401 to 1450 is 4.76208983421
2018-04-23 09:51:11,498 - brc - INFO - Average loss from batch 1451 to 1500 is 4.708923316
2018-04-23 09:53:13,026 - brc - INFO - Average loss from batch 1501 to 1550 is 4.7245994091
2018-04-23 09:55:13,270 - brc - INFO - Average loss from batch 1551 to 1600 is 4.8102471447
2018-04-23 09:57:14,436 - brc - INFO - Average loss from batch 1601 to 1650 is 4.75055947304
2018-04-23 09:59:14,334 - brc - INFO - Average loss from batch 1651 to 1700 is 4.73908297539
2018-04-23 10:01:14,756 - brc - INFO - Average loss from batch 1701 to 1750 is 4.72855138779
2018-04-23 10:03:15,673 - brc - INFO - Average loss from batch 1751 to 1800 is 4.71255763531
2018-04-23 10:06:03,994 - brc - INFO - Average loss from batch 1801 to 1850 is 4.80861256599
2018-04-23 10:08:05,154 - brc - INFO - Average loss from batch 1851 to 1900 is 4.67000334263
2018-04-23 10:10:07,030 - brc - INFO - Average loss from batch 1901 to 1950 is 4.51956106186
2018-04-23 10:12:08,087 - brc - INFO - Average loss from batch 1951 to 2000 is 4.72500864983
2018-04-23 10:12:34,809 - brc - INFO - Evaluating the model ...
2018-04-23 10:30:45,268 - brc - INFO - Dev eval loss 8.46417952042
2018-04-23 10:30:45,270 - brc - INFO - Dev eval result: {'BLEU-4': 40.95, 'ROUGE-L': 48.29}
2018-04-23 10:32:20,313 - brc - INFO - Average loss from batch 2001 to 2050 is 4.7252188921
2018-04-23 10:34:26,213 - brc - INFO - Average loss from batch 2051 to 2100 is 4.7652357769
2018-04-23 10:36:29,421 - brc - INFO - Average loss from batch 2101 to 2150 is 4.68374236107
2018-04-23 10:39:20,911 - brc - INFO - Average loss from batch 2151 to 2200 is 4.77732779026
2018-04-23 10:41:26,813 - brc - INFO - Average loss from batch 2201 to 2250 is 4.78704780579
2018-04-23 10:43:34,303 - brc - INFO - Average loss from batch 2251 to 2300 is 4.72279504776
2018-04-23 10:45:39,090 - brc - INFO - Average loss from batch 2301 to 2350 is 4.74219714642
2018-04-23 10:47:42,777 - brc - INFO - Average loss from batch 2351 to 2400 is 4.68678246021
2018-04-23 10:49:47,203 - brc - INFO - Average loss from batch 2401 to 2450 is 4.70425862789
2018-04-23 10:51:48,911 - brc - INFO - Average loss from batch 2451 to 2500 is 4.69724924088
2018-04-23 10:53:49,786 - brc - INFO - Average loss from batch 2501 to 2550 is 4.65784715652
2018-04-23 10:55:50,931 - brc - INFO - Average loss from batch 2551 to 2600 is 4.76129410744
2018-04-23 10:57:52,941 - brc - INFO - Average loss from batch 2601 to 2650 is 4.6590246582
2018-04-23 10:59:56,886 - brc - INFO - Average loss from batch 2651 to 2700 is 4.71957099438
2018-04-23 11:02:01,465 - brc - INFO - Average loss from batch 2701 to 2750 is 4.75764135361
2018-04-23 11:04:08,125 - brc - INFO - Average loss from batch 2751 to 2800 is 4.67515822887
2018-04-23 11:06:13,923 - brc - INFO - Average loss from batch 2801 to 2850 is 4.62953261375
2018-04-23 11:09:07,072 - brc - INFO - Average loss from batch 2851 to 2900 is 4.77660606861
2018-04-23 11:11:13,403 - brc - INFO - Average loss from batch 2901 to 2950 is 4.65662786007
2018-04-23 11:13:19,043 - brc - INFO - Average loss from batch 2951 to 3000 is 4.69503146172
2018-04-23 11:15:23,096 - brc - INFO - Average loss from batch 3001 to 3050 is 4.73482781887
2018-04-23 11:17:26,447 - brc - INFO - Average loss from batch 3051 to 3100 is 4.59295828342
2018-04-23 11:21:22,393 - brc - INFO - Running with args : Namespace(algo='BIDAF', batch_size=32, brc_dir='model/', char_embed='../../data/embedding/wiki_brc/wiki_brc.char.vec', char_hidden_size=100, dev_files=['../../data/preprocessed_ltp/devset/search.dev.filter.json', '../../data/preprocessed_ltp/devset/zhidao.dev.filter.json'], dropout_keep_prob=0.5, epochs=10, evaluate=False, gpu='0', hidden_size=150, learning_rate=1e-06, log_path='model/log', max_a_len=500, max_p_len=500, max_p_num=5, max_q_len=60, max_w_len=4, model_dir='model/', optim='adam', pos_embed_dim=10, pr_rate=0.2, predict=False, prepare=False, restore=True, result_dir='model/', summary_dir='model/', test_files=['../../data/test1set/preprocessed/search.test1.json', '../../data/test1set/preprocessed/zhidao.test1.json'], train=True, train_files=['../../data/preprocessed_ltp/trainset/search.train.filter.json', '../../data/preprocessed_ltp/trainset/zhidao.train.filter.json'], vocab_dir='model/', weight_decay=0, word_embed='../../data/embedding/wiki_brc/wiki_brc.word.vec')
2018-04-23 11:21:22,393 - brc - INFO - Load data_set and vocab...
2018-04-23 11:27:24,767 - brc - INFO - Train set size: 257469 questions.
2018-04-23 11:28:19,233 - brc - INFO - Dev set size: 10000 questions.
2018-04-23 11:28:19,234 - brc - INFO - Converting text into ids...
2018-04-23 11:38:25,334 - brc - INFO - Initialize the model...
2018-04-23 11:38:31,520 - brc - INFO - Time to build graph: 5.65135002136 s
2018-04-23 11:38:48,103 - brc - INFO - There are 3865506 parameters in the model
2018-04-23 11:38:50,052 - brc - INFO - Restoring the model...
2018-04-23 11:38:50,388 - brc - INFO - Model restored from model/, with prefix BIDAF
2018-04-23 11:38:50,388 - brc - INFO - Evaluating the model on dev set...
2018-04-23 11:57:00,412 - brc - INFO - Training the model...
2018-04-23 11:57:00,413 - brc - INFO - Training the model for epoch 1
2018-04-23 12:01:04,340 - brc - INFO - Running with args : Namespace(algo='BIDAF', batch_size=30, brc_dir='model/', char_embed='../../data/embedding/wiki_brc/wiki_brc.char.vec', char_hidden_size=100, dev_files=['../../data/preprocessed_ltp/devset/search.dev.filter.json', '../../data/preprocessed_ltp/devset/zhidao.dev.filter.json'], dropout_keep_prob=0.5, epochs=10, evaluate=False, gpu='0', hidden_size=150, learning_rate=1e-06, log_path='model/log', max_a_len=500, max_p_len=500, max_p_num=5, max_q_len=60, max_w_len=4, model_dir='model/', optim='adam', pos_embed_dim=10, pr_rate=0.2, predict=False, prepare=False, restore=True, result_dir='model/', summary_dir='model/', test_files=['../../data/test1set/preprocessed/search.test1.json', '../../data/test1set/preprocessed/zhidao.test1.json'], train=True, train_files=['../../data/preprocessed_ltp/trainset/search.train.filter.json', '../../data/preprocessed_ltp/trainset/zhidao.train.filter.json'], vocab_dir='model/', weight_decay=0, word_embed='../../data/embedding/wiki_brc/wiki_brc.word.vec')
2018-04-23 12:01:04,341 - brc - INFO - Load data_set and vocab...
2018-04-23 12:06:21,108 - brc - INFO - Train set size: 257469 questions.
2018-04-23 12:07:12,586 - brc - INFO - Dev set size: 10000 questions.
2018-04-23 12:07:12,586 - brc - INFO - Converting text into ids...
2018-04-23 12:17:28,342 - brc - INFO - Initialize the model...
2018-04-23 12:17:34,043 - brc - INFO - Time to build graph: 4.96688294411 s
2018-04-23 12:17:49,886 - brc - INFO - There are 3865506 parameters in the model
2018-04-23 12:17:51,944 - brc - INFO - Restoring the model...
2018-04-23 12:17:52,320 - brc - INFO - Model restored from model/, with prefix BIDAF
2018-04-23 12:17:52,320 - brc - INFO - Evaluating the model on dev set...
2018-04-23 12:36:13,972 - brc - INFO - Training the model...
2018-04-23 12:36:13,974 - brc - INFO - Training the model for epoch 1
2018-04-23 12:38:11,052 - brc - INFO - Average loss from batch 1 to 50 is 8.3540098381
2018-04-23 12:40:09,375 - brc - INFO - Average loss from batch 51 to 100 is 8.23811095238
2018-04-23 12:42:07,943 - brc - INFO - Average loss from batch 101 to 150 is 8.32021733284
2018-04-23 12:44:06,744 - brc - INFO - Average loss from batch 151 to 200 is 8.31001307487
2018-04-23 12:46:05,013 - brc - INFO - Average loss from batch 201 to 250 is 8.31041581154
2018-04-23 12:48:01,711 - brc - INFO - Average loss from batch 251 to 300 is 8.44626465797
2018-04-23 12:50:00,505 - brc - INFO - Average loss from batch 301 to 350 is 8.26016558647
2018-04-23 12:52:26,534 - brc - INFO - Average loss from batch 351 to 400 is 8.22818656921
2018-04-23 12:54:24,282 - brc - INFO - Average loss from batch 401 to 450 is 8.28074691772
2018-04-23 12:56:23,903 - brc - INFO - Average loss from batch 451 to 500 is 8.13727043152
2018-04-23 12:58:22,062 - brc - INFO - Average loss from batch 501 to 550 is 8.10432394028
2018-04-23 13:00:19,507 - brc - INFO - Average loss from batch 551 to 600 is 8.1788995266
2018-04-23 13:02:17,069 - brc - INFO - Average loss from batch 601 to 650 is 8.17038371086
2018-04-23 13:04:15,693 - brc - INFO - Average loss from batch 651 to 700 is 8.0757111454
2018-04-23 13:06:13,159 - brc - INFO - Average loss from batch 701 to 750 is 8.08553103447
2018-04-23 13:08:10,637 - brc - INFO - Average loss from batch 751 to 800 is 8.02028550148
2018-04-23 13:10:09,156 - brc - INFO - Average loss from batch 801 to 850 is 8.13213485718
2018-04-23 13:12:07,165 - brc - INFO - Average loss from batch 851 to 900 is 8.03189235687
2018-04-23 13:14:04,726 - brc - INFO - Average loss from batch 901 to 950 is 7.98101578712
2018-04-23 13:16:03,661 - brc - INFO - Average loss from batch 951 to 1000 is 8.07843394279
2018-04-23 13:18:02,813 - brc - INFO - Average loss from batch 1001 to 1050 is 7.92410469055
2018-04-23 13:20:33,775 - brc - INFO - Average loss from batch 1051 to 1100 is 8.22849695206
2018-04-23 13:22:32,540 - brc - INFO - Average loss from batch 1101 to 1150 is 8.07907711983
2018-04-23 13:24:32,661 - brc - INFO - Average loss from batch 1151 to 1200 is 8.21316827774
2018-04-23 13:26:32,062 - brc - INFO - Average loss from batch 1201 to 1250 is 7.91793087006
2018-04-23 13:28:31,596 - brc - INFO - Average loss from batch 1251 to 1300 is 7.98257500648
2018-04-23 13:30:31,886 - brc - INFO - Average loss from batch 1301 to 1350 is 8.08529479027
2018-04-23 13:32:29,898 - brc - INFO - Average loss from batch 1351 to 1400 is 7.84746848106
2018-04-23 13:34:30,263 - brc - INFO - Average loss from batch 1401 to 1450 is 7.91180677414
2018-04-23 13:36:30,128 - brc - INFO - Average loss from batch 1451 to 1500 is 8.04962157249
2018-04-23 13:38:29,100 - brc - INFO - Average loss from batch 1501 to 1550 is 7.92856832504
2018-04-23 13:40:30,489 - brc - INFO - Average loss from batch 1551 to 1600 is 7.94894918442
2018-04-23 13:42:30,224 - brc - INFO - Average loss from batch 1601 to 1650 is 7.9665260601
2018-04-23 13:44:31,027 - brc - INFO - Average loss from batch 1651 to 1700 is 7.96164715767
2018-04-23 13:47:05,093 - brc - INFO - Average loss from batch 1701 to 1750 is 7.81770567894
2018-04-23 13:49:05,886 - brc - INFO - Average loss from batch 1751 to 1800 is 7.83745402336
2018-04-23 13:51:03,969 - brc - INFO - Average loss from batch 1801 to 1850 is 7.78400267601
2018-04-23 13:53:02,090 - brc - INFO - Average loss from batch 1851 to 1900 is 7.82679227829
2018-04-23 13:55:01,132 - brc - INFO - Average loss from batch 1901 to 1950 is 7.90186683655
2018-04-23 13:57:00,512 - brc - INFO - Average loss from batch 1951 to 2000 is 8.08757804871
2018-04-23 13:58:58,874 - brc - INFO - Average loss from batch 2001 to 2050 is 7.80352101326
2018-04-23 14:00:57,181 - brc - INFO - Average loss from batch 2051 to 2100 is 8.02032124519
2018-04-23 14:02:44,492 - brc - INFO - Evaluating the model ...
2018-04-23 14:22:45,086 - brc - INFO - Dev eval loss 8.2573775816
2018-04-23 14:22:45,088 - brc - INFO - Dev eval result: {'BLEU-4': 39.79, 'ROUGE-L': 48.55}
2018-04-23 14:22:52,137 - brc - INFO - Model saved in model/, with prefix BIDAF.
2018-04-23 14:23:04,111 - brc - INFO - Average loss from batch 2101 to 2150 is 7.92124699593
2018-04-23 14:25:05,787 - brc - INFO - Average loss from batch 2151 to 2200 is 7.80007267952
2018-04-23 14:27:06,956 - brc - INFO - Average loss from batch 2201 to 2250 is 8.04686341286
2018-04-23 14:29:08,453 - brc - INFO - Average loss from batch 2251 to 2300 is 7.89066736221
2018-04-23 14:31:09,934 - brc - INFO - Average loss from batch 2301 to 2350 is 7.98173950195
2018-04-23 14:33:13,908 - brc - INFO - Average loss from batch 2351 to 2400 is 7.92179297447
2018-04-23 14:35:16,730 - brc - INFO - Average loss from batch 2401 to 2450 is 7.95746207237
2018-04-23 14:37:18,841 - brc - INFO - Average loss from batch 2451 to 2500 is 7.772897892
2018-04-23 14:39:22,588 - brc - INFO - Average loss from batch 2501 to 2550 is 7.88613728523
2018-04-23 14:41:27,052 - brc - INFO - Average loss from batch 2551 to 2600 is 7.94145762444
2018-04-23 14:43:30,233 - brc - INFO - Average loss from batch 2601 to 2650 is 7.71958324432
2018-04-23 14:45:29,008 - brc - INFO - Average loss from batch 2651 to 2700 is 7.8838247776
2018-04-23 14:47:26,282 - brc - INFO - Average loss from batch 2701 to 2750 is 7.81421452522
2018-04-23 14:49:56,786 - brc - INFO - Average loss from batch 2751 to 2800 is 7.76834001541
2018-04-23 14:51:53,865 - brc - INFO - Average loss from batch 2801 to 2850 is 7.75404237747
2018-04-23 14:53:51,755 - brc - INFO - Average loss from batch 2851 to 2900 is 7.73145645142
2018-04-23 14:55:49,339 - brc - INFO - Average loss from batch 2901 to 2950 is 7.95010546684
2018-04-23 14:57:48,077 - brc - INFO - Average loss from batch 2951 to 3000 is 7.84716736794
2018-04-23 14:59:46,523 - brc - INFO - Average loss from batch 3001 to 3050 is 7.81779080391
2018-04-23 15:01:43,586 - brc - INFO - Average loss from batch 3051 to 3100 is 7.69307730675
2018-04-23 15:03:42,525 - brc - INFO - Average loss from batch 3101 to 3150 is 7.83938925743
2018-04-23 15:05:39,219 - brc - INFO - Average loss from batch 3151 to 3200 is 7.78596172333
2018-04-23 15:07:37,398 - brc - INFO - Average loss from batch 3201 to 3250 is 7.81459946632
2018-04-23 15:09:34,437 - brc - INFO - Average loss from batch 3251 to 3300 is 7.65693180084
2018-04-23 15:11:31,994 - brc - INFO - Average loss from batch 3301 to 3350 is 7.6630225563
2018-04-23 15:13:30,436 - brc - INFO - Average loss from batch 3351 to 3400 is 7.68022144318
2018-04-23 15:15:28,053 - brc - INFO - Average loss from batch 3401 to 3450 is 7.60543177605
2018-04-23 15:18:00,941 - brc - INFO - Average loss from batch 3451 to 3500 is 7.83155529022
2018-04-23 15:19:58,273 - brc - INFO - Average loss from batch 3501 to 3550 is 7.70847564697
2018-04-23 15:21:56,488 - brc - INFO - Average loss from batch 3551 to 3600 is 7.59791436195
2018-04-23 15:23:54,082 - brc - INFO - Average loss from batch 3601 to 3650 is 7.60668086052
2018-04-23 15:25:51,625 - brc - INFO - Average loss from batch 3651 to 3700 is 7.68698408127
2018-04-23 15:27:50,707 - brc - INFO - Average loss from batch 3701 to 3750 is 7.64875549316
2018-04-23 15:29:47,880 - brc - INFO - Average loss from batch 3751 to 3800 is 7.66440489769
2018-04-23 15:31:45,828 - brc - INFO - Average loss from batch 3801 to 3850 is 7.55137800217
2018-04-23 15:33:44,585 - brc - INFO - Average loss from batch 3851 to 3900 is 7.70253361702
2018-04-23 15:35:41,551 - brc - INFO - Average loss from batch 3901 to 3950 is 7.68620970726
2018-04-23 15:37:39,676 - brc - INFO - Average loss from batch 3951 to 4000 is 7.5780585289
2018-04-23 15:39:37,142 - brc - INFO - Average loss from batch 4001 to 4050 is 7.74755880356
2018-04-23 15:41:34,297 - brc - INFO - Average loss from batch 4051 to 4100 is 7.72515437126
2018-04-23 15:43:32,228 - brc - INFO - Average loss from batch 4101 to 4150 is 7.58929430008
2018-04-23 15:46:04,933 - brc - INFO - Average loss from batch 4151 to 4200 is 7.5613856411
2018-04-23 15:48:02,020 - brc - INFO - Average loss from batch 4201 to 4250 is 7.7017496109
2018-04-23 15:49:37,099 - brc - INFO - Evaluating the model ...
2018-04-23 16:08:15,937 - brc - INFO - Dev eval loss 8.18507207441
2018-04-23 16:08:15,939 - brc - INFO - Dev eval result: {'BLEU-4': 38.97, 'ROUGE-L': 48.46}
2018-04-23 16:08:39,212 - brc - INFO - Average loss from batch 4251 to 4300 is 7.51287519455
2018-04-23 16:10:37,010 - brc - INFO - Average loss from batch 4301 to 4350 is 7.55307723045
2018-04-23 16:12:36,802 - brc - INFO - Average loss from batch 4351 to 4400 is 7.6400327301
2018-04-23 16:14:34,281 - brc - INFO - Average loss from batch 4401 to 4450 is 7.50665395737
2018-04-23 16:16:32,471 - brc - INFO - Average loss from batch 4451 to 4500 is 7.63870508194
2018-04-23 16:19:05,258 - brc - INFO - Average loss from batch 4501 to 4550 is 7.66514042854
2018-04-23 16:21:01,860 - brc - INFO - Average loss from batch 4551 to 4600 is 7.5165041256
2018-04-23 16:22:59,807 - brc - INFO - Average loss from batch 4601 to 4650 is 7.6969305706
2018-04-23 16:24:57,344 - brc - INFO - Average loss from batch 4651 to 4700 is 7.60628429413
2018-04-23 16:26:55,785 - brc - INFO - Average loss from batch 4701 to 4750 is 7.56166422844
2018-04-23 16:28:53,547 - brc - INFO - Average loss from batch 4751 to 4800 is 7.57612916946
2018-04-23 16:30:51,991 - brc - INFO - Average loss from batch 4801 to 4850 is 7.76383167267
2018-04-23 16:32:49,556 - brc - INFO - Average loss from batch 4851 to 4900 is 7.50278389931
2018-04-23 16:34:47,456 - brc - INFO - Average loss from batch 4901 to 4950 is 7.59499933243
2018-04-23 16:36:44,495 - brc - INFO - Average loss from batch 4951 to 5000 is 7.64351242065
2018-04-23 16:38:43,274 - brc - INFO - Average loss from batch 5001 to 5050 is 7.49753890038
2018-04-23 16:40:40,969 - brc - INFO - Average loss from batch 5051 to 5100 is 7.48862005234
2018-04-23 16:42:38,618 - brc - INFO - Average loss from batch 5101 to 5150 is 7.71943263054
2018-04-23 16:44:37,968 - brc - INFO - Average loss from batch 5151 to 5200 is 7.46610733032
2018-04-23 16:47:13,084 - brc - INFO - Average loss from batch 5201 to 5250 is 7.35956505775
2018-04-23 16:49:09,635 - brc - INFO - Average loss from batch 5251 to 5300 is 7.58110290527
2018-04-23 16:51:07,027 - brc - INFO - Average loss from batch 5301 to 5350 is 7.43445127487
2018-04-23 16:53:04,728 - brc - INFO - Average loss from batch 5351 to 5400 is 7.40657979965
2018-04-23 16:55:03,395 - brc - INFO - Average loss from batch 5401 to 5450 is 7.57849675179
2018-04-23 16:57:00,707 - brc - INFO - Average loss from batch 5451 to 5500 is 7.29385709763
2018-04-23 16:58:58,701 - brc - INFO - Average loss from batch 5501 to 5550 is 7.39120940208
2018-04-23 17:00:55,441 - brc - INFO - Average loss from batch 5551 to 5600 is 7.53453179359
2018-04-23 17:02:52,824 - brc - INFO - Average loss from batch 5601 to 5650 is 7.44922569275
2018-04-23 17:04:50,740 - brc - INFO - Average loss from batch 5651 to 5700 is 7.37252156258
2018-04-23 17:06:48,333 - brc - INFO - Average loss from batch 5701 to 5750 is 7.47729025841
2018-04-23 17:08:46,172 - brc - INFO - Average loss from batch 5751 to 5800 is 7.46003353119
2018-04-23 17:10:44,746 - brc - INFO - Average loss from batch 5801 to 5850 is 7.27610618591
2018-04-23 17:12:47,094 - brc - INFO - Average loss from batch 5851 to 5900 is 7.54557015419
2018-04-23 17:14:55,688 - brc - INFO - Average loss from batch 5901 to 5950 is 7.45549536705
2018-04-23 17:17:46,017 - brc - INFO - Average loss from batch 5951 to 6000 is 7.51679091454
2018-04-23 17:19:53,255 - brc - INFO - Average loss from batch 6001 to 6050 is 7.38176542282
2018-04-23 17:22:01,134 - brc - INFO - Average loss from batch 6051 to 6100 is 7.52460604668
2018-04-23 17:24:08,612 - brc - INFO - Average loss from batch 6101 to 6150 is 7.44816924095
2018-04-23 17:26:16,256 - brc - INFO - Average loss from batch 6151 to 6200 is 7.24559922218
2018-04-23 17:28:24,482 - brc - INFO - Average loss from batch 6201 to 6250 is 7.33322047234
2018-04-23 17:30:33,177 - brc - INFO - Average loss from batch 6251 to 6300 is 7.36026983261
2018-04-23 17:32:40,429 - brc - INFO - Average loss from batch 6301 to 6350 is 7.41338670731
2018-04-23 17:34:48,841 - brc - INFO - Average loss from batch 6351 to 6400 is 7.38618350983
2018-04-23 17:36:17,383 - brc - INFO - Evaluating the model ...
2018-04-23 17:57:54,416 - brc - INFO - Dev eval loss 8.1264793725
2018-04-23 17:57:54,419 - brc - INFO - Dev eval result: {'BLEU-4': 37.96, 'ROUGE-L': 48.32}
2018-04-23 17:58:32,439 - brc - INFO - Average loss from batch 6401 to 6450 is 7.34702004433
2018-04-23 18:00:41,109 - brc - INFO - Average loss from batch 6451 to 6500 is 7.30972887993
2018-04-23 18:02:49,813 - brc - INFO - Average loss from batch 6501 to 6550 is 7.4051763916
2018-04-23 18:04:57,929 - brc - INFO - Average loss from batch 6551 to 6600 is 7.29453984261
2018-04-23 18:07:05,660 - brc - INFO - Average loss from batch 6601 to 6650 is 7.28638457298
2018-04-23 18:09:12,096 - brc - INFO - Average loss from batch 6651 to 6700 is 7.37234080315
2018-04-23 18:11:19,936 - brc - INFO - Average loss from batch 6701 to 6750 is 7.39730725288
2018-04-23 18:13:27,774 - brc - INFO - Average loss from batch 6751 to 6800 is 7.3319589901
2018-04-23 18:15:35,263 - brc - INFO - Average loss from batch 6801 to 6850 is 7.34443858147
2018-04-23 18:17:42,477 - brc - INFO - Average loss from batch 6851 to 6900 is 7.32285543442
2018-04-23 18:19:49,630 - brc - INFO - Average loss from batch 6901 to 6950 is 7.3373256588
2018-04-23 18:21:57,172 - brc - INFO - Average loss from batch 6951 to 7000 is 7.37109760284
2018-04-23 18:24:49,843 - brc - INFO - Average loss from batch 7001 to 7050 is 7.36725790024
2018-04-23 18:26:57,357 - brc - INFO - Average loss from batch 7051 to 7100 is 7.20294874191
2018-04-23 18:29:04,146 - brc - INFO - Average loss from batch 7101 to 7150 is 7.37692831993
2018-04-23 18:31:11,861 - brc - INFO - Average loss from batch 7151 to 7200 is 7.38104594231
2018-04-23 18:33:18,986 - brc - INFO - Average loss from batch 7201 to 7250 is 7.30163133621
2018-04-23 18:35:27,589 - brc - INFO - Average loss from batch 7251 to 7300 is 7.27265451431
2018-04-23 18:37:35,740 - brc - INFO - Average loss from batch 7301 to 7350 is 7.35964313507
2018-04-23 18:39:43,642 - brc - INFO - Average loss from batch 7351 to 7400 is 7.41749486923
2018-04-23 18:41:49,767 - brc - INFO - Average loss from batch 7401 to 7450 is 7.26254179955
2018-04-23 18:43:57,378 - brc - INFO - Average loss from batch 7451 to 7500 is 7.34426680565
2018-04-23 18:46:04,160 - brc - INFO - Average loss from batch 7501 to 7550 is 7.21816917419
2018-04-23 18:48:10,633 - brc - INFO - Average loss from batch 7551 to 7600 is 7.25129804611
2018-04-23 18:50:17,306 - brc - INFO - Average loss from batch 7601 to 7650 is 7.30588527679
2018-04-23 18:52:25,004 - brc - INFO - Average loss from batch 7651 to 7700 is 7.16768901825
2018-04-23 18:54:33,522 - brc - INFO - Average loss from batch 7701 to 7750 is 7.31061632156
2018-04-23 18:57:26,795 - brc - INFO - Average loss from batch 7751 to 7800 is 7.15811561584
2018-04-23 18:59:34,888 - brc - INFO - Average loss from batch 7801 to 7850 is 7.31812078476
2018-04-23 19:01:41,946 - brc - INFO - Average loss from batch 7851 to 7900 is 7.2815276432
2018-04-23 19:03:50,259 - brc - INFO - Average loss from batch 7901 to 7950 is 7.15556055069
2018-04-23 19:05:57,343 - brc - INFO - Average loss from batch 7951 to 8000 is 7.3912075901
2018-04-23 19:08:04,511 - brc - INFO - Average loss from batch 8001 to 8050 is 7.27628489494
2018-04-23 19:10:12,063 - brc - INFO - Average loss from batch 8051 to 8100 is 7.23097882271
2018-04-23 19:12:19,171 - brc - INFO - Average loss from batch 8101 to 8150 is 7.36942298889
2018-04-23 19:14:27,906 - brc - INFO - Average loss from batch 8151 to 8200 is 7.2509577179
2018-04-23 19:16:35,902 - brc - INFO - Average loss from batch 8201 to 8250 is 7.24888905525
2018-04-23 19:18:43,251 - brc - INFO - Average loss from batch 8251 to 8300 is 7.42605441093
2018-04-23 19:20:50,542 - brc - INFO - Average loss from batch 8301 to 8350 is 7.18126074791
2018-04-23 19:22:58,575 - brc - INFO - Average loss from batch 8351 to 8400 is 7.24325743675
2018-04-23 19:25:06,617 - brc - INFO - Average loss from batch 8401 to 8450 is 7.14424134254
2018-04-23 19:27:59,047 - brc - INFO - Average loss from batch 8451 to 8500 is 7.2849571991
2018-04-23 19:30:06,852 - brc - INFO - Average loss from batch 8501 to 8550 is 7.24280139923
2018-04-23 19:31:23,273 - brc - INFO - Evaluating the model ...
2018-04-23 19:52:37,831 - brc - INFO - Dev eval loss 8.08272290182
2018-04-23 19:52:37,831 - brc - INFO - Dev eval result: {'BLEU-4': 37.23, 'ROUGE-L': 48.09}
2018-04-23 19:52:44,869 - brc - INFO - Average train loss for epoch 1 is 7.65204469065
2018-04-23 19:52:44,871 - brc - INFO - Evaluating the model after epoch 1
2018-04-24 11:40:53,272 - brc - INFO - Running with args : Namespace(algo='BIDAF', batch_size=30, brc_dir='model/', char_embed='../../data/embedding/wiki_brc/wiki_brc.char.vec', char_hidden_size=100, dev_files=['../../data/preprocessed_ltp/devset/search.dev.filter.json', '../../data/preprocessed_ltp/devset/zhidao.dev.filter.json'], dropout_keep_prob=0.5, epochs=10, evaluate=False, gpu='0', hidden_size=150, learning_rate=0.0001, log_path='model/log', max_a_len=500, max_p_len=500, max_p_num=5, max_q_len=60, max_w_len=4, model_dir='model/', optim='adam', pos_embed_dim=10, pr_rate=0.2, predict=False, prepare=False, restore=True, result_dir='model/', summary_dir='model/', test_files=['../../data/test1set/preprocessed/search.test1.json', '../../data/test1set/preprocessed/zhidao.test1.json'], train=True, train_files=['../../data/preprocessed_ltp/trainset/search.train.filter.json', '../../data/preprocessed_ltp/trainset/zhidao.train.filter.json'], vocab_dir='model/', weight_decay=0, word_embed='../../data/embedding/wiki_brc/wiki_brc.word.vec')
2018-04-24 11:40:53,273 - brc - INFO - Load data_set and vocab...
2018-04-24 11:47:21,325 - brc - INFO - Train set size: 257469 questions.
2018-04-24 11:48:15,211 - brc - INFO - Dev set size: 10000 questions.
2018-04-24 11:48:15,211 - brc - INFO - Converting text into ids...
2018-04-24 11:58:12,150 - brc - INFO - Initialize the model...
2018-04-24 11:58:17,637 - brc - INFO - Time to build graph: 4.58857798576 s
2018-04-24 11:58:33,491 - brc - INFO - There are 3865506 parameters in the model
2018-04-24 11:58:35,572 - brc - INFO - Restoring the model...
2018-04-24 11:58:37,039 - brc - INFO - Model restored from model/, with prefix BIDAF
2018-04-24 11:58:37,039 - brc - INFO - Evaluating the model on dev set...
2018-04-24 12:18:22,986 - brc - INFO - Training the model...
2018-04-24 12:18:22,988 - brc - INFO - Training the model for epoch 1
2018-04-24 12:20:19,541 - brc - INFO - Average loss from batch 1 to 50 is 7.49225678444
2018-04-24 12:22:22,206 - brc - INFO - Average loss from batch 51 to 100 is 7.20207321167
2018-04-24 12:24:25,941 - brc - INFO - Average loss from batch 101 to 150 is 6.92515955925
2018-04-24 12:26:24,777 - brc - INFO - Average loss from batch 151 to 200 is 6.93462359428
2018-04-24 12:28:21,844 - brc - INFO - Average loss from batch 201 to 250 is 6.62953820229
2018-04-24 12:30:20,034 - brc - INFO - Average loss from batch 251 to 300 is 6.674203825
2018-04-24 12:32:18,976 - brc - INFO - Average loss from batch 301 to 350 is 6.53364714622
2018-04-24 12:34:46,662 - brc - INFO - Average loss from batch 351 to 400 is 6.54420354843
2018-04-24 12:36:44,745 - brc - INFO - Average loss from batch 401 to 450 is 6.44388988495
2018-04-24 12:38:41,720 - brc - INFO - Average loss from batch 451 to 500 is 6.40662830353
2018-04-24 12:40:39,846 - brc - INFO - Average loss from batch 501 to 550 is 6.44415728569
2018-04-24 12:42:38,834 - brc - INFO - Average loss from batch 551 to 600 is 6.48511987686
2018-04-24 12:44:38,223 - brc - INFO - Average loss from batch 601 to 650 is 6.23473096848
2018-04-24 12:46:54,442 - brc - INFO - Average loss from batch 651 to 700 is 6.27657042503
2018-04-24 12:49:16,727 - brc - INFO - Average loss from batch 701 to 750 is 6.25252163887
2018-04-24 12:51:37,978 - brc - INFO - Average loss from batch 751 to 800 is 6.21641704559
2018-04-24 12:54:00,781 - brc - INFO - Average loss from batch 801 to 850 is 6.26039162636
2018-04-24 12:56:21,409 - brc - INFO - Average loss from batch 851 to 900 is 6.20462651253
2018-04-24 12:58:39,524 - brc - INFO - Average loss from batch 901 to 950 is 6.35354948997
2018-04-24 13:00:58,763 - brc - INFO - Average loss from batch 951 to 1000 is 6.29047980309
2018-04-24 13:03:20,831 - brc - INFO - Average loss from batch 1001 to 1050 is 6.27500479698
2018-04-24 13:06:07,688 - brc - INFO - Average loss from batch 1051 to 1100 is 6.27292304993
2018-04-24 13:08:13,573 - brc - INFO - Average loss from batch 1101 to 1150 is 6.17292160988
2018-04-24 13:10:21,776 - brc - INFO - Average loss from batch 1151 to 1200 is 6.01433238029
2018-04-24 13:12:28,535 - brc - INFO - Average loss from batch 1201 to 1250 is 6.23751026154
2018-04-24 13:14:36,103 - brc - INFO - Average loss from batch 1251 to 1300 is 6.14757247925
2018-04-24 13:16:39,201 - brc - INFO - Average loss from batch 1301 to 1350 is 6.25923473358
2018-04-24 13:18:37,632 - brc - INFO - Average loss from batch 1351 to 1400 is 6.17187712669
2018-04-24 13:20:35,627 - brc - INFO - Average loss from batch 1401 to 1450 is 6.15474327087
2018-04-24 13:22:32,636 - brc - INFO - Average loss from batch 1451 to 1500 is 6.06704246521
2018-04-24 13:24:29,526 - brc - INFO - Average loss from batch 1501 to 1550 is 6.15383566856
2018-04-24 13:26:27,839 - brc - INFO - Average loss from batch 1551 to 1600 is 6.13087908745
2018-04-24 13:28:25,485 - brc - INFO - Average loss from batch 1601 to 1650 is 6.15602902412
2018-04-24 13:30:22,121 - brc - INFO - Average loss from batch 1651 to 1700 is 6.11304794312
2018-04-24 13:32:50,323 - brc - INFO - Average loss from batch 1701 to 1750 is 6.12324186325
2018-04-24 13:34:48,174 - brc - INFO - Average loss from batch 1751 to 1800 is 6.09874353409
2018-04-24 13:36:46,201 - brc - INFO - Average loss from batch 1801 to 1850 is 6.04714330673
2018-04-24 13:38:44,979 - brc - INFO - Average loss from batch 1851 to 1900 is 6.04792108536
2018-04-24 13:40:41,430 - brc - INFO - Average loss from batch 1901 to 1950 is 6.05215149879
2018-04-24 13:42:39,551 - brc - INFO - Average loss from batch 1951 to 2000 is 6.15987254143
2018-04-24 13:44:37,960 - brc - INFO - Average loss from batch 2001 to 2050 is 5.9371556282
2018-04-24 13:46:35,497 - brc - INFO - Average loss from batch 2051 to 2100 is 6.1662097168
2018-04-24 13:48:21,674 - brc - INFO - Evaluating the model ...
2018-04-24 14:08:48,484 - brc - INFO - Dev eval loss 7.89835957336
2018-04-24 14:08:48,487 - brc - INFO - Dev eval result: {'BLEU-4': 34.8, 'ROUGE-L': 46.53}
2018-04-24 14:08:59,784 - brc - INFO - Average loss from batch 2101 to 2150 is 6.11337295532
2018-04-24 14:10:58,635 - brc - INFO - Average loss from batch 2151 to 2200 is 6.00751005173
2018-04-24 14:12:55,906 - brc - INFO - Average loss from batch 2201 to 2250 is 6.14816678047
2018-04-24 14:14:53,184 - brc - INFO - Average loss from batch 2251 to 2300 is 6.01739491463
2018-04-24 14:16:52,201 - brc - INFO - Average loss from batch 2301 to 2350 is 6.08748270988
2018-04-24 14:18:48,952 - brc - INFO - Average loss from batch 2351 to 2400 is 6.13148345947
2018-04-24 14:20:46,599 - brc - INFO - Average loss from batch 2401 to 2450 is 5.97237569809
2018-04-24 14:22:43,800 - brc - INFO - Average loss from batch 2451 to 2500 is 6.06821398735
2018-04-24 14:24:41,523 - brc - INFO - Average loss from batch 2501 to 2550 is 5.97326930046
2018-04-24 14:26:38,433 - brc - INFO - Average loss from batch 2551 to 2600 is 5.92889167786
2018-04-24 14:28:37,492 - brc - INFO - Average loss from batch 2601 to 2650 is 6.03328996658
2018-04-24 14:30:37,168 - brc - INFO - Average loss from batch 2651 to 2700 is 5.89807231903
2018-04-24 14:32:36,961 - brc - INFO - Average loss from batch 2701 to 2750 is 5.97289310455
2018-04-24 14:35:08,814 - brc - INFO - Average loss from batch 2751 to 2800 is 5.94645108223
2018-04-24 14:37:04,710 - brc - INFO - Average loss from batch 2801 to 2850 is 5.99850473404
2018-04-24 14:39:03,702 - brc - INFO - Average loss from batch 2851 to 2900 is 6.07738059998
2018-04-24 14:41:04,231 - brc - INFO - Average loss from batch 2901 to 2950 is 5.95184366226
2018-04-24 14:43:05,258 - brc - INFO - Average loss from batch 2951 to 3000 is 6.05316877365
2018-04-24 14:45:03,061 - brc - INFO - Average loss from batch 3001 to 3050 is 5.98373997688
2018-04-24 14:47:02,845 - brc - INFO - Average loss from batch 3051 to 3100 is 6.04627914429
2018-04-24 14:48:59,490 - brc - INFO - Average loss from batch 3101 to 3150 is 5.96797143936
2018-04-24 14:50:58,073 - brc - INFO - Average loss from batch 3151 to 3200 is 5.95189021111
2018-04-24 14:52:56,515 - brc - INFO - Average loss from batch 3201 to 3250 is 6.05273851395
2018-04-24 14:57:23,875 - brc - INFO - Running with args : Namespace(algo='BIDAF', batch_size=32, brc_dir='model/', char_embed='../../data/embedding/wiki_brc/wiki_brc.char.vec', char_hidden_size=100, dev_files=['../../data/preprocessed_ltp/devset/search.dev.filter.json', '../../data/preprocessed_ltp/devset/zhidao.dev.filter.json'], dropout_keep_prob=1, epochs=10, evaluate=False, gpu='0', hidden_size=150, learning_rate=0.001, log_path='model/log', max_a_len=500, max_p_len=500, max_p_num=5, max_q_len=60, max_w_len=4, model_dir='model/', optim='adam', pos_embed_dim=10, pr_rate=0.2, predict=False, prepare=False, restore=True, result_dir='model/', summary_dir='model/', test_files=['../../data/test1set/preprocessed/search.test1.json', '../../data/test1set/preprocessed/zhidao.test1.json'], train=True, train_files=['../../data/preprocessed_ltp/trainset/search.train.filter.json', '../../data/preprocessed_ltp/trainset/zhidao.train.filter.json', '../../data/WebQA.v1.0/WebQA_ltp.filter.json', '../../data/sougou/sougou_ltp.filter.json'], vocab_dir='model/', weight_decay=0, word_embed='../../data/embedding/wiki_brc/wiki_brc.word.vec')
2018-04-24 14:57:23,875 - brc - INFO - Load data_set and vocab...
2018-04-24 15:03:32,210 - brc - INFO - Train set size: 525450 questions.
2018-04-24 15:04:25,079 - brc - INFO - Dev set size: 10000 questions.
2018-04-24 15:04:25,079 - brc - INFO - Converting text into ids...
2018-04-24 15:16:23,613 - brc - INFO - Initialize the model...
2018-04-24 15:16:29,352 - brc - INFO - Time to build graph: 5.39490294456 s
2018-04-24 15:16:45,614 - brc - INFO - There are 3865506 parameters in the model
2018-04-24 15:17:46,681 - brc - INFO - Running with args : Namespace(algo='BIDAF', batch_size=32, brc_dir='model/', char_embed='../../data/embedding/wiki_brc/wiki_brc.char.vec', char_hidden_size=100, dev_files=['../../data/preprocessed_ltp/devset/search.dev.filter.json', '../../data/preprocessed_ltp/devset/zhidao.dev.filter.json'], dropout_keep_prob=1, epochs=10, evaluate=False, gpu='0', hidden_size=150, learning_rate=0.001, log_path='model/log', max_a_len=500, max_p_len=500, max_p_num=5, max_q_len=60, max_w_len=4, model_dir='model/', optim='adam', pos_embed_dim=10, pr_rate=0.2, predict=False, prepare=False, restore=True, result_dir='model/', summary_dir='model/', test_files=['../../data/test1set/preprocessed/search.test1.json', '../../data/test1set/preprocessed/zhidao.test1.json'], train=True, train_files=['../../data/preprocessed_ltp/trainset/search.train.filter.json', '../../data/preprocessed_ltp/trainset/zhidao.train.filter.json', '../../data/WebQA.v1.0/WebQA_ltp.filter.json', '../../data/sougou/sougou_ltp.filter.json'], vocab_dir='model/', weight_decay=0, word_embed='../../data/embedding/wiki_brc/wiki_brc.word.vec')
2018-04-24 15:17:46,681 - brc - INFO - Load data_set and vocab...
2018-04-24 15:24:08,250 - brc - INFO - Train set size: 525450 questions.
2018-04-24 15:25:00,721 - brc - INFO - Dev set size: 10000 questions.
2018-04-24 15:25:00,721 - brc - INFO - Converting text into ids...
2018-04-24 15:36:21,447 - brc - INFO - Initialize the model...
2018-04-24 15:36:26,549 - brc - INFO - Time to build graph: 4.44764304161 s
2018-04-24 15:36:42,207 - brc - INFO - There are 3865506 parameters in the model
2018-04-24 15:36:44,170 - brc - INFO - Restoring the model...
2018-04-24 15:36:45,427 - brc - INFO - Model restored from model/, with prefix BIDAF
2018-04-24 15:36:45,427 - brc - INFO - Evaluating the model on dev set...
2018-04-24 15:54:54,196 - brc - INFO - Training the model...
2018-04-24 15:54:54,196 - brc - INFO - Training the model for epoch 1
2018-04-24 15:57:21,143 - brc - INFO - Average loss from batch 1 to 50 is 4.73129995823
2018-04-24 15:59:18,066 - brc - INFO - Average loss from batch 51 to 100 is 4.29145446777
2018-04-24 16:01:16,135 - brc - INFO - Average loss from batch 101 to 150 is 4.20171281815
2018-04-24 16:03:13,363 - brc - INFO - Average loss from batch 151 to 200 is 4.09378612518
2018-04-24 16:05:11,717 - brc - INFO - Average loss from batch 201 to 250 is 4.12346984386
2018-04-24 16:07:09,429 - brc - INFO - Average loss from batch 251 to 300 is 3.93438579559
2018-04-24 16:09:06,212 - brc - INFO - Average loss from batch 301 to 350 is 3.88476652145
2018-04-24 16:11:02,069 - brc - INFO - Average loss from batch 351 to 400 is 3.87330458164
2018-04-24 16:12:58,298 - brc - INFO - Average loss from batch 401 to 450 is 3.96321556091
2018-04-24 16:14:56,105 - brc - INFO - Average loss from batch 451 to 500 is 3.91920121193
2018-04-24 16:16:53,961 - brc - INFO - Average loss from batch 501 to 550 is 3.90946880341
2018-04-24 16:18:51,325 - brc - INFO - Average loss from batch 551 to 600 is 3.80085950375
2018-04-24 16:20:49,356 - brc - INFO - Average loss from batch 601 to 650 is 3.83868208408
2018-04-24 16:22:47,119 - brc - INFO - Average loss from batch 651 to 700 is 3.98740135193
2018-04-24 16:25:21,227 - brc - INFO - Average loss from batch 701 to 750 is 3.87206731319
2018-04-24 16:27:19,172 - brc - INFO - Average loss from batch 751 to 800 is 3.84119452953
2018-04-24 16:29:17,844 - brc - INFO - Average loss from batch 801 to 850 is 3.83708760738
2018-04-24 16:31:16,004 - brc - INFO - Average loss from batch 851 to 900 is 3.79283857822
2018-04-24 16:33:14,474 - brc - INFO - Average loss from batch 901 to 950 is 3.75678603172
2018-04-24 16:35:12,243 - brc - INFO - Average loss from batch 951 to 1000 is 3.90022186279
2018-04-24 16:37:10,515 - brc - INFO - Average loss from batch 1001 to 1050 is 3.74106875896
2018-04-24 16:39:08,350 - brc - INFO - Average loss from batch 1051 to 1100 is 3.71589740276
2018-04-24 16:41:06,270 - brc - INFO - Average loss from batch 1101 to 1150 is 3.84092442989
2018-04-24 16:43:05,436 - brc - INFO - Average loss from batch 1151 to 1200 is 3.69426339626
2018-04-24 16:45:04,419 - brc - INFO - Average loss from batch 1201 to 1250 is 3.64545108795
2018-04-24 16:47:03,533 - brc - INFO - Average loss from batch 1251 to 1300 is 3.72597671032
2018-04-24 16:49:02,165 - brc - INFO - Average loss from batch 1301 to 1350 is 3.67383873463
2018-04-24 16:50:59,329 - brc - INFO - Average loss from batch 1351 to 1400 is 3.65066763878
2018-04-24 16:52:57,881 - brc - INFO - Average loss from batch 1401 to 1450 is 3.73751953125
2018-04-24 16:55:35,005 - brc - INFO - Average loss from batch 1451 to 1500 is 3.60215658665
2018-04-24 16:57:32,003 - brc - INFO - Average loss from batch 1501 to 1550 is 3.62355166912
2018-04-24 16:59:30,056 - brc - INFO - Average loss from batch 1551 to 1600 is 3.6264551115
2018-04-24 17:01:27,567 - brc - INFO - Average loss from batch 1601 to 1650 is 3.74995299816
2018-04-24 17:03:26,532 - brc - INFO - Average loss from batch 1651 to 1700 is 3.73695277214
2018-04-24 17:05:26,320 - brc - INFO - Average loss from batch 1701 to 1750 is 3.81066870689
2018-04-24 17:07:24,193 - brc - INFO - Average loss from batch 1751 to 1800 is 3.77439145088
2018-04-24 17:09:21,423 - brc - INFO - Average loss from batch 1801 to 1850 is 3.65100764751
2018-04-24 17:11:20,859 - brc - INFO - Average loss from batch 1851 to 1900 is 3.64068729401
2018-04-24 17:13:18,074 - brc - INFO - Average loss from batch 1901 to 1950 is 3.69502281904
2018-04-24 17:15:16,624 - brc - INFO - Average loss from batch 1951 to 2000 is 3.62629202843
2018-04-24 17:17:13,942 - brc - INFO - Average loss from batch 2001 to 2050 is 3.74680642128
2018-04-24 17:19:11,408 - brc - INFO - Average loss from batch 2051 to 2100 is 3.58767144203
2018-04-24 17:21:09,927 - brc - INFO - Average loss from batch 2101 to 2150 is 3.73358817101
2018-04-24 17:23:43,794 - brc - INFO - Average loss from batch 2151 to 2200 is 3.64437178612
2018-04-24 17:25:42,904 - brc - INFO - Average loss from batch 2201 to 2250 is 3.71225345135
2018-04-24 17:27:40,006 - brc - INFO - Average loss from batch 2251 to 2300 is 3.62489204407
2018-04-24 17:29:38,268 - brc - INFO - Average loss from batch 2301 to 2350 is 3.75113954067
2018-04-24 17:31:35,533 - brc - INFO - Average loss from batch 2351 to 2400 is 3.64094579697
2018-04-24 17:33:33,447 - brc - INFO - Average loss from batch 2401 to 2450 is 3.73177108765
2018-04-24 17:35:32,887 - brc - INFO - Average loss from batch 2451 to 2500 is 3.7423535347
2018-04-24 17:37:32,467 - brc - INFO - Average loss from batch 2501 to 2550 is 3.75315276146
2018-04-24 17:39:30,140 - brc - INFO - Average loss from batch 2551 to 2600 is 3.62446136951
2018-04-24 17:41:25,048 - brc - INFO - Average loss from batch 2601 to 2650 is 3.65169662476
2018-04-24 17:43:21,997 - brc - INFO - Average loss from batch 2651 to 2700 is 3.63315113068
2018-04-24 17:45:20,962 - brc - INFO - Average loss from batch 2701 to 2750 is 3.60534481049
2018-04-24 17:47:17,177 - brc - INFO - Average loss from batch 2751 to 2800 is 3.75792223454
2018-04-24 17:49:13,725 - brc - INFO - Average loss from batch 2801 to 2850 is 3.66037743092
2018-04-24 17:51:10,243 - brc - INFO - Average loss from batch 2851 to 2900 is 3.54555142403
2018-04-24 17:53:44,276 - brc - INFO - Average loss from batch 2901 to 2950 is 3.67997366905
2018-04-24 17:55:40,846 - brc - INFO - Average loss from batch 2951 to 3000 is 3.74577220917
2018-04-24 17:58:08,593 - brc - INFO - Average loss from batch 3001 to 3050 is 3.78523649216
2018-04-24 18:03:04,314 - brc - INFO - Average loss from batch 3051 to 3100 is 3.65815093994
2018-04-24 18:09:46,856 - brc - INFO - Average loss from batch 3101 to 3150 is 3.69900347233
2018-04-24 18:17:12,158 - brc - INFO - Average loss from batch 3151 to 3200 is 3.56058285236
2018-04-24 18:24:24,798 - brc - INFO - Average loss from batch 3201 to 3250 is 3.76458934307
2018-04-24 18:31:25,426 - brc - INFO - Average loss from batch 3251 to 3300 is 3.48519747257
2018-04-24 18:38:38,613 - brc - INFO - Average loss from batch 3301 to 3350 is 3.66071044445
2018-04-24 18:45:43,859 - brc - INFO - Average loss from batch 3351 to 3400 is 3.68760551453
2018-04-24 18:53:15,609 - brc - INFO - Average loss from batch 3401 to 3450 is 3.59857047081
2018-04-24 19:00:35,722 - brc - INFO - Average loss from batch 3451 to 3500 is 3.6616957283
2018-04-24 19:07:44,351 - brc - INFO - Average loss from batch 3501 to 3550 is 3.63813864231
2018-04-24 19:15:05,588 - brc - INFO - Average loss from batch 3551 to 3600 is 3.58953573227
2018-04-24 19:22:27,081 - brc - INFO - Average loss from batch 3601 to 3650 is 3.72830635071
2018-04-24 19:32:15,100 - brc - INFO - Average loss from batch 3651 to 3700 is 3.59425030231
2018-04-24 19:39:36,373 - brc - INFO - Average loss from batch 3701 to 3750 is 3.49476191521
2018-04-24 19:47:08,101 - brc - INFO - Average loss from batch 3751 to 3800 is 3.49172014236
2018-04-24 19:54:24,021 - brc - INFO - Average loss from batch 3801 to 3850 is 3.49846509457
2018-04-24 20:01:41,458 - brc - INFO - Average loss from batch 3851 to 3900 is 3.59384946823
2018-04-24 20:09:07,700 - brc - INFO - Average loss from batch 3901 to 3950 is 3.58841747761
2018-04-24 20:16:35,986 - brc - INFO - Average loss from batch 3951 to 4000 is 3.61033096313
2018-04-24 20:23:52,320 - brc - INFO - Average loss from batch 4001 to 4050 is 3.66855324268
2018-04-24 20:31:14,325 - brc - INFO - Average loss from batch 4051 to 4100 is 3.67915462971
2018-04-24 20:32:03,044 - brc - INFO - Evaluating the model ...
2018-04-24 21:12:53,372 - brc - INFO - Dev eval loss 8.21079851837
2018-04-24 21:12:53,374 - brc - INFO - Dev eval result: {'BLEU-4': 39.11, 'ROUGE-L': 47.56}
2018-04-24 21:14:39,613 - brc - INFO - Average loss from batch 4101 to 4150 is 3.55207201004
2018-04-24 21:16:37,116 - brc - INFO - Average loss from batch 4151 to 4200 is 3.57891553879
2018-04-24 21:18:34,578 - brc - INFO - Average loss from batch 4201 to 4250 is 3.55631951332
2018-04-24 21:20:30,813 - brc - INFO - Average loss from batch 4251 to 4300 is 3.60007892609
2018-04-24 21:22:27,106 - brc - INFO - Average loss from batch 4301 to 4350 is 3.53190074921
2018-04-28 14:44:27,773 - brc - INFO - Running with args : Namespace(algo='BIDAF', batch_size=32, brc_dir='model/', char_embed='../../data/embedding/wiki_brc/wiki_brc.char.vec', char_hidden_size=100, dev_files=['../../data/preprocessed_ltp/devset/search.dev.filter.json', '../../data/preprocessed_ltp/devset/zhidao.dev.filter.json'], dropout_keep_prob=1, epochs=10, evaluate=False, gpu='0', hidden_size=150, learning_rate=0.0001, log_path='model/log', max_a_len=500, max_p_len=500, max_p_num=5, max_q_len=60, max_w_len=4, model_dir='model/', optim='adam', pos_embed_dim=10, pr_rate=0.2, predict=False, prepare=False, restore=True, result_dir='model/', summary_dir='model/', test_files=['../../data/test1set/preprocessed/search.test1.json', '../../data/test1set/preprocessed/zhidao.test1.json'], train=True, train_files=['../../data/preprocessed_ltp/trainset/search.train.filter.json', '../../data/preprocessed_ltp/trainset/zhidao.train.filter.json'], vocab_dir='model/', weight_decay=0, word_embed='../../data/embedding/wiki_brc/wiki_brc.word.vec')
2018-04-28 14:44:27,773 - brc - INFO - Load data_set and vocab...
2018-04-28 14:54:22,495 - brc - INFO - Train set size: 257469 questions.
2018-04-28 14:55:31,508 - brc - INFO - Dev set size: 10000 questions.
2018-04-28 14:55:31,805 - brc - INFO - Converting text into ids...
2018-04-28 15:05:44,089 - brc - INFO - Initialize the model...
2018-04-28 15:05:51,073 - brc - INFO - Time to build graph: 6.07986092567 s
2018-04-28 15:06:07,666 - brc - INFO - There are 3865506 parameters in the model
2018-04-28 15:06:11,726 - brc - INFO - Restoring the model...
2018-04-28 15:06:18,129 - brc - INFO - Model restored from model/, with prefix BIDAF
2018-04-28 15:06:18,129 - brc - INFO - Evaluating the model on dev set...
2018-04-28 15:24:53,518 - brc - INFO - Training the model...
2018-04-28 15:24:53,555 - brc - INFO - Training the model for epoch 1
2018-04-28 15:26:51,333 - brc - INFO - Average loss from batch 1 to 50 is 4.66792246819
2018-04-28 15:28:47,394 - brc - INFO - Average loss from batch 51 to 100 is 4.75130441189
2018-04-28 15:30:41,341 - brc - INFO - Average loss from batch 101 to 150 is 4.72161729813
2018-04-28 15:32:35,929 - brc - INFO - Average loss from batch 151 to 200 is 4.73896629333
2018-04-28 15:34:31,292 - brc - INFO - Average loss from batch 201 to 250 is 4.85503552437
2018-04-28 15:36:27,361 - brc - INFO - Average loss from batch 251 to 300 is 4.74432238102
2018-04-28 15:39:02,684 - brc - INFO - Average loss from batch 301 to 350 is 4.66472097397
2018-04-28 15:40:57,165 - brc - INFO - Average loss from batch 351 to 400 is 4.63951795101
2018-04-28 15:42:51,692 - brc - INFO - Average loss from batch 401 to 450 is 4.72601869583
2018-04-28 15:44:50,148 - brc - INFO - Average loss from batch 451 to 500 is 4.82999628067
2018-04-28 15:46:44,443 - brc - INFO - Average loss from batch 501 to 550 is 4.64146214008
2018-04-28 15:48:42,545 - brc - INFO - Average loss from batch 551 to 600 is 4.8109535265
2018-04-28 15:50:44,872 - brc - INFO - Average loss from batch 601 to 650 is 4.82090839863
2018-04-28 15:52:43,337 - brc - INFO - Average loss from batch 651 to 700 is 4.8482977438
2018-04-28 15:54:39,488 - brc - INFO - Average loss from batch 701 to 750 is 4.75104725838
2018-04-28 15:56:36,395 - brc - INFO - Average loss from batch 751 to 800 is 4.64526295185
2018-04-28 15:58:35,001 - brc - INFO - Average loss from batch 801 to 850 is 4.76760367393
2018-04-28 16:00:36,244 - brc - INFO - Average loss from batch 851 to 900 is 4.66754004955
2018-04-28 16:02:34,167 - brc - INFO - Average loss from batch 901 to 950 is 4.72859059334
2018-04-28 16:05:02,930 - brc - INFO - Average loss from batch 951 to 1000 is 4.72266762257
2018-04-28 16:05:15,189 - brc - INFO - Evaluating the model ...
2018-04-28 16:22:47,642 - brc - INFO - Dev eval loss 8.40526437378
2018-04-28 16:22:47,693 - brc - INFO - Dev eval result: {'BLEU-4': 40.97, 'ROUGE-L': 48.21}
2018-04-28 16:24:33,694 - brc - INFO - Average loss from batch 1001 to 1050 is 4.66444680214
2018-04-28 16:26:36,272 - brc - INFO - Average loss from batch 1051 to 1100 is 4.60696427822
2018-04-28 16:28:36,701 - brc - INFO - Average loss from batch 1101 to 1150 is 4.72377893448
2018-04-28 16:30:33,555 - brc - INFO - Average loss from batch 1151 to 1200 is 4.78052490234
2018-04-28 16:32:35,592 - brc - INFO - Average loss from batch 1201 to 1250 is 4.71267099857
2018-04-28 16:34:35,558 - brc - INFO - Average loss from batch 1251 to 1300 is 4.7685726881
2018-04-28 16:37:04,851 - brc - INFO - Average loss from batch 1301 to 1350 is 4.79096953869
2018-04-28 16:39:01,476 - brc - INFO - Average loss from batch 1351 to 1400 is 4.76560435772
2018-04-28 16:40:58,882 - brc - INFO - Average loss from batch 1401 to 1450 is 4.79385961056
2018-04-28 16:42:55,294 - brc - INFO - Average loss from batch 1451 to 1500 is 4.73876282692
2018-04-28 16:44:53,702 - brc - INFO - Average loss from batch 1501 to 1550 is 4.72352445602
2018-04-28 16:46:51,059 - brc - INFO - Average loss from batch 1551 to 1600 is 4.85227904797
2018-04-28 16:48:48,625 - brc - INFO - Average loss from batch 1601 to 1650 is 4.71933117867
2018-04-28 16:50:45,391 - brc - INFO - Average loss from batch 1651 to 1700 is 4.68755289555
2018-04-28 16:52:43,283 - brc - INFO - Average loss from batch 1701 to 1750 is 4.73373788834
2018-04-28 16:54:41,269 - brc - INFO - Average loss from batch 1751 to 1800 is 4.83640623093
2018-04-28 16:57:53,405 - brc - INFO - Average loss from batch 1801 to 1850 is 4.67221653938
2018-04-28 16:59:49,763 - brc - INFO - Average loss from batch 1851 to 1900 is 4.83592420578
2018-04-28 17:01:49,593 - brc - INFO - Average loss from batch 1901 to 1950 is 4.81061240196
2018-04-28 17:04:20,846 - brc - INFO - Average loss from batch 1951 to 2000 is 4.8063586998
2018-04-28 17:05:26,417 - brc - INFO - Evaluating the model ...
2018-04-28 17:23:08,197 - brc - INFO - Dev eval loss 8.41951038971
2018-04-28 17:23:22,419 - brc - INFO - Dev eval result: {'BLEU-4': 40.78, 'ROUGE-L': 48.4}
2018-04-28 17:24:53,695 - brc - INFO - Average loss from batch 2001 to 2050 is 4.79214953423
2018-04-28 17:26:51,319 - brc - INFO - Average loss from batch 2051 to 2100 is 4.9694635582
2018-04-28 17:29:13,273 - brc - INFO - Average loss from batch 2101 to 2150 is 4.86069416046
2018-04-28 17:31:09,142 - brc - INFO - Average loss from batch 2151 to 2200 is 4.7885051775
2018-04-28 17:33:04,679 - brc - INFO - Average loss from batch 2201 to 2250 is 4.84352568626
2018-04-28 17:35:32,410 - brc - INFO - Average loss from batch 2251 to 2300 is 4.74645408154
2018-04-28 17:37:29,154 - brc - INFO - Average loss from batch 2301 to 2350 is 4.81627727509
2018-04-28 17:39:24,701 - brc - INFO - Average loss from batch 2351 to 2400 is 4.6730542326
2018-04-28 17:41:30,142 - brc - INFO - Average loss from batch 2401 to 2450 is 4.72727174282
2018-04-28 17:43:25,327 - brc - INFO - Average loss from batch 2451 to 2500 is 4.610040555
2018-04-28 17:45:20,247 - brc - INFO - Average loss from batch 2501 to 2550 is 4.83506688118
2018-04-28 17:47:15,355 - brc - INFO - Average loss from batch 2551 to 2600 is 4.95075602055
2018-04-28 17:49:13,700 - brc - INFO - Average loss from batch 2601 to 2650 is 4.7601380825
2018-04-28 17:51:10,893 - brc - INFO - Average loss from batch 2651 to 2700 is 4.86989962578
2018-04-28 17:53:07,982 - brc - INFO - Average loss from batch 2701 to 2750 is 4.71178984642
2018-04-28 17:55:05,323 - brc - INFO - Average loss from batch 2751 to 2800 is 4.74471133232
2018-04-28 17:57:02,984 - brc - INFO - Average loss from batch 2801 to 2850 is 4.80609478474
2018-04-28 17:58:59,555 - brc - INFO - Average loss from batch 2851 to 2900 is 4.69781553268
2018-04-28 18:01:31,866 - brc - INFO - Average loss from batch 2901 to 2950 is 4.71713352203
2018-04-28 18:03:28,403 - brc - INFO - Average loss from batch 2951 to 3000 is 4.87999378204
2018-04-28 18:04:04,276 - brc - INFO - Evaluating the model ...
2018-04-28 18:21:42,663 - brc - INFO - Dev eval loss 8.42018710785
2018-04-28 18:21:42,666 - brc - INFO - Dev eval result: {'BLEU-4': 40.91, 'ROUGE-L': 48.29}
2018-04-28 18:23:05,182 - brc - INFO - Average loss from batch 3001 to 3050 is 4.62943840027
2018-04-28 18:25:03,540 - brc - INFO - Average loss from batch 3051 to 3100 is 4.76025537491
2018-04-28 18:27:16,016 - brc - INFO - Average loss from batch 3101 to 3150 is 4.78899557114
2018-04-28 18:29:13,398 - brc - INFO - Average loss from batch 3151 to 3200 is 4.76913964748
2018-04-28 18:31:10,946 - brc - INFO - Average loss from batch 3201 to 3250 is 4.89216293335
2018-04-28 18:33:48,345 - brc - INFO - Average loss from batch 3251 to 3300 is 4.77508292198
2018-04-28 18:35:47,656 - brc - INFO - Average loss from batch 3301 to 3350 is 4.80253639221
2018-04-28 18:37:45,715 - brc - INFO - Average loss from batch 3351 to 3400 is 4.72565611839
2018-04-28 18:39:43,688 - brc - INFO - Average loss from batch 3401 to 3450 is 4.78753050804
2018-04-28 18:41:40,503 - brc - INFO - Average loss from batch 3451 to 3500 is 4.68918514729
2018-04-28 18:43:38,292 - brc - INFO - Average loss from batch 3501 to 3550 is 4.70534226894
2018-04-28 18:45:34,386 - brc - INFO - Average loss from batch 3551 to 3600 is 4.64645254135
2018-04-28 18:47:32,997 - brc - INFO - Average loss from batch 3601 to 3650 is 4.71461892605
2018-04-28 18:49:30,079 - brc - INFO - Average loss from batch 3651 to 3700 is 4.56200794697
2018-04-28 18:51:27,566 - brc - INFO - Average loss from batch 3701 to 3750 is 4.66694842815
2018-04-28 18:53:25,238 - brc - INFO - Average loss from batch 3751 to 3800 is 4.85088404655
2018-04-28 18:55:22,549 - brc - INFO - Average loss from batch 3801 to 3850 is 4.80927671909
2018-04-28 18:57:20,448 - brc - INFO - Average loss from batch 3851 to 3900 is 4.81483136177
2018-04-28 19:00:00,204 - brc - INFO - Average loss from batch 3901 to 3950 is 4.76377652168
2018-04-28 19:01:59,015 - brc - INFO - Average loss from batch 3951 to 4000 is 4.73745428562
2018-04-28 19:02:46,525 - brc - INFO - Evaluating the model ...
2018-04-28 19:20:26,330 - brc - INFO - Dev eval loss 8.41534239197
2018-04-28 19:20:26,348 - brc - INFO - Dev eval result: {'BLEU-4': 40.95, 'ROUGE-L': 48.37}
2018-04-28 19:21:35,427 - brc - INFO - Average loss from batch 4001 to 4050 is 4.68847186565
2018-04-28 19:23:32,023 - brc - INFO - Average loss from batch 4051 to 4100 is 4.7625099802
2018-04-28 19:25:27,802 - brc - INFO - Average loss from batch 4101 to 4150 is 4.7038970232
2018-04-28 19:27:37,324 - brc - INFO - Average loss from batch 4151 to 4200 is 4.73308022976
2018-04-28 19:29:34,506 - brc - INFO - Average loss from batch 4201 to 4250 is 4.64986360073
2018-04-28 19:32:11,251 - brc - INFO - Average loss from batch 4251 to 4300 is 4.6914571619
2018-04-28 19:34:08,464 - brc - INFO - Average loss from batch 4301 to 4350 is 4.7968103838
2018-04-28 19:36:05,397 - brc - INFO - Average loss from batch 4351 to 4400 is 4.8760337162
2018-04-28 19:38:03,187 - brc - INFO - Average loss from batch 4401 to 4450 is 4.59392784595
2018-04-28 19:40:00,132 - brc - INFO - Average loss from batch 4451 to 4500 is 4.73381973267
2018-04-28 19:41:57,172 - brc - INFO - Average loss from batch 4501 to 4550 is 4.7760392189
2018-04-28 19:43:54,592 - brc - INFO - Average loss from batch 4551 to 4600 is 4.7011284399
2018-04-28 19:45:51,773 - brc - INFO - Average loss from batch 4601 to 4650 is 4.75739596844
2018-04-28 19:47:48,416 - brc - INFO - Average loss from batch 4651 to 4700 is 4.82054788113
2018-04-28 19:49:45,315 - brc - INFO - Average loss from batch 4701 to 4750 is 4.7354475832
2018-04-28 19:51:42,165 - brc - INFO - Average loss from batch 4751 to 4800 is 4.77772876263
2018-04-28 19:53:39,851 - brc - INFO - Average loss from batch 4801 to 4850 is 4.88680341244
2018-04-28 19:55:36,659 - brc - INFO - Average loss from batch 4851 to 4900 is 4.80336513996
2018-04-28 19:58:15,809 - brc - INFO - Average loss from batch 4901 to 4950 is 4.85767701626
2018-04-28 20:00:13,362 - brc - INFO - Average loss from batch 4951 to 5000 is 4.81793895245
2018-04-28 20:01:11,910 - brc - INFO - Evaluating the model ...
2018-04-28 20:19:01,849 - brc - INFO - Dev eval loss 8.45050299377
2018-04-28 20:19:01,866 - brc - INFO - Dev eval result: {'BLEU-4': 40.83, 'ROUGE-L': 48.39}
2018-04-28 20:20:00,069 - brc - INFO - Average loss from batch 5001 to 5050 is 4.66478590965
2018-04-28 20:21:58,273 - brc - INFO - Average loss from batch 5051 to 5100 is 4.77090447903
2018-04-28 20:23:55,424 - brc - INFO - Average loss from batch 5101 to 5150 is 4.71515273571
2018-04-28 20:25:52,192 - brc - INFO - Average loss from batch 5151 to 5200 is 4.78786364555
2018-04-28 20:27:49,350 - brc - INFO - Average loss from batch 5201 to 5250 is 4.83401553631
2018-04-28 20:30:23,817 - brc - INFO - Average loss from batch 5251 to 5300 is 4.85870897293
2018-04-28 20:32:21,013 - brc - INFO - Average loss from batch 5301 to 5350 is 4.86412445545
2018-04-28 20:34:19,268 - brc - INFO - Average loss from batch 5351 to 5400 is 4.72688304901
2018-04-28 20:36:16,718 - brc - INFO - Average loss from batch 5401 to 5450 is 4.71218626976
2018-04-28 20:38:13,852 - brc - INFO - Average loss from batch 5451 to 5500 is 4.85626492977
2018-04-28 20:40:10,969 - brc - INFO - Average loss from batch 5501 to 5550 is 4.85474350929
2018-04-28 20:42:08,446 - brc - INFO - Average loss from batch 5551 to 5600 is 4.92939269066
2018-04-28 20:44:04,920 - brc - INFO - Average loss from batch 5601 to 5650 is 4.81020082474
2018-04-28 20:46:01,868 - brc - INFO - Average loss from batch 5651 to 5700 is 4.7144563818
2018-04-28 20:47:58,735 - brc - INFO - Average loss from batch 5701 to 5750 is 4.77914502621
2018-04-28 20:49:55,782 - brc - INFO - Average loss from batch 5751 to 5800 is 4.96203923702
2018-04-28 20:51:52,121 - brc - INFO - Average loss from batch 5801 to 5850 is 4.79835885525
2018-04-28 20:53:48,350 - brc - INFO - Average loss from batch 5851 to 5900 is 4.64626572132
2018-04-28 20:56:24,819 - brc - INFO - Average loss from batch 5901 to 5950 is 4.87578175545
2018-04-28 20:58:19,869 - brc - INFO - Average loss from batch 5951 to 6000 is 4.81954690933
2018-04-28 20:59:28,943 - brc - INFO - Evaluating the model ...
2018-04-28 21:17:03,759 - brc - INFO - Dev eval loss 8.41344760056
2018-04-28 21:17:28,926 - brc - INFO - Dev eval result: {'BLEU-4': 40.69, 'ROUGE-L': 48.16}
2018-04-28 21:18:15,372 - brc - INFO - Average loss from batch 6001 to 6050 is 4.77025099277
2018-04-28 21:20:12,337 - brc - INFO - Average loss from batch 6051 to 6100 is 4.75326006889
2018-04-28 21:22:55,486 - brc - INFO - Average loss from batch 6101 to 6150 is 4.78941195488
2018-04-28 21:26:03,007 - brc - INFO - Average loss from batch 6151 to 6200 is 4.74127646446
2018-04-28 21:28:00,393 - brc - INFO - Average loss from batch 6201 to 6250 is 4.79967079639
2018-04-28 21:30:39,274 - brc - INFO - Average loss from batch 6251 to 6300 is 4.80910085201
2018-04-28 21:32:43,782 - brc - INFO - Average loss from batch 6301 to 6350 is 4.70088050365
2018-04-28 21:34:40,805 - brc - INFO - Average loss from batch 6351 to 6400 is 4.90321813107
2018-04-28 21:36:37,783 - brc - INFO - Average loss from batch 6401 to 6450 is 4.94960152626
2018-04-28 21:38:35,250 - brc - INFO - Average loss from batch 6451 to 6500 is 4.86772846699
2018-04-28 21:40:33,535 - brc - INFO - Average loss from batch 6501 to 6550 is 4.86782856464
2018-04-28 21:42:32,283 - brc - INFO - Average loss from batch 6551 to 6600 is 4.90593997478
2018-04-28 21:44:29,990 - brc - INFO - Average loss from batch 6601 to 6650 is 4.68463536263
2018-04-28 21:46:27,275 - brc - INFO - Average loss from batch 6651 to 6700 is 4.69367798328
2018-04-28 21:48:24,315 - brc - INFO - Average loss from batch 6701 to 6750 is 4.8715626955
2018-04-28 21:50:23,044 - brc - INFO - Average loss from batch 6751 to 6800 is 4.82314639091
2018-04-28 21:52:20,092 - brc - INFO - Average loss from batch 6801 to 6850 is 4.76009216309
2018-04-28 21:54:15,760 - brc - INFO - Average loss from batch 6851 to 6900 is 4.76691687584
2018-04-28 21:56:13,093 - brc - INFO - Average loss from batch 6901 to 6950 is 4.72185303688
2018-04-28 21:58:52,505 - brc - INFO - Average loss from batch 6951 to 7000 is 4.76112360954
2018-04-28 22:00:14,193 - brc - INFO - Evaluating the model ...
2018-04-28 22:18:07,240 - brc - INFO - Dev eval loss 8.43360738602
2018-04-28 22:18:07,243 - brc - INFO - Dev eval result: {'BLEU-4': 40.69, 'ROUGE-L': 48.21}
2018-04-28 22:18:41,950 - brc - INFO - Average loss from batch 7001 to 7050 is 4.78206849098
2018-04-28 22:20:40,267 - brc - INFO - Average loss from batch 7051 to 7100 is 4.84342163086
2018-04-28 22:22:38,449 - brc - INFO - Average loss from batch 7101 to 7150 is 4.75863025665
2018-04-28 22:24:35,498 - brc - INFO - Average loss from batch 7151 to 7200 is 4.75658740997
2018-04-28 22:26:32,224 - brc - INFO - Average loss from batch 7201 to 7250 is 4.75783098221
2018-04-28 22:28:30,091 - brc - INFO - Average loss from batch 7251 to 7300 is 4.87327148914
2018-04-28 22:31:09,814 - brc - INFO - Average loss from batch 7301 to 7350 is 4.7338699007
2018-04-28 22:33:06,448 - brc - INFO - Average loss from batch 7351 to 7400 is 4.77660858154
2018-04-28 22:35:03,401 - brc - INFO - Average loss from batch 7401 to 7450 is 4.83060936928
2018-04-28 22:37:00,533 - brc - INFO - Average loss from batch 7451 to 7500 is 4.78298779011
2018-04-28 22:38:57,567 - brc - INFO - Average loss from batch 7501 to 7550 is 4.8161438036
2018-04-28 22:40:56,587 - brc - INFO - Average loss from batch 7551 to 7600 is 4.72449710369
2018-04-28 22:42:54,742 - brc - INFO - Average loss from batch 7601 to 7650 is 4.7467872858
2018-04-28 22:44:51,247 - brc - INFO - Average loss from batch 7651 to 7700 is 4.72919041634
2018-04-28 22:46:50,801 - brc - INFO - Average loss from batch 7701 to 7750 is 4.74633811951
2018-04-28 22:48:45,628 - brc - INFO - Average loss from batch 7751 to 7800 is 4.90669676781
2018-04-28 22:50:41,685 - brc - INFO - Average loss from batch 7801 to 7850 is 4.64438154697
2018-04-28 22:52:36,844 - brc - INFO - Average loss from batch 7851 to 7900 is 4.83019565582
2018-04-28 22:54:32,624 - brc - INFO - Average loss from batch 7901 to 7950 is 4.75932806015
2018-04-28 22:57:10,967 - brc - INFO - Average loss from batch 7951 to 8000 is 4.8912555933
2018-04-28 22:58:43,517 - brc - INFO - Evaluating the model ...
2018-04-28 23:16:12,216 - brc - INFO - Dev eval loss 8.37806376038
2018-04-28 23:16:32,931 - brc - INFO - Dev eval result: {'BLEU-4': 41.04, 'ROUGE-L': 48.27}
2018-04-28 23:16:47,415 - brc - INFO - Average train loss for epoch 1 is 4.77070874939
2018-04-28 23:16:47,421 - brc - INFO - Evaluating the model after epoch 1
2018-04-28 23:35:05,242 - brc - INFO - Dev eval loss 8.37332947769
2018-04-28 23:35:05,242 - brc - INFO - Dev eval result: {'BLEU-4': 41.15, 'ROUGE-L': 48.23}
2018-04-28 23:35:05,242 - brc - INFO - Training the model for epoch 2
2018-04-28 23:37:06,542 - brc - INFO - Average loss from batch 1 to 50 is 4.63650876999
2018-04-28 23:39:06,859 - brc - INFO - Average loss from batch 51 to 100 is 4.63097349644
2018-04-28 23:41:06,749 - brc - INFO - Average loss from batch 101 to 150 is 4.64347807407
2018-04-28 23:43:07,972 - brc - INFO - Average loss from batch 151 to 200 is 4.63964641571
2018-04-28 23:45:10,438 - brc - INFO - Average loss from batch 201 to 250 is 4.61398551464
2018-04-28 23:47:12,580 - brc - INFO - Average loss from batch 251 to 300 is 4.46213554382
2018-04-28 23:49:13,799 - brc - INFO - Average loss from batch 301 to 350 is 4.710458498
2018-04-28 23:51:15,682 - brc - INFO - Average loss from batch 351 to 400 is 4.66998981476
2018-04-28 23:53:17,217 - brc - INFO - Average loss from batch 401 to 450 is 4.74709969997
2018-04-28 23:55:19,663 - brc - INFO - Average loss from batch 451 to 500 is 4.66607192039
2018-04-28 23:57:20,528 - brc - INFO - Average loss from batch 501 to 550 is 4.77644430637
2018-04-28 23:59:21,503 - brc - INFO - Average loss from batch 551 to 600 is 4.66122328281
2018-04-29 00:01:23,060 - brc - INFO - Average loss from batch 601 to 650 is 4.70084465981
2018-04-29 00:04:11,516 - brc - INFO - Average loss from batch 651 to 700 is 4.62755092621
2018-04-29 00:06:14,270 - brc - INFO - Average loss from batch 701 to 750 is 4.76290534496
2018-04-29 00:08:16,042 - brc - INFO - Average loss from batch 751 to 800 is 4.68527517796
2018-04-29 00:10:19,454 - brc - INFO - Average loss from batch 801 to 850 is 4.58453837872
2018-04-29 00:12:23,021 - brc - INFO - Average loss from batch 851 to 900 is 4.69775912762
2018-04-29 00:14:25,946 - brc - INFO - Average loss from batch 901 to 950 is 4.63965350628
2018-04-29 00:16:28,254 - brc - INFO - Average loss from batch 951 to 1000 is 4.62240474701
2018-04-29 00:16:44,524 - brc - INFO - Evaluating the model ...
2018-04-29 00:34:40,997 - brc - INFO - Dev eval loss 8.51700577164
2018-04-29 00:34:40,997 - brc - INFO - Dev eval result: {'BLEU-4': 40.8, 'ROUGE-L': 48.0}
2018-04-29 00:37:12,402 - brc - INFO - Average loss from batch 1001 to 1050 is 4.75903505325
2018-04-29 00:39:12,370 - brc - INFO - Average loss from batch 1051 to 1100 is 4.64449277401
2018-04-29 00:41:12,015 - brc - INFO - Average loss from batch 1101 to 1150 is 4.71080979824
2018-04-29 00:43:12,191 - brc - INFO - Average loss from batch 1151 to 1200 is 4.74414048195
2018-04-29 00:45:12,447 - brc - INFO - Average loss from batch 1201 to 1250 is 4.78506169319
2018-04-29 00:47:12,577 - brc - INFO - Average loss from batch 1251 to 1300 is 4.72298557281
2018-04-29 00:49:12,004 - brc - INFO - Average loss from batch 1301 to 1350 is 4.65677222252
2018-04-29 00:51:11,868 - brc - INFO - Average loss from batch 1351 to 1400 is 4.7347549963
2018-04-29 00:53:11,362 - brc - INFO - Average loss from batch 1401 to 1450 is 4.82622707367
2018-04-29 00:55:10,806 - brc - INFO - Average loss from batch 1451 to 1500 is 4.70045269966
2018-04-29 00:57:12,462 - brc - INFO - Average loss from batch 1501 to 1550 is 4.76331713676
2018-04-29 00:59:11,636 - brc - INFO - Average loss from batch 1551 to 1600 is 4.75071576595
2018-04-29 01:01:10,657 - brc - INFO - Average loss from batch 1601 to 1650 is 4.67366275787
2018-04-29 01:04:01,265 - brc - INFO - Average loss from batch 1651 to 1700 is 4.60025606632
2018-04-29 01:06:00,001 - brc - INFO - Average loss from batch 1701 to 1750 is 4.72543447018
2018-04-29 01:07:59,975 - brc - INFO - Average loss from batch 1751 to 1800 is 4.58781218052
2018-04-29 01:09:59,925 - brc - INFO - Average loss from batch 1801 to 1850 is 4.63092012405
2018-04-29 01:12:02,083 - brc - INFO - Average loss from batch 1851 to 1900 is 4.66165733337
2018-04-29 01:14:04,001 - brc - INFO - Average loss from batch 1901 to 1950 is 4.64504266739
2018-04-29 01:16:07,732 - brc - INFO - Average loss from batch 1951 to 2000 is 4.66149593353
2018-04-29 01:16:32,339 - brc - INFO - Evaluating the model ...
2018-04-29 01:34:16,941 - brc - INFO - Dev eval loss 8.5221310112
2018-04-29 01:34:16,942 - brc - INFO - Dev eval result: {'BLEU-4': 41.61, 'ROUGE-L': 48.03}
2018-04-29 01:35:53,724 - brc - INFO - Average loss from batch 2001 to 2050 is 4.73832677841
2018-04-29 01:38:44,853 - brc - INFO - Average loss from batch 2051 to 2100 is 4.74715610027
2018-04-29 01:40:47,083 - brc - INFO - Average loss from batch 2101 to 2150 is 4.73709741116
2018-04-29 01:42:50,791 - brc - INFO - Average loss from batch 2151 to 2200 is 4.779185853
2018-04-29 01:44:53,786 - brc - INFO - Average loss from batch 2201 to 2250 is 4.63871101379
2018-04-29 01:46:56,808 - brc - INFO - Average loss from batch 2251 to 2300 is 4.59423249722
2018-04-29 01:48:59,715 - brc - INFO - Average loss from batch 2301 to 2350 is 4.65520039558
2018-04-29 01:51:03,064 - brc - INFO - Average loss from batch 2351 to 2400 is 4.57828318596
2018-04-29 01:53:05,886 - brc - INFO - Average loss from batch 2401 to 2450 is 4.61010699749
2018-04-29 01:55:08,838 - brc - INFO - Average loss from batch 2451 to 2500 is 4.71663136959
2018-04-29 01:57:11,670 - brc - INFO - Average loss from batch 2501 to 2550 is 4.73339079857
2018-04-29 01:59:12,908 - brc - INFO - Average loss from batch 2551 to 2600 is 4.66963299274
2018-04-29 02:01:15,015 - brc - INFO - Average loss from batch 2601 to 2650 is 4.67219628811
2018-04-29 02:03:17,823 - brc - INFO - Average loss from batch 2651 to 2700 is 4.58807836056
2018-04-29 02:06:08,408 - brc - INFO - Average loss from batch 2701 to 2750 is 4.78318844318
2018-04-29 02:08:10,837 - brc - INFO - Average loss from batch 2751 to 2800 is 4.79592762947
2018-04-29 02:10:13,224 - brc - INFO - Average loss from batch 2801 to 2850 is 4.52849184036
2018-04-29 02:12:15,168 - brc - INFO - Average loss from batch 2851 to 2900 is 4.69919648647
2018-04-29 02:14:17,963 - brc - INFO - Average loss from batch 2901 to 2950 is 4.71907295704
2018-04-29 02:16:21,023 - brc - INFO - Average loss from batch 2951 to 3000 is 4.80522441864
2018-04-29 02:16:57,399 - brc - INFO - Evaluating the model ...
2018-04-29 02:35:11,224 - brc - INFO - Dev eval loss 8.55576927261
2018-04-29 02:35:11,255 - brc - INFO - Dev eval result: {'BLEU-4': 40.73, 'ROUGE-L': 48.39}
2018-04-29 02:36:34,883 - brc - INFO - Average loss from batch 3001 to 3050 is 4.61915932178
2018-04-29 02:39:25,221 - brc - INFO - Average loss from batch 3051 to 3100 is 4.63286836147
2018-04-29 02:41:24,762 - brc - INFO - Average loss from batch 3101 to 3150 is 4.6776909256
2018-04-29 02:43:25,014 - brc - INFO - Average loss from batch 3151 to 3200 is 4.64412020683
2018-04-29 02:45:24,853 - brc - INFO - Average loss from batch 3201 to 3250 is 4.75137990475
2018-04-29 02:47:25,745 - brc - INFO - Average loss from batch 3251 to 3300 is 4.66542545795
2018-04-29 02:49:25,167 - brc - INFO - Average loss from batch 3301 to 3350 is 4.67940232754
2018-04-29 02:51:25,144 - brc - INFO - Average loss from batch 3351 to 3400 is 4.70633728027
2018-04-29 02:53:25,189 - brc - INFO - Average loss from batch 3401 to 3450 is 4.75682647228
2018-04-29 02:55:27,820 - brc - INFO - Average loss from batch 3451 to 3500 is 4.63290951729
2018-04-29 02:57:32,031 - brc - INFO - Average loss from batch 3501 to 3550 is 4.76709004402
2018-04-29 02:59:34,099 - brc - INFO - Average loss from batch 3551 to 3600 is 4.71511980534
2018-04-29 03:01:48,574 - brc - INFO - Average loss from batch 3601 to 3650 is 4.63046278954
2018-04-29 03:04:33,654 - brc - INFO - Average loss from batch 3651 to 3700 is 4.66971402645
2018-04-29 03:06:38,361 - brc - INFO - Average loss from batch 3701 to 3750 is 4.83688662052
2018-04-29 03:09:28,535 - brc - INFO - Average loss from batch 3751 to 3800 is 4.69221991062
2018-04-29 03:11:30,737 - brc - INFO - Average loss from batch 3801 to 3850 is 4.72159781933
2018-04-29 03:13:32,962 - brc - INFO - Average loss from batch 3851 to 3900 is 4.66099836349
2018-04-29 03:15:35,554 - brc - INFO - Average loss from batch 3901 to 3950 is 4.54706523895
2018-04-29 03:17:38,081 - brc - INFO - Average loss from batch 3951 to 4000 is 4.57095230103
2018-04-29 03:18:27,460 - brc - INFO - Evaluating the model ...
2018-04-29 03:36:05,301 - brc - INFO - Dev eval loss 8.58759653625
2018-04-29 03:36:05,304 - brc - INFO - Dev eval result: {'BLEU-4': 41.53, 'ROUGE-L': 47.99}
2018-04-29 03:37:17,735 - brc - INFO - Average loss from batch 4001 to 4050 is 4.68453579426
2018-04-29 03:39:20,286 - brc - INFO - Average loss from batch 4051 to 4100 is 4.68322130203
2018-04-29 03:42:11,835 - brc - INFO - Average loss from batch 4101 to 4150 is 4.71508447647
2018-04-29 03:44:14,146 - brc - INFO - Average loss from batch 4151 to 4200 is 4.73336958885
2018-04-29 03:46:16,701 - brc - INFO - Average loss from batch 4201 to 4250 is 4.76525384426
2018-04-29 03:48:20,040 - brc - INFO - Average loss from batch 4251 to 4300 is 4.8414710331
2018-04-29 03:50:20,926 - brc - INFO - Average loss from batch 4301 to 4350 is 4.67685491562
2018-04-29 03:52:23,463 - brc - INFO - Average loss from batch 4351 to 4400 is 4.76510558605
2018-04-29 03:54:27,441 - brc - INFO - Average loss from batch 4401 to 4450 is 4.74956043243
2018-04-29 03:56:31,207 - brc - INFO - Average loss from batch 4451 to 4500 is 4.6130026722
2018-04-29 03:58:33,892 - brc - INFO - Average loss from batch 4501 to 4550 is 4.67692672729
2018-04-29 04:00:37,334 - brc - INFO - Average loss from batch 4551 to 4600 is 4.73264997482
2018-04-29 04:02:39,617 - brc - INFO - Average loss from batch 4601 to 4650 is 4.65297867775
2018-04-29 04:04:41,425 - brc - INFO - Average loss from batch 4651 to 4700 is 4.63960395336
2018-04-29 04:06:44,172 - brc - INFO - Average loss from batch 4701 to 4750 is 4.65928609848
2018-04-29 04:08:46,466 - brc - INFO - Average loss from batch 4751 to 4800 is 4.68766586304
2018-04-29 04:11:37,533 - brc - INFO - Average loss from batch 4801 to 4850 is 4.79524665356
2018-04-29 04:13:41,071 - brc - INFO - Average loss from batch 4851 to 4900 is 4.62615207672
2018-04-29 04:15:44,749 - brc - INFO - Average loss from batch 4901 to 4950 is 4.70337965012
2018-04-29 04:17:46,431 - brc - INFO - Average loss from batch 4951 to 5000 is 4.58345582962
2018-04-29 04:18:47,381 - brc - INFO - Evaluating the model ...
2018-04-29 04:37:00,636 - brc - INFO - Dev eval loss 8.55802585907
2018-04-29 04:37:00,681 - brc - INFO - Dev eval result: {'BLEU-4': 40.76, 'ROUGE-L': 48.06}
2018-04-29 04:37:59,184 - brc - INFO - Average loss from batch 5001 to 5050 is 4.81680860996
2018-04-29 04:40:00,981 - brc - INFO - Average loss from batch 5051 to 5100 is 4.68982113838
2018-04-29 04:42:02,200 - brc - INFO - Average loss from batch 5101 to 5150 is 4.78713374615
2018-04-29 04:44:51,358 - brc - INFO - Average loss from batch 5151 to 5200 is 4.74788454056
2018-04-29 04:46:52,567 - brc - INFO - Average loss from batch 5201 to 5250 is 4.70529746056
2018-04-29 04:49:20,520 - brc - INFO - Average loss from batch 5251 to 5300 is 4.73117358208
2018-04-29 04:51:23,628 - brc - INFO - Average loss from batch 5301 to 5350 is 4.74636592865
2018-04-29 04:53:45,120 - brc - INFO - Average loss from batch 5351 to 5400 is 4.70072422981
2018-04-29 04:55:46,382 - brc - INFO - Average loss from batch 5401 to 5450 is 4.63689350605
2018-04-29 04:57:47,971 - brc - INFO - Average loss from batch 5451 to 5500 is 4.75482126713
2018-04-29 04:59:52,017 - brc - INFO - Average loss from batch 5501 to 5550 is 4.76085224152
2018-04-29 05:01:54,057 - brc - INFO - Average loss from batch 5551 to 5600 is 4.64111248016
2018-04-29 05:03:55,976 - brc - INFO - Average loss from batch 5601 to 5650 is 4.70480219841
2018-04-29 05:05:58,959 - brc - INFO - Average loss from batch 5651 to 5700 is 4.61553325653
2018-04-29 05:08:01,142 - brc - INFO - Average loss from batch 5701 to 5750 is 4.65081354618
2018-04-29 05:10:11,390 - brc - INFO - Average loss from batch 5751 to 5800 is 4.79812643528
2018-04-29 05:12:13,373 - brc - INFO - Average loss from batch 5801 to 5850 is 4.65130255222
2018-04-29 05:15:05,620 - brc - INFO - Average loss from batch 5851 to 5900 is 4.83033743382
2018-04-29 05:17:09,523 - brc - INFO - Average loss from batch 5901 to 5950 is 4.6736067152
2018-04-29 05:19:12,722 - brc - INFO - Average loss from batch 5951 to 6000 is 4.64335160255
2018-04-29 05:20:26,364 - brc - INFO - Evaluating the model ...
2018-04-29 05:38:53,505 - brc - INFO - Dev eval loss 8.5149860054
2018-04-29 05:38:53,555 - brc - INFO - Dev eval result: {'BLEU-4': 40.12, 'ROUGE-L': 48.18}
2018-04-29 05:39:42,655 - brc - INFO - Average loss from batch 6001 to 6050 is 4.77713274479
2018-04-29 05:41:45,280 - brc - INFO - Average loss from batch 6051 to 6100 is 4.69627787113
2018-04-29 05:43:49,322 - brc - INFO - Average loss from batch 6101 to 6150 is 4.74242808342
2018-04-29 05:45:53,231 - brc - INFO - Average loss from batch 6151 to 6200 is 4.65431983471
2018-04-29 05:48:47,682 - brc - INFO - Average loss from batch 6201 to 6250 is 4.76337844849
2018-04-29 05:50:50,595 - brc - INFO - Average loss from batch 6251 to 6300 is 4.76525383472
2018-04-29 05:52:54,708 - brc - INFO - Average loss from batch 6301 to 6350 is 4.68649506092
2018-04-29 05:54:56,623 - brc - INFO - Average loss from batch 6351 to 6400 is 4.78336133003
2018-04-29 05:57:00,604 - brc - INFO - Average loss from batch 6401 to 6450 is 4.68179712296
2018-04-29 05:59:02,392 - brc - INFO - Average loss from batch 6451 to 6500 is 4.75572003841
2018-04-29 06:01:04,491 - brc - INFO - Average loss from batch 6501 to 6550 is 4.71328932285
2018-04-29 06:03:17,083 - brc - INFO - Average loss from batch 6551 to 6600 is 4.67495792389
2018-04-29 06:05:20,264 - brc - INFO - Average loss from batch 6601 to 6650 is 4.72539758682
2018-04-29 06:07:25,228 - brc - INFO - Average loss from batch 6651 to 6700 is 4.68098178864
2018-04-29 06:09:29,649 - brc - INFO - Average loss from batch 6701 to 6750 is 4.7676671648
2018-04-29 06:11:30,125 - brc - INFO - Average loss from batch 6751 to 6800 is 4.71335010052
2018-04-29 06:13:31,132 - brc - INFO - Average loss from batch 6801 to 6850 is 4.66668161392
2018-04-29 06:16:37,339 - brc - INFO - Average loss from batch 6851 to 6900 is 4.78261867523
2018-04-29 06:18:46,658 - brc - INFO - Average loss from batch 6901 to 6950 is 4.66110343456
2018-04-29 06:20:49,189 - brc - INFO - Average loss from batch 6951 to 7000 is 4.69945113182
2018-04-29 06:22:14,257 - brc - INFO - Evaluating the model ...
2018-04-29 06:40:25,008 - brc - INFO - Dev eval loss 8.53716842041
2018-04-29 06:40:25,081 - brc - INFO - Dev eval result: {'BLEU-4': 40.98, 'ROUGE-L': 48.27}
2018-04-29 06:41:02,665 - brc - INFO - Average loss from batch 7001 to 7050 is 4.6403779459
2018-04-29 06:43:04,509 - brc - INFO - Average loss from batch 7051 to 7100 is 4.73390721321
2018-04-29 06:45:08,643 - brc - INFO - Average loss from batch 7101 to 7150 is 4.72237017155
2018-04-29 06:47:14,666 - brc - INFO - Average loss from batch 7151 to 7200 is 4.79138046741
2018-04-29 06:50:10,106 - brc - INFO - Average loss from batch 7201 to 7250 is 4.71702663898
2018-04-29 06:52:14,695 - brc - INFO - Average loss from batch 7251 to 7300 is 4.72262979507
2018-04-29 06:54:18,088 - brc - INFO - Average loss from batch 7301 to 7350 is 4.83314901829
2018-04-29 06:56:21,774 - brc - INFO - Average loss from batch 7351 to 7400 is 4.73859939575
2018-04-29 06:58:24,961 - brc - INFO - Average loss from batch 7401 to 7450 is 4.68507987976
2018-04-29 07:00:30,183 - brc - INFO - Average loss from batch 7451 to 7500 is 4.62585681438
2018-04-29 07:02:33,604 - brc - INFO - Average loss from batch 7501 to 7550 is 4.62916731358
2018-04-29 07:04:37,554 - brc - INFO - Average loss from batch 7551 to 7600 is 4.76969089031
2018-04-29 07:06:39,059 - brc - INFO - Average loss from batch 7601 to 7650 is 4.81574606419
2018-04-29 07:08:42,250 - brc - INFO - Average loss from batch 7651 to 7700 is 4.5284478569
2018-04-29 07:10:44,631 - brc - INFO - Average loss from batch 7701 to 7750 is 4.57050127029
2018-04-29 07:12:46,602 - brc - INFO - Average loss from batch 7751 to 7800 is 4.74628818989
2018-04-29 07:14:49,986 - brc - INFO - Average loss from batch 7801 to 7850 is 4.76464057922
2018-04-29 07:16:51,822 - brc - INFO - Average loss from batch 7851 to 7900 is 4.61091007233
2018-04-29 07:19:43,183 - brc - INFO - Average loss from batch 7901 to 7950 is 4.82173359871
2018-04-29 07:21:44,942 - brc - INFO - Average loss from batch 7951 to 8000 is 4.69023562908
2018-04-29 07:23:37,280 - brc - INFO - Evaluating the model ...
2018-04-29 07:41:50,488 - brc - INFO - Dev eval loss 8.48415563126
2018-04-29 07:42:00,679 - brc - INFO - Dev eval result: {'BLEU-4': 40.66, 'ROUGE-L': 48.22}
2018-04-29 07:42:14,817 - brc - INFO - Average train loss for epoch 2 is 4.69571879221
2018-04-29 07:42:14,820 - brc - INFO - Evaluating the model after epoch 2
2018-04-29 08:01:20,638 - brc - INFO - Dev eval loss 8.48239729691
2018-04-29 08:01:20,641 - brc - INFO - Dev eval result: {'BLEU-4': 40.77, 'ROUGE-L': 48.22}
2018-04-29 08:01:20,643 - brc - INFO - Training the model for epoch 3
2018-04-29 08:03:19,173 - brc - INFO - Average loss from batch 1 to 50 is 4.48301029682
2018-04-29 08:05:21,380 - brc - INFO - Average loss from batch 51 to 100 is 4.60789975166
2018-04-29 08:07:23,970 - brc - INFO - Average loss from batch 101 to 150 is 4.59175880909
2018-04-29 08:09:26,038 - brc - INFO - Average loss from batch 151 to 200 is 4.63360083103
2018-04-29 08:11:26,021 - brc - INFO - Average loss from batch 201 to 250 is 4.60542421341
2018-04-29 08:13:26,682 - brc - INFO - Average loss from batch 251 to 300 is 4.57498476982
2018-04-29 08:15:28,361 - brc - INFO - Average loss from batch 301 to 350 is 4.572716856
2018-04-29 08:17:29,304 - brc - INFO - Average loss from batch 351 to 400 is 4.59252819061
2018-04-29 08:19:29,917 - brc - INFO - Average loss from batch 401 to 450 is 4.52640101433
2018-04-29 08:21:30,684 - brc - INFO - Average loss from batch 451 to 500 is 4.54475159168
2018-04-29 08:23:32,297 - brc - INFO - Average loss from batch 501 to 550 is 4.58360844135
2018-04-29 08:25:33,407 - brc - INFO - Average loss from batch 551 to 600 is 4.56023441315
2018-04-29 08:28:24,149 - brc - INFO - Average loss from batch 601 to 650 is 4.52429081917
2018-04-29 08:30:23,954 - brc - INFO - Average loss from batch 651 to 700 is 4.58723238945
2018-04-29 08:32:27,620 - brc - INFO - Average loss from batch 701 to 750 is 4.56707859039
2018-04-29 08:34:32,308 - brc - INFO - Average loss from batch 751 to 800 is 4.495360322
2018-04-29 08:36:35,563 - brc - INFO - Average loss from batch 801 to 850 is 4.53008713722
2018-04-29 08:38:39,849 - brc - INFO - Average loss from batch 851 to 900 is 4.60105819225
2018-04-29 08:40:43,587 - brc - INFO - Average loss from batch 901 to 950 is 4.68486841202
2018-04-29 08:42:47,402 - brc - INFO - Average loss from batch 951 to 1000 is 4.66439920902
2018-04-29 08:43:00,140 - brc - INFO - Evaluating the model ...
2018-04-29 09:02:27,614 - brc - INFO - Dev eval loss 8.62159707413
2018-04-29 09:02:27,957 - brc - INFO - Dev eval result: {'BLEU-4': 40.36, 'ROUGE-L': 47.9}
2018-04-29 09:04:17,075 - brc - INFO - Average loss from batch 1001 to 1050 is 4.56524851322
2018-04-29 09:06:20,685 - brc - INFO - Average loss from batch 1051 to 1100 is 4.49696968079
2018-04-29 09:08:24,730 - brc - INFO - Average loss from batch 1101 to 1150 is 4.51897621632
2018-04-29 09:10:28,354 - brc - INFO - Average loss from batch 1151 to 1200 is 4.69902846813
2018-04-29 09:12:31,241 - brc - INFO - Average loss from batch 1201 to 1250 is 4.47083260059
2018-04-29 09:14:34,365 - brc - INFO - Average loss from batch 1251 to 1300 is 4.60994431019
2018-04-29 09:16:37,858 - brc - INFO - Average loss from batch 1301 to 1350 is 4.68634736061
2018-04-29 09:18:41,446 - brc - INFO - Average loss from batch 1351 to 1400 is 4.5322062397
2018-04-29 09:20:46,039 - brc - INFO - Average loss from batch 1401 to 1450 is 4.57520158768
2018-04-29 09:22:49,136 - brc - INFO - Average loss from batch 1451 to 1500 is 4.56000923157
2018-04-29 09:24:53,117 - brc - INFO - Average loss from batch 1501 to 1550 is 4.47725474834
2018-04-29 09:26:57,063 - brc - INFO - Average loss from batch 1551 to 1600 is 4.4377802372
2018-04-29 09:29:52,606 - brc - INFO - Average loss from batch 1601 to 1650 is 4.55821031094
2018-04-29 09:31:55,062 - brc - INFO - Average loss from batch 1651 to 1700 is 4.53770739079
2018-04-29 09:33:58,300 - brc - INFO - Average loss from batch 1701 to 1750 is 4.56803769588
2018-04-29 09:36:02,093 - brc - INFO - Average loss from batch 1751 to 1800 is 4.50860528469
2018-04-29 09:38:05,476 - brc - INFO - Average loss from batch 1801 to 1850 is 4.40812224865
2018-04-29 09:40:09,081 - brc - INFO - Average loss from batch 1851 to 1900 is 4.60624243736
2018-04-29 09:42:13,026 - brc - INFO - Average loss from batch 1901 to 1950 is 4.67664227962
2018-04-29 09:44:16,933 - brc - INFO - Average loss from batch 1951 to 2000 is 4.67550041676
2018-04-29 09:44:41,472 - brc - INFO - Evaluating the model ...
2018-04-29 10:03:28,452 - brc - INFO - Dev eval loss 8.68082930603
2018-04-29 10:03:28,454 - brc - INFO - Dev eval result: {'BLEU-4': 41.46, 'ROUGE-L': 47.8}
2018-04-29 10:05:04,032 - brc - INFO - Average loss from batch 2001 to 2050 is 4.61499405861
2018-04-29 10:07:05,122 - brc - INFO - Average loss from batch 2051 to 2100 is 4.58011542797
2018-04-29 10:09:05,331 - brc - INFO - Average loss from batch 2101 to 2150 is 4.53483835697
2018-04-29 10:11:05,542 - brc - INFO - Average loss from batch 2151 to 2200 is 4.54995833397
2018-04-29 10:13:05,845 - brc - INFO - Average loss from batch 2201 to 2250 is 4.48137468338
2018-04-29 10:15:06,332 - brc - INFO - Average loss from batch 2251 to 2300 is 4.53904039383
2018-04-29 10:17:07,675 - brc - INFO - Average loss from batch 2301 to 2350 is 4.6002391386
2018-04-29 10:19:12,000 - brc - INFO - Average loss from batch 2351 to 2400 is 4.54172428131
2018-04-29 10:21:16,562 - brc - INFO - Average loss from batch 2401 to 2450 is 4.70727497101
2018-04-29 10:23:20,618 - brc - INFO - Average loss from batch 2451 to 2500 is 4.66797232151
2018-04-29 10:25:23,396 - brc - INFO - Average loss from batch 2501 to 2550 is 4.52886559963
2018-04-29 10:27:26,460 - brc - INFO - Average loss from batch 2551 to 2600 is 4.5589298439
2018-04-29 10:29:30,845 - brc - INFO - Average loss from batch 2601 to 2650 is 4.57124791145
2018-04-29 10:32:26,156 - brc - INFO - Average loss from batch 2651 to 2700 is 4.59365137577
2018-04-29 10:34:30,014 - brc - INFO - Average loss from batch 2701 to 2750 is 4.61010618687
2018-04-29 10:36:34,256 - brc - INFO - Average loss from batch 2751 to 2800 is 4.53155426025
2018-04-29 10:38:38,471 - brc - INFO - Average loss from batch 2801 to 2850 is 4.58863465786
2018-04-29 10:40:41,677 - brc - INFO - Average loss from batch 2851 to 2900 is 4.45839300156
2018-04-29 10:42:45,539 - brc - INFO - Average loss from batch 2901 to 2950 is 4.55917748451
2018-04-29 10:44:49,697 - brc - INFO - Average loss from batch 2951 to 3000 is 4.48908586025
2018-04-29 10:45:26,316 - brc - INFO - Evaluating the model ...
2018-04-29 11:04:02,933 - brc - INFO - Dev eval loss 8.66024165268
2018-04-29 11:04:02,936 - brc - INFO - Dev eval result: {'BLEU-4': 40.72, 'ROUGE-L': 47.88}
2018-04-29 11:07:30,414 - brc - INFO - Running with args : Namespace(algo='BIDAF', batch_size=32, brc_dir='model/', char_embed='../../data/embedding/wiki_brc/wiki_brc.char.vec', char_hidden_size=100, dev_files=['../../data/preprocessed_ltp/devset/search.dev.filter.json', '../../data/preprocessed_ltp/devset/zhidao.dev.filter.json'], dropout_keep_prob=1, epochs=10, evaluate=False, gpu='0', hidden_size=150, learning_rate=0.0001, log_path='model/log', max_a_len=500, max_p_len=500, max_p_num=5, max_q_len=60, max_w_len=4, model_dir='model/', optim='adam', pos_embed_dim=10, pr_rate=0.2, predict=True, prepare=False, restore=False, result_dir='model/', summary_dir='model/', test_files=['../../data/preprocessed_ltp/test2set/search.test1.filter.json', '../../data/preprocessed_ltp/test2set/zhidao.test1.filter.json', '../../data/preprocessed_ltp/test2set/search.test2.filter.json', '../../data/preprocessed_ltp/test2set/zhidao.test2.filter.json'], train=False, train_files=['../../data/preprocessed_ltp/trainset/search.train.filter.json', '../../data/preprocessed_ltp/trainset/zhidao.train.filter.json'], vocab_dir='model/', weight_decay=0, word_embed='../../data/embedding/wiki_brc/wiki_brc.word.vec')
2018-04-29 11:07:30,414 - brc - INFO - Load data_set and vocab...
2018-04-29 11:19:39,793 - brc - INFO - Running with args : Namespace(algo='BIDAF', batch_size=64, brc_dir='model/', char_embed='../../data/embedding/wiki_brc/wiki_brc.char.vec', char_hidden_size=100, dev_files=['../../data/preprocessed_ltp/devset/search.dev.filter.json', '../../data/preprocessed_ltp/devset/zhidao.dev.filter.json'], dropout_keep_prob=1, epochs=10, evaluate=False, gpu='0', hidden_size=150, learning_rate=0.0001, log_path='model/log', max_a_len=500, max_p_len=500, max_p_num=5, max_q_len=60, max_w_len=4, model_dir='model/', optim='adam', pos_embed_dim=10, pr_rate=0.2, predict=True, prepare=False, restore=False, result_dir='model/', summary_dir='model/', test_files=['../../data/preprocessed_ltp/test2set/search.test1.filter.json', '../../data/preprocessed_ltp/test2set/zhidao.test1.filter.json', '../../data/preprocessed_ltp/test2set/search.test2.filter.json', '../../data/preprocessed_ltp/test2set/zhidao.test2.filter.json'], train=False, train_files=['../../data/preprocessed_ltp/trainset/search.train.filter.json', '../../data/preprocessed_ltp/trainset/zhidao.train.filter.json'], vocab_dir='model/', weight_decay=0, word_embed='../../data/embedding/wiki_brc/wiki_brc.word.vec')
2018-04-29 11:19:39,793 - brc - INFO - Load data_set and vocab...
2018-04-29 11:32:46,170 - brc - INFO - Test set size: 120000 questions.
2018-04-29 11:32:46,170 - brc - INFO - Converting text into ids...
2018-04-29 11:39:34,205 - brc - INFO - Restoring the model...
2018-04-29 11:39:40,602 - brc - INFO - Time to build graph: 5.98728394508 s
2018-04-29 11:39:59,011 - brc - INFO - There are 3865506 parameters in the model
2018-04-29 11:40:09,288 - brc - INFO - Model restored from model/, with prefix BIDAF
2018-04-29 11:40:09,288 - brc - INFO - Predicting answers for test set...
2018-04-29 13:51:19,398 - brc - INFO - Saving test.predicted results to model/test.predicted.json
2018-05-02 09:53:36,607 - brc - INFO - Running with args : Namespace(algo='BIDAF', batch_size=128, brc_dir='model/', char_embed='../../data/embedding/wiki_brc/wiki_brc.char.vec', char_hidden_size=100, dev_files=['../../data/preprocessed_ltp/devset/search.dev.filter.json', '../../data/preprocessed_ltp/devset/zhidao.dev.filter.json'], dropout_keep_prob=1, epochs=10, evaluate=True, gpu='0', hidden_size=150, learning_rate=0.001, log_path='model/log', max_a_len=500, max_p_len=500, max_p_num=5, max_q_len=60, max_w_len=4, model_dir='model/backup22/', optim='adam', pos_embed_dim=10, pr_rate=0.2, predict=False, prepare=False, restore=False, result_dir='model/', summary_dir='model/', test_files=['../../data/test1set/preprocessed/search.test1.json', '../../data/test1set/preprocessed/zhidao.test1.json'], train=False, train_files=['../../data/preprocessed/trainset/search.train.json', '../../data/preprocessed/trainset/zhidao.train.json'], vocab_dir='model/', weight_decay=0, word_embed='../../data/embedding/wiki_brc/wiki_brc.word.vec')
2018-05-02 09:53:36,607 - brc - INFO - Load data_set and vocab...
2018-05-02 09:54:58,774 - brc - INFO - Dev set size: 10000 questions.
2018-05-02 09:54:58,775 - brc - INFO - Converting text into ids...
2018-05-02 09:55:25,100 - brc - INFO - Restoring the model...
2018-05-02 09:55:31,091 - brc - INFO - Time to build graph: 4.59329581261 s
2018-05-02 09:55:42,232 - brc - INFO - There are 3865506 parameters in the model
2018-05-02 09:55:44,925 - brc - INFO - Model restored from model/backup22/, with prefix BIDAF
2018-05-02 09:55:44,926 - brc - INFO - Evaluating the model on dev set...
2018-05-02 10:05:23,570 - brc - INFO - Saving dev.predicted results to model/dev.predicted.json
2018-05-02 10:12:09,392 - brc - INFO - Loss on dev set: 8.25737721405
2018-05-02 10:12:09,395 - brc - INFO - Result on dev set: {'BLEU-4': 42.46, 'ROUGE-L': 50.17}
2018-05-02 10:12:09,395 - brc - INFO - Predicted answers are saved to model/
2018-05-03 19:41:46,855 - brc - INFO - Running with args : Namespace(algo='BIDAF', batch_size=64, brc_dir='model/', char_embed='../../data/embedding/wiki_brc/wiki_brc.char.vec', char_hidden_size=100, dev_files=['../../data/preprocessed_ltp/devset/search.dev.filter.json', '../../data/preprocessed_ltp/devset/zhidao.dev.filter.json'], dropout_keep_prob=1, epochs=10, evaluate=True, gpu='0', hidden_size=150, learning_rate=0.001, log_path='model/log', max_a_len=500, max_p_len=500, max_p_num=5, max_q_len=60, max_w_len=4, model_dir='model/backup22/', optim='adam', pos_embed_dim=10, pr_rate=0.2, predict=False, prepare=False, restore=False, result_dir='model/', summary_dir='model/', test_files=['../../data/test1set/preprocessed/search.test1.json', '../../data/test1set/preprocessed/zhidao.test1.json'], train=False, train_files=['../../data/preprocessed/trainset/search.train.json', '../../data/preprocessed/trainset/zhidao.train.json'], vocab_dir='model/', weight_decay=0, word_embed='../../data/embedding/wiki_brc/wiki_brc.word.vec')
2018-05-03 19:41:46,855 - brc - INFO - Load data_set and vocab...
2018-05-03 19:42:51,360 - brc - INFO - Dev set size: 10000 questions.
2018-05-03 19:42:51,360 - brc - INFO - Converting text into ids...
2018-05-03 19:43:07,199 - brc - INFO - Restoring the model...
2018-05-03 19:43:12,643 - brc - INFO - Time to build graph: 5.16960597038 s
2018-05-03 19:44:52,558 - brc - INFO - Running with args : Namespace(algo='BIDAF', batch_size=64, brc_dir='model/', char_embed='../../data/embedding/wiki_brc/wiki_brc.char.vec', char_hidden_size=100, dev_files=['../../data/preprocessed_ltp/devset/search.dev.filter.json', '../../data/preprocessed_ltp/devset/zhidao.dev.filter.json'], dropout_keep_prob=1, epochs=10, evaluate=True, gpu='0', hidden_size=150, learning_rate=0.001, log_path='model/log', max_a_len=500, max_p_len=500, max_p_num=5, max_q_len=60, max_w_len=4, model_dir='model/backup22/', optim='adam', pos_embed_dim=10, pr_rate=0.2, predict=False, prepare=False, restore=False, result_dir='model/', summary_dir='model/', test_files=['../../data/test1set/preprocessed/search.test1.json', '../../data/test1set/preprocessed/zhidao.test1.json'], train=False, train_files=['../../data/preprocessed/trainset/search.train.json', '../../data/preprocessed/trainset/zhidao.train.json'], vocab_dir='model/', weight_decay=0, word_embed='../../data/embedding/wiki_brc/wiki_brc.word.vec')
2018-05-03 19:44:52,558 - brc - INFO - Load data_set and vocab...
2018-05-03 19:45:45,292 - brc - INFO - Dev set size: 10000 questions.
2018-05-03 19:45:45,292 - brc - INFO - Converting text into ids...
2018-05-03 19:46:01,067 - brc - INFO - Restoring the model...
2018-05-03 19:46:06,431 - brc - INFO - Time to build graph: 5.10367512703 s
2018-05-03 19:46:13,770 - brc - INFO - There are 3865506 parameters in the model
2018-05-03 19:46:18,943 - brc - INFO - Model restored from model/backup22/, with prefix BIDAF
2018-05-03 19:46:18,943 - brc - INFO - Evaluating the model on dev set...
2018-05-03 19:46:55,978 - brc - INFO - Running with args : Namespace(algo='BIDAF', batch_size=96, brc_dir='model/', char_embed='../../data/embedding/wiki_brc/wiki_brc.char.vec', char_hidden_size=100, dev_files=['../../data/preprocessed_ltp/devset/search.dev.filter.json', '../../data/preprocessed_ltp/devset/zhidao.dev.filter.json'], dropout_keep_prob=1, epochs=10, evaluate=True, gpu='0', hidden_size=150, learning_rate=0.001, log_path='model/log', max_a_len=500, max_p_len=500, max_p_num=5, max_q_len=60, max_w_len=4, model_dir='model/backup22/', optim='adam', pos_embed_dim=10, pr_rate=0.2, predict=False, prepare=False, restore=False, result_dir='model/', summary_dir='model/', test_files=['../../data/test1set/preprocessed/search.test1.json', '../../data/test1set/preprocessed/zhidao.test1.json'], train=False, train_files=['../../data/preprocessed/trainset/search.train.json', '../../data/preprocessed/trainset/zhidao.train.json'], vocab_dir='model/', weight_decay=0, word_embed='../../data/embedding/wiki_brc/wiki_brc.word.vec')
2018-05-03 19:46:55,978 - brc - INFO - Load data_set and vocab...
2018-05-03 19:47:48,367 - brc - INFO - Dev set size: 10000 questions.
2018-05-03 19:47:48,367 - brc - INFO - Converting text into ids...
2018-05-03 19:48:03,763 - brc - INFO - Restoring the model...
2018-05-03 19:48:09,135 - brc - INFO - Time to build graph: 5.10927891731 s
2018-05-03 19:48:16,585 - brc - INFO - There are 3865506 parameters in the model
2018-05-03 19:48:18,355 - brc - INFO - Model restored from model/backup22/, with prefix BIDAF
2018-05-03 19:48:18,355 - brc - INFO - Evaluating the model on dev set...
2018-05-03 19:55:38,985 - brc - INFO - Saving dev.predicted results to model/dev.predicted.json
2018-05-03 20:00:16,979 - brc - INFO - Loss on dev set: 8.25737710114
2018-05-03 20:00:16,979 - brc - INFO - Result on dev set: {'BLEU-4': 42.46, 'ROUGE-L': 50.17}
2018-05-03 20:00:16,979 - brc - INFO - Predicted answers are saved to model/
2018-05-08 11:20:58,039 - brc - INFO - Running with args : Namespace(algo='BIDAF', batch_size=96, brc_dir='model/', char_embed='../../data/embedding/wiki_brc/wiki_brc.char.vec', char_hidden_size=100, dev_files=['../../data/preprocessed_ltp/devset/search.dev.filter.json', '../../data/preprocessed_ltp/devset/zhidao.dev.filter.json'], dropout_keep_prob=1, epochs=10, evaluate=True, gpu='0', hidden_size=150, learning_rate=0.001, log_path='model/log', max_a_len=500, max_p_len=500, max_p_num=5, max_q_len=60, max_w_len=4, model_dir='model/backup22/', optim='adam', pos_embed_dim=10, pr_rate=0.2, predict=False, prepare=False, restore=False, result_dir='model/', summary_dir='model/', test_files=['../../data/test1set/preprocessed/search.test1.json', '../../data/test1set/preprocessed/zhidao.test1.json'], train=False, train_files=['../../data/preprocessed/trainset/search.train.json', '../../data/preprocessed/trainset/zhidao.train.json'], vocab_dir='model/', weight_decay=0, word_embed='../../data/embedding/wiki_brc/wiki_brc.word.vec')
2018-05-08 11:20:58,039 - brc - INFO - Load data_set and vocab...
2018-05-08 11:22:03,850 - brc - INFO - Dev set size: 10000 questions.
2018-05-08 11:22:03,850 - brc - INFO - Converting text into ids...
2018-05-08 11:22:19,605 - brc - INFO - Restoring the model...
2018-05-08 11:22:26,304 - brc - INFO - Time to build graph: 5.87147498131 s
2018-05-08 11:22:33,736 - brc - INFO - There are 3865506 parameters in the model
2018-05-08 11:22:39,220 - brc - INFO - Model restored from model/backup22/, with prefix BIDAF
2018-05-08 11:22:39,220 - brc - INFO - Evaluating the model on dev set...
2018-05-08 11:30:04,363 - brc - INFO - Saving dev.predicted results to model/dev.predicted.json
2018-05-08 11:35:06,531 - brc - INFO - Loss on dev set: 8.25737710114
2018-05-08 11:35:06,533 - brc - INFO - Result on dev set: {'BLEU-4': 42.46, 'ROUGE-L': 50.17}
2018-05-08 11:35:06,533 - brc - INFO - Predicted answers are saved to model/
2018-05-13 00:16:32,875 - brc - INFO - Running with args : Namespace(algo='BIDAF', batch_size=96, brc_dir='model/', char_embed='../../data/embedding/wiki_brc/wiki_brc.char.vec', char_hidden_size=100, dev_files=['../../data/preprocessed_ltp/devset/search.dev.filter.json', '../../data/preprocessed_ltp/devset/zhidao.dev.filter.json'], dropout_keep_prob=1, epochs=10, evaluate=True, gpu='0', hidden_size=150, learning_rate=0.001, log_path='model/log', max_a_len=500, max_p_len=500, max_p_num=5, max_q_len=60, max_w_len=4, model_dir='model/backup22/', optim='adam', pos_embed_dim=10, pr_rate=0.2, predict=False, prepare=False, restore=False, result_dir='model/', summary_dir='model/', test_files=['../../data/test1set/preprocessed/search.test1.json', '../../data/test1set/preprocessed/zhidao.test1.json'], train=False, train_files=['../../data/preprocessed/trainset/search.train.json', '../../data/preprocessed/trainset/zhidao.train.json'], vocab_dir='model/', weight_decay=0, word_embed='../../data/embedding/wiki_brc/wiki_brc.word.vec')
2018-05-13 00:16:32,875 - brc - INFO - Load data_set and vocab...
2018-05-13 00:17:38,115 - brc - INFO - Dev set size: 10000 questions.
2018-05-13 00:17:38,115 - brc - INFO - Converting text into ids...
2018-05-13 00:17:53,743 - brc - INFO - Restoring the model...
2018-05-13 00:18:00,500 - brc - INFO - Time to build graph: 5.84607696533 s
2018-05-13 00:18:07,920 - brc - INFO - There are 3865506 parameters in the model
2018-05-13 00:18:13,057 - brc - INFO - Model restored from model/backup22/, with prefix BIDAF
2018-05-13 00:18:13,057 - brc - INFO - Evaluating the model on dev set...
2018-05-13 00:25:36,856 - brc - INFO - Saving dev.predicted results to model/dev.predicted.json
2018-05-13 00:30:40,999 - brc - INFO - Loss on dev set: 8.25737710114
2018-05-13 00:30:41,005 - brc - INFO - Result on dev set: {'BLEU-4': 42.46, 'ROUGE-L': 50.17}
2018-05-13 00:30:41,005 - brc - INFO - Predicted answers are saved to model/
2018-05-23 23:02:17,403 - brc - INFO - Running with args : Namespace(algo='BIDAF', batch_size=96, brc_dir='model/', char_embed='../../data/embedding/wiki_brc/wiki_brc.char.vec', char_hidden_size=100, dev_files=['../../data/preprocessed_ltp/devset/search.dev.filter.json', '../../data/preprocessed_ltp/devset/zhidao.dev.filter.json'], dropout_keep_prob=1, epochs=10, evaluate=True, gpu='0', hidden_size=150, learning_rate=0.001, log_path='model/log', max_a_len=500, max_p_len=500, max_p_num=5, max_q_len=60, max_w_len=4, model_dir='model/backup22/', optim='adam', pos_embed_dim=10, pr_rate=0.2, predict=False, prepare=False, restore=False, result_dir='model/', summary_dir='model/', test_files=['../../data/test1set/preprocessed/search.test1.json', '../../data/test1set/preprocessed/zhidao.test1.json'], train=False, train_files=['../../data/preprocessed/trainset/search.train.json', '../../data/preprocessed/trainset/zhidao.train.json'], vocab_dir='model/', weight_decay=0, word_embed='../../data/embedding/wiki_brc/wiki_brc.word.vec')
2018-05-23 23:02:17,403 - brc - INFO - Load data_set and vocab...
2018-05-23 23:03:24,265 - brc - INFO - Dev set size: 10000 questions.
2018-05-23 23:03:24,265 - brc - INFO - Converting text into ids...
2018-05-23 23:03:41,156 - brc - INFO - Restoring the model...
2018-05-23 23:03:48,146 - brc - INFO - Time to build graph: 6.1444978714 s
2018-05-23 23:03:56,008 - brc - INFO - There are 3865506 parameters in the model
2018-05-23 23:04:01,213 - brc - INFO - Model restored from model/backup22/, with prefix BIDAF
2018-05-23 23:04:01,213 - brc - INFO - Evaluating the model on dev set...
2018-05-23 23:11:27,971 - brc - INFO - Saving dev.predicted results to model/dev.predicted.json
2018-05-23 23:16:02,792 - brc - INFO - Loss on dev set: 8.25737710114
2018-05-23 23:16:02,794 - brc - INFO - Result on dev set: {'BLEU-4': 42.46, 'ROUGE-L': 50.17}
2018-05-23 23:16:02,794 - brc - INFO - Predicted answers are saved to model/
